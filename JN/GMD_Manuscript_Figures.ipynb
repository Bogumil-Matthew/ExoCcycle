{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265277d7",
   "metadata": {},
   "source": [
    "# <center>GMD_Manuscript_Figures</center>\n",
    "This jupyter-notebook is used to make the GMD methods paper figures\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6d676",
   "metadata": {},
   "source": [
    "# F01: Reconstructed Bathymetry plots and Basin Boundaries Used in Bogumil et al. (2024) (See FinalizedFigures folder for Composite Figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "\n",
    "# For reading matlab files that store plate boundaries.\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "from netCDF4 import Dataset\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import Polygon\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "\n",
    "###################################\n",
    "## Define Functions for Figure  ###\n",
    "###################################\n",
    "def load_netcdf_data(age):\n",
    "    # Read bathymetry file.\n",
    "    ds = Dataset(os.getcwd()+'/PNAS_Bogumil_Results/bathymetryNCFiles/Bathymetry_{}Ma.nc'.format(age))\n",
    "\n",
    "    # Assign data to variables\n",
    "    lon, lat = np.meshgrid(ds['lon'][:], ds['lat'][:]);\n",
    "    z = ds['z'][:].data;\n",
    "    continents = ds['z'][:].mask;\n",
    "    continentsnew = cp.deepcopy(continents).astype(float)\n",
    "    continentsnew[continentsnew==0] = np.nan\n",
    "\n",
    "    \n",
    "    # Close dataset\n",
    "    ds.close();\n",
    "    \n",
    "    # Return variables\n",
    "    return lon, lat, z, continentsnew\n",
    "\n",
    "def remove_non_unique_rows(arr):\n",
    "    # Count occurrences of each row\n",
    "    unique_rows, counts = np.unique(arr, axis=0, return_counts=True)\n",
    "    # Only keep rows that appear once\n",
    "    unique_only = unique_rows[counts == 1]\n",
    "    return unique_only\n",
    "\n",
    "def readBoundaries(age, pacificValues=[1,0]):\n",
    "    # Load the .mat file\n",
    "    mat_data = scipy.io.loadmat(os.getcwd()+'/PNAS_Bogumil_Results/basinPolygons/Earth{}Ma_basin_poly.mat'.format(age))\n",
    "\n",
    "    # Print variable names in the file (ignoring MATLAB metadata entries)\n",
    "    variable_names = [key for key in mat_data.keys() if not key.startswith('__')]\n",
    "    #print(\"Variables in .mat file:\", variable_names);\n",
    "\n",
    "    # Access a specific variable (replace 'your_variable_name' as needed)\n",
    "    boundaries = mat_data['Earth{}Ma'.format(age)][0][0];\n",
    "    \n",
    "    # Merge two Pacific boundaries\n",
    "    if pacificValues is not None:\n",
    "        x = np.vstack( (boundaries[pacificValues[0]], boundaries[pacificValues[1]]) )\n",
    "        x = remove_non_unique_rows(x)\n",
    "        boundariesOut = np.array(np.arange(len(boundaries)-1), dtype=object)\n",
    "        boundariesOut[0] = x\n",
    "\n",
    "        cnt = 0;\n",
    "        for i in range(len(boundaries)):\n",
    "            #print(i, (pacificValues[0]==i), (pacificValues[1]==i), ((pacificValues[0]==i) | (pacificValues[1]==i)))\n",
    "            if not ((pacificValues[0]==i) | (pacificValues[1]==i)):\n",
    "                #print(i)\n",
    "                boundariesOut[cnt+1] = boundaries[i]\n",
    "                boundariesOut[cnt+1] = boundaries[i]\n",
    "                cnt+=1;\n",
    "    else:\n",
    "        boundariesOut = np.array(np.arange(len(boundaries)), dtype=object)\n",
    "        for i in range(len(boundaries)):\n",
    "            boundariesOut[i] = boundaries[i]\n",
    "        \n",
    "\n",
    "    return boundariesOut\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# Read and plot bathymetry and basin boundaries from Bogumil et al. (2024) #\n",
    "############################################################################\n",
    "\n",
    "# Load NetCDF file\n",
    "age1 = 0; age2 = 60;\n",
    "lon, lat, z1, continents1 = load_netcdf_data(age1)\n",
    "lon, lat, z2, continents2 = load_netcdf_data(age2)\n",
    "\n",
    "# Load basin boundaries\n",
    "boundaries1 = readBoundaries(age1, None)\n",
    "boundaries2 = readBoundaries(age2, None)\n",
    "\n",
    "# Reduce resolution\n",
    "factor = 1\n",
    "lon = lon[::factor].T[::factor].T\n",
    "lat = lat[::factor].T[::factor].T\n",
    "z1  = z1[::factor].T[::factor].T\n",
    "z2  = z2[::factor].T[::factor].T\n",
    "continents1 = continents1[::factor].T[::factor].T\n",
    "continents2 = continents2[::factor].T[::factor].T\n",
    "\n",
    "\n",
    "# Create the figure\n",
    "## Set up projection and figure\n",
    "proj = ccrs.Robinson()\n",
    "fig, axs = plt.subplots(\n",
    "    2, 1,\n",
    "    figsize=(12, 10),\n",
    "    subplot_kw={'projection': proj},\n",
    "    constrained_layout=False\n",
    ")\n",
    "\n",
    "# Define common color scale\n",
    "vmin = np.nanmin([np.nanmin(z1), np.nanmin(z2)])\n",
    "vmax = np.nanmax([np.nanmax(z1), np.nanmax(z2)])\n",
    "vmin = 0\n",
    "vmax = 6000\n",
    "\n",
    "\n",
    "# Example polygon (replace with your actual lat/lon)\n",
    "poly_lats = [-10, -10, 0, 0, -10]\n",
    "poly_lons = [100, 110, 110, 100, 100]\n",
    "polygon = Polygon(zip(poly_lons, poly_lats))\n",
    "\n",
    "# Sample reversed blue cmap for bathymetry\n",
    "N = 35\n",
    "N = 30\n",
    "blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "\n",
    "# Plot first dataset\n",
    "## Plot bathymetry\n",
    "mesh11 = axs[0].pcolormesh(lon, lat, z1, transform=ccrs.PlateCarree(), cmap=blues_cm, shading='auto', vmin=vmin, vmax=vmax)\n",
    "## Plot Land\n",
    "mesh12 = axs[0].pcolormesh(lon, lat, continents1, transform=ccrs.PlateCarree(), cmap='YlOrBr', shading='auto', vmin=0, vmax=4)\n",
    "## Plot basin boundaries\n",
    "colors = ['black', 'black', 'black', 'black', 'black']\n",
    "\n",
    "#colors = ['black', 'black', 'red', 'green']\n",
    "cnt=0\n",
    "for boundary in boundaries1:\n",
    "    lonB = boundary[:,0]\n",
    "    latB = -1*boundary[:,1]\n",
    "    latB[latB > 90] = 90;\n",
    "    latB[latB < -90] = -90;\n",
    "    lonB[lonB > 180] = 180;\n",
    "    lonB[lonB < -180] = -180;\n",
    "\n",
    "    polygon1 = Polygon(zip(lonB, latB))\n",
    "    colori = colors[cnt]\n",
    "    axs[0].plot(lonB, latB, linestyle='solid', color=colori, transform=ccrs.PlateCarree())\n",
    "    cnt+=1;\n",
    "\n",
    "\n",
    "# Plot second dataset\n",
    "## Plot bathymetry\n",
    "mesh21 = axs[1].pcolormesh(lon, lat, z2, transform=ccrs.PlateCarree(), cmap=blues_cm, shading='auto', vmin=vmin, vmax=vmax)\n",
    "## Plot Land\n",
    "mesh22 = axs[1].pcolormesh(lon, lat, continents2, transform=ccrs.PlateCarree(), cmap='YlOrBr', shading='auto', vmin=0, vmax=4)\n",
    "## Plot basin boundaries\n",
    "cnt=0\n",
    "for boundary in boundaries2:\n",
    "    lonB = boundary[:,0]\n",
    "    latB = -1*boundary[:,1]\n",
    "    \n",
    "    latB[latB > 90] = 90;\n",
    "    latB[latB < -90] = -90;\n",
    "    lonB[lonB > 180] = 180;\n",
    "    lonB[lonB < -180] = -180;\n",
    "\n",
    "    polygon1 = Polygon(zip(lonB, latB))\n",
    "    colori = colors[cnt]\n",
    "    axs[1].plot(lonB, latB, linestyle='solid', color=colori, transform=ccrs.PlateCarree())\n",
    "    #axs[1].add_geometries([polygon1], crs=ccrs.PlateCarree(), facecolor='none', edgecolor=colori, linewidth=2)\n",
    "    cnt+=1;\n",
    "\n",
    "\n",
    "# Add shared colorbar\n",
    "cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.02])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(mesh21, cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label(\"Bathymetry\")\n",
    "\n",
    "# Save figure\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/Bogumil_etal_2024_Bathymetry_and_BasinBoundaries\"\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "plt.savefig(directory_name+\"/0_60Ma_Bathymetry_and_BasinBoundaries.png\", dpi=600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82019cbc",
   "metadata": {},
   "source": [
    "# F04: Diagrams used to construct Girvan-Newman and Louvain Algorithm Diagram Figure (See FinalizedFigures folder for Composite Figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/GN_L_Algorithm\";\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "\n",
    "###################################\n",
    "## Define Functions for Figure 2 ##\n",
    "###################################\n",
    "class NeighborNetwork():\n",
    "    \"\"\"\n",
    "    createNeighborNetwork is a function designed\n",
    "    to create an networkx spatial graph with neighbor\n",
    "    node edges. Node edges are given a value of 1,\n",
    "    but can be modified using a method.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size=(2,8)):\n",
    "        \"\"\"\n",
    "        Initializes NeighborNetwork.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        size : TUPLE\n",
    "            A tuple describing the size of the output\n",
    "            graph. The graph will have size[0]*size[1]\n",
    "            nodes.\n",
    "        \"\"\"\n",
    "        # Construct new graph\n",
    "        self.G = nx.Graph()\n",
    "        \n",
    "        # Add nodes\n",
    "        ## Create numpy array of input size\n",
    "        rows = size[0]\n",
    "        cols = size[1]\n",
    "        self.XX, self.YY = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "        \n",
    "        # Create nodes\n",
    "        self.pos = [];\n",
    "        for x, y in zip(self.XX.flatten(), self.YY.flatten()):\n",
    "            currentNodeid = x + y*cols;\n",
    "            self.G.add_node(currentNodeid, pos=(x-(cols-1)/2,\n",
    "                                                (y-(rows-1)/2)*np.abs(0.4*(x-(cols-1)/2))+(y-(rows-1)/2))\n",
    "                           )\n",
    "            self.pos.append(currentNodeid)\n",
    "        self.pos=np.array(self.pos);\n",
    "        \n",
    "        # Iterate over each nodes' xy position adding edges\n",
    "        # adding each edge.\n",
    "        for x, y in zip(self.XX.flatten(), self.YY.flatten()):\n",
    "            # Positions\n",
    "            #               X + Y*(# of columns) \n",
    "            currentNodeid = x + y*cols;\n",
    "            leftid        = x + y*cols - 1;\n",
    "            aboveid       = x + (y-1)*cols\n",
    "            \n",
    "            # Add edges to other nodes            \n",
    "            if (x > 0):\n",
    "                # Make connection left\n",
    "                self.G.add_edge(currentNodeid,leftid, weight=1)            \n",
    "            if (y > 0):\n",
    "                # Make connection below\n",
    "                self.G.add_edge(currentNodeid,aboveid, weight=1)\n",
    "                \n",
    "            # Add edges to other nodes            \n",
    "            if (x == 0):\n",
    "                # Make connection left\n",
    "                self.G.add_edge(currentNodeid,leftid+cols, weight=1)            \n",
    "                \n",
    "                \n",
    "    def plot(self, title=\"Initial network\", saveFig=True):\n",
    "        elarge = [(u, v) for (u, v, d) in self.G.edges(data=True) if d[\"weight\"] > .5]\n",
    "        esmall = [(u, v) for (u, v, d) in self.G.edges(data=True) if d[\"weight\"] <= .5]\n",
    "        \n",
    "        pos = nx.get_node_attributes(myNeighborNetwork.G, \"pos\")\n",
    "        \n",
    "        # Create new figure\n",
    "        fig = plt.figure()\n",
    "\n",
    "        # nodes\n",
    "        nx.draw_networkx_nodes(self.G, pos, node_size=700)\n",
    "\n",
    "        # edges\n",
    "        nx.draw_networkx_edges(self.G, pos, edgelist=elarge, width=6)\n",
    "        nx.draw_networkx_edges(\n",
    "            self.G, pos, edgelist=esmall, width=6, alpha=0.5, edge_color=\"r\", style=\"dashed\"\n",
    "        )\n",
    "\n",
    "        # node labels\n",
    "        nx.draw_networkx_labels(self.G, pos, font_size=20, font_family=\"sans-serif\")\n",
    "        # edge weight labels\n",
    "        edge_labels = nx.get_edge_attributes(self.G, \"weight\")\n",
    "        nx.draw_networkx_edge_labels(self.G, pos, edge_labels)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        plt.title(title)\n",
    "        ax.margins(.1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        if saveFig:\n",
    "            plt.savefig(directory_name+\"/\"+title+\".svg\", dpi=600)\n",
    "\n",
    "# Girvan-newman algorithm \n",
    "def most_central_edge(G):\n",
    "    centrality = nx.edge_betweenness_centrality(G, weight=\"weight\")\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# Function that removes highest between edges removeNEdges times.\n",
    "def girvanNewmanBetweennessDiagram(removeNEdges=1):\n",
    "    # Make graph ()\n",
    "    myNeighborNetwork = NeighborNetwork(size=(2,4))\n",
    "    ## Change edge attributes\n",
    "    myNeighborNetwork.G.edges[5,6]['weight'] = .5\n",
    "    myNeighborNetwork.G.edges[1,2]['weight'] = .7\n",
    "\n",
    "    # Plot again (removed most central edge)\n",
    "    for i in range(removeNEdges):\n",
    "        u,v = most_central_edge(myNeighborNetwork.G)\n",
    "        centrality = nx.edge_betweenness_centrality(myNeighborNetwork.G, weight=\"weight\")\n",
    "        print(\"Removing edge from node pair {}-{}\".format(u,v))\n",
    "        myNeighborNetwork.G.remove_edge(u,v)\n",
    "        \n",
    "        \n",
    "    myNeighborNetwork.plot(title=\"3-{} Removed highest edge betweenness centrality - Girvan-Newman\".format(i))\n",
    "\n",
    "\n",
    "    # Plot again (change edge values to centrality values)\n",
    "\n",
    "    ## Set node edges to have betweenness centrality value\n",
    "    list(centrality.values())/ np.min(list(centrality.values()))\n",
    "    for nodes in centrality:\n",
    "        myNeighborNetwork.G.add_edge(nodes[0],\n",
    "                                     nodes[1],\n",
    "                                     weight=centrality[nodes]/np.min(list(centrality.values())))\n",
    "\n",
    "    myNeighborNetwork.plot(title=\"2-{} Betweenness Centrality Values - Girvan-Newman\".format(i))\n",
    "        \n",
    "\n",
    "###############################\n",
    "### Girvan-newman algorithm ###\n",
    "###############################\n",
    "# Make graph ()\n",
    "myNeighborNetwork = NeighborNetwork(size=(2,4))\n",
    "## Change edge attributes\n",
    "myNeighborNetwork.G.edges[5,6]['weight'] = .5\n",
    "myNeighborNetwork.G.edges[1,2]['weight'] = .7\n",
    "\n",
    "# Plot graph\n",
    "myNeighborNetwork.plot(title='1 Initial network - Girvan-Newman')\n",
    "\n",
    "\n",
    "#############################################\n",
    "### Girvan-newman algorithm removed edges ###\n",
    "#############################################\n",
    "# Remove one edge (1 community)\n",
    "girvanNewmanBetweennessDiagram(1)\n",
    "# Remove two edge (1 community)\n",
    "girvanNewmanBetweennessDiagram(2)\n",
    "# Remove three edge (1 community)\n",
    "girvanNewmanBetweennessDiagram(3)\n",
    "# Remove four edge (Creates 2 communities)\n",
    "girvanNewmanBetweennessDiagram(4)\n",
    "\n",
    "\n",
    "###############################\n",
    "###### Louvain algorithm ######\n",
    "###############################\n",
    "# Make graph ()\n",
    "myNeighborNetwork = NeighborNetwork(size=(2,4))\n",
    "\n",
    "commL = nx.community.louvain_communities(myNeighborNetwork.G, weight='weight', max_level=20)\n",
    "\n",
    "## Change edge attributes\n",
    "# myNeighborNetwork.G.remove_edge(4,5)\n",
    "# myNeighborNetwork.G.remove_edge(5,6)\n",
    "# myNeighborNetwork.G.remove_edge(6,7)\n",
    "# myNeighborNetwork.G.remove_edge(7,4)\n",
    "\n",
    "# myNeighborNetwork.G.remove_edge(0,1)\n",
    "# myNeighborNetwork.G.remove_edge(1,2)\n",
    "# myNeighborNetwork.G.remove_edge(2,3)\n",
    "# myNeighborNetwork.G.remove_edge(3,0)\n",
    "\n",
    "# myNeighborNetwork.G.remove_edge(4,0)\n",
    "# myNeighborNetwork.G.remove_edge(5,1)\n",
    "# myNeighborNetwork.G.remove_edge(6,2)\n",
    "# myNeighborNetwork.G.remove_edge(7,3)\n",
    "\n",
    "###################################\n",
    "## Define Functions for Figure 2 ##\n",
    "###################################\n",
    "def remove_intercommunity_edges(G, communities):\n",
    "    \"\"\"\n",
    "    Removes all edges between communities in the graph G.\n",
    "\n",
    "    Parameters:\n",
    "    - G: A NetworkX graph (can be directed or undirected)\n",
    "    - communities: A list of sets, each set contains nodes in one community\n",
    "                   (e.g., output of nx.community.louvain_communities)\n",
    "\n",
    "    Returns:\n",
    "    - G_sub: A copy of G with only intra-community edges retained\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original graph\n",
    "    G_sub = G.copy()\n",
    "    \n",
    "    # Build a node to community index map\n",
    "    node_to_comm = {}\n",
    "    for idx, comm in enumerate(communities):\n",
    "        for node in comm:\n",
    "            node_to_comm[node] = idx\n",
    "\n",
    "    # Identify and remove inter-community edges\n",
    "    edges_to_remove = []\n",
    "    for u, v in G.edges():\n",
    "        if node_to_comm.get(u) != node_to_comm.get(v):\n",
    "            edges_to_remove.append((u, v))\n",
    "\n",
    "    G_sub.remove_edges_from(edges_to_remove)\n",
    "    return G_sub\n",
    "\n",
    "\n",
    "###############################\n",
    "###### Louvain algorithm ######\n",
    "###############################\n",
    "# Make graph ()\n",
    "myNeighborNetwork1 = NeighborNetwork(size=(2,4))\n",
    "myNeighborNetwork2 = NeighborNetwork(size=(2,4))\n",
    "\n",
    "## Change edge attributes\n",
    "myNeighborNetwork1.G.edges[5,6]['weight'] = .5\n",
    "myNeighborNetwork1.G.edges[1,2]['weight'] = .7\n",
    "myNeighborNetwork2.G.edges[5,6]['weight'] = .5\n",
    "myNeighborNetwork2.G.edges[1,2]['weight'] = .7\n",
    "\n",
    "## Find communities\n",
    "seed = 3\n",
    "commL1 = nx.community.louvain_communities(myNeighborNetwork1.G, weight='weight', threshold=.9, max_level=100, seed=seed)\n",
    "commL2 = nx.community.louvain_communities(myNeighborNetwork2.G, weight='weight', threshold=.2, max_level=100, seed=seed)\n",
    "\n",
    "## Find Louvain communities\n",
    "modularity1 = nx.community.modularity(myNeighborNetwork1.G, commL1, weight='weight')\n",
    "modularity2 = nx.community.modularity(myNeighborNetwork2.G, commL2, weight='weight')\n",
    "\n",
    "# Plot graph - Initial graph\n",
    "myNeighborNetwork1.plot(title='4 Initial network - Louvain', saveFig=True)\n",
    "\n",
    "# Plot graph - Once reduced\n",
    "## Removed all edge connections and add them where there are nodes forming communities\n",
    "myNeighborNetwork1.G = remove_intercommunity_edges(myNeighborNetwork1.G, commL1)\n",
    "## Plot\n",
    "myNeighborNetwork1.plot(title='5 Once Reduced - Louvain - seed {}'.format(seed), saveFig=True)\n",
    "\n",
    "# # Plot graph - Twice reduced\n",
    "## Removed inter-community connections\n",
    "myNeighborNetwork2.G = remove_intercommunity_edges(myNeighborNetwork2.G, commL2)\n",
    "## Plot\n",
    "myNeighborNetwork2.plot(title='6 Twice Reduced - Louvain - seed {}'.format(seed), saveFig=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e5a5d",
   "metadata": {},
   "source": [
    "# F07: Prepare For Analysis by Downloading Etopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create bathymetry object with body=... attributes\n",
    "# Try setting body='mars' | 'earth' | 'moon', 'Venus'\n",
    "body=\"Earth\"\n",
    "planetBathy = EC.Bathymetry.BathyMeasured(body=body)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory_name = os.getcwd()+\"/topographies/{}\".format(planetBathy.model)\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Download topography model (note that is must only be done once per body).\n",
    "# NOTE: UNCOMMENT THIS SECTION TO DOWNLOAD TOPOGRAPHY MODEL\n",
    "planetBathy.getTopo(os.getcwd(),\n",
    "                  verbose=True);\n",
    "\n",
    "# Read topography. This method will generate a topography model netCDF4 file with \n",
    "# new_resolution, in degrees. Note that the generated topography model will be \n",
    "# cell registered (All calculations from here on out are in cell registered to\n",
    "# simplify codes and reduce data loss on conversions).\n",
    "planetBathy.readTopo(os.getcwd(),\n",
    "                   new_resolution=1,\n",
    "                   verbose=False);\n",
    "\n",
    "# Generate a bathymetry model base on a set of input methods and properties. The setSeaLelvel\n",
    "# method has multiple ways to fill topography with oceans. The two currently implemented at\n",
    "# the time of this JN creation are as follows:\n",
    "#     1) basinVolume : An option to define bathymetry by flooding topography with\n",
    "#                      basinVolume['uncompactedVol'] amount of ocean water, in m3.\n",
    "#     2) OceanArea : Option to define bathymetry by flooding topography until\n",
    "#                    oceanArea['area'], decimal percent, of global area is covered\n",
    "#                    with oceans.\n",
    "# \n",
    "# Here, I use the OceanArea constraint and block the basinVolume constraint with comments.\n",
    "# \n",
    "planetBathy.setSeaLevel(basinVolume = {\"on\":False, 'uncompactedVol':None},\n",
    "                      oceanArea = {\"on\":True, \"area\":0.7},\n",
    "                      isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "# Note that in this basinVolume example the uncompactedVol was set to the oceanArea\n",
    "# bathymetry model's VOC, where oceanArea = {\"on\":True, \"area\":0.7}. \n",
    "#\n",
    "# planetBathy.setSeaLevel(basinVolume = {\"on\":True, 'uncompactedVol':3.299187952154623e+17},\n",
    "#                       oceanArea = {\"on\":False, \"area\":0.7},\n",
    "#                       isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "\n",
    "# Save bathymetry model as netCDF4. Note that models will be saved under the same root folder\n",
    "# that was supplied to the readTopo(...) method.\n",
    "# \n",
    "# only the bathymetry array is saved in this file. Other relevant values are represented\n",
    "# as vectors (e.g., lat, lon, area-weights, global bathymetery distributions, etc) or\n",
    "# attributes (e.g., VOC, AOC, high latitude cutoff, etc).\n",
    "# \n",
    "planetBathy.saveBathymetry()\n",
    "\n",
    "#\n",
    "# To see a full set of stored netCDF4 values, the user can uncomment the code below\n",
    "# \n",
    "# planetBathy.readBathymetry()\n",
    "# print(planetBathy.bathync)\n",
    "# print(planetBathy.bathync.variables)\n",
    "\n",
    "# Plot bathymetry model\n",
    "blues_cm = mpl.colormaps['Blues'].resampled(100)\n",
    "EC.plotHelper.plotGlobal(planetBathy.lat, planetBathy.lon, planetBathy.bathymetry,\n",
    "                    outputDir = planetBathy.data_dir+\"/bathymetries/{}\".format(planetBathy.model),\n",
    "                    fidName = \"{}-setSeaLevel_Area0p7.png\".format(planetBathy.model),\n",
    "                    cmapOpts={\"cmap\":blues_cm,\n",
    "                              \"cbar-title\":\"cbar-title\",\n",
    "                              \"cbar-range\":[np.nanmin(np.nanmin(planetBathy.bathymetry)),\n",
    "                                            np.nanmean(planetBathy.bathymetry)+2*np.nanstd(planetBathy.bathymetry)]},\n",
    "                    pltOpts={\"valueType\": \"Bathymetry\",\n",
    "                             \"valueUnits\": \"m\",\n",
    "                             \"plotTitle\":\"{}\".format(planetBathy.model),\n",
    "                             \"plotZeroContour\":True},\n",
    "                    savePNG = True)\n",
    "\n",
    "\n",
    "# Plot bathymetry model w/ bathymetry histograms\n",
    "EC.plotHelper.plotGlobalwHist(planetBathy.lat, planetBathy.lon, planetBathy.bathymetry,\n",
    "                        planetBathy.binEdges, planetBathy.bathymetryAreaDist_wHighlat, planetBathy.bathymetryAreaDist, planetBathy.highlatlat,\n",
    "                        outputDir = planetBathy.data_dir+\"/bathymetries/{}\".format(planetBathy.model),\n",
    "                        fidName = \"{}-setSeaLevel_Area0p7.png\".format(planetBathy.model),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[np.nanmin(np.nanmin(planetBathy.bathymetry)),\n",
    "                                                np.nanmean(planetBathy.bathymetry)+2*np.nanstd(planetBathy.bathymetry)]},\n",
    "                        pltOpts={\"valueType\": \"Bathymetry\",\n",
    "                                 \"valueUnits\": \"m\",\n",
    "                                 \"plotTitle\":\"{}\".format(planetBathy.model),\n",
    "                                 \"plotZeroContour\":True},\n",
    "                        savePNG = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2d09e",
   "metadata": {},
   "source": [
    "# F07: (Leiden Ensemble - Reduction On Etopo Bathymetry)\n",
    "\n",
    "Makes two subplots:\n",
    "- Etopo bathymetry map\n",
    "- Leiden detected communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a94678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = 'None'; # ['threshold'] = [0]\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":False,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results    \n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));\n",
    "\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fc0af",
   "metadata": {},
   "source": [
    "# F07: (Leiden Ensemble - Reduction and Girvan-Newman On Etopo Bathymetry)\n",
    "\n",
    "Makes two subplots:\n",
    "- Etopo bathymetry map\n",
    "- Leiden-Girvan-Newman detected communities\n",
    "\n",
    "Note that mergeSmallBasins is set to false, such that we can see the effect of Girvan-Newman mergers.\n",
    "- basins.detectionMethod[\"mergerPackage\"][\"mergeSmallBasins\"][\"on\"]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "    \n",
    "    # Make folder to hold figure results\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden-GirvanNewman')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    # Note that mergeSmallBasins is set to false, such that we can see\n",
    "    # the effect of Girvan-Newman mergers.\n",
    "    mergerPackage[\"mergeSmallBasins\"][\"on\"]=False\n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b46c9",
   "metadata": {},
   "source": [
    "# F07: (Leiden Ensemble - Reduction and Post-Processing (small basin merger) On Etopo Bathymetry)\n",
    "\n",
    "Makes two subplots:\n",
    "- Etopo bathymetry map\n",
    "- Leiden detected communities with merged small communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden-PP')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    \n",
    "    # Create node cluster\n",
    "    # Note that the small basin mergers are not inlcuded\n",
    "    # in the LGNClusters. Only large basin mergers such that\n",
    "    # small basin mergers results in X chosen basins.\n",
    "    LeidenClusters=NodeClustering(communities=basins.Rcommunities,\n",
    "                           graph=basins.G,\n",
    "                           method_name=\"consensus_ledien\",\n",
    "                           method_parameters={\n",
    "                               \"resolution_parameter\": resolution,\n",
    "                               \"runs\": ensembleSize,\n",
    "                               \"distance_threshold\": 0.3}\n",
    "                          )\n",
    "\n",
    "    LGNClusters=NodeClustering(communities=basins.communitiesFinal,\n",
    "                           graph=basins.G,\n",
    "                           method_name=\"consensus_ledien\",\n",
    "                           method_parameters={\n",
    "                               \"resolution_parameter\": resolution,\n",
    "                               \"runs\": ensembleSize,\n",
    "                               \"distance_threshold\": 0.3}\n",
    "                          )\n",
    "\n",
    "\n",
    "    # Calculate community detection metrics\n",
    "    for cluster, method in zip([LeidenClusters, LGNClusters], [\"LeidenClusters\", \"LGNClusters\"]):\n",
    "        newman_girvan_modularity = evaluation.newman_girvan_modularity(basins.G, cluster)\n",
    "        internal_edge_density = evaluation.internal_edge_density(basins.G, cluster)\n",
    "        erdos_renyi_modularity= evaluation.erdos_renyi_modularity(basins.G, cluster)\n",
    "        modularity_density    = evaluation.modularity_density(basins.G, cluster)\n",
    "        avg_embeddedness      = evaluation.avg_embeddedness(basins.G, cluster)\n",
    "        conductance           = evaluation.conductance(basins.G, cluster)\n",
    "        surprise              = evaluation.surprise(basins.G, cluster)\n",
    "\n",
    "        # Add community evaluation metrics to output\n",
    "        readmetxt += \"\\n\\nCommunity evaluation metrics ({}):\\n\".format(method);\n",
    "        readmetxt += \"newman_girvan_modularity:\\t {}\\n\".format(newman_girvan_modularity.score)\n",
    "        readmetxt += \"erdos_renyi_modularity:\\t\\t {}\\n\".format(erdos_renyi_modularity.score)\n",
    "        readmetxt += \"modularity_density:\\t\\t {}\\n\".format(modularity_density.score)\n",
    "        readmetxt += \"internal_edge_density:\\t\\t {} +- {} (std)\\n\".format(internal_edge_density.score, internal_edge_density.std)\n",
    "        readmetxt += \"avg_embeddedness:\\t\\t {} +- {} (std)\\n\".format(avg_embeddedness.score, avg_embeddedness.std)\n",
    "        readmetxt += \"conductance:\\t\\t\\t {} +- {} (std)\\n\".format(conductance.score, conductance.std)\n",
    "        readmetxt += \"surprise:\\t\\t\\t {}\\n\".format(surprise.score)\n",
    "        \n",
    "    \n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8be3d7",
   "metadata": {},
   "source": [
    "# F07: (Leiden Ensemble - Reduction, Girvan-Newman, and Post-Processing On Etopo Bathymetry)\n",
    "\n",
    "Makes two subplots:\n",
    "- Etopo bathymetry map\n",
    "- Leiden-Girvan-Newman detected communities with merged small communities\n",
    "\n",
    "Note that mergeSmallBasins is now always True, such that we can see the effect of Leiden-Girvan-Newman mergers plus the small basin mergers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden-GirvanNewman-PP')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd620a",
   "metadata": {},
   "source": [
    "# F07: Node locations for 1) Leiden Ensemble - Reduction and 2) Leiden Ensemble - Reduction and Girvan-Newman On Etopo Bathymetry\n",
    "\n",
    "Makes two subplots:\n",
    "- Node locations for initial global graph inputted into the Leiden Ensemble reduction step\n",
    "- Node locations for the reduced Leiden Ensemble community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node plot:\n",
    "#     1) Base 1 degree resolution\n",
    "#     2) Louvain community nodes (i.e., input to Girvan-Newman)\n",
    "#\n",
    "####################################################\n",
    "### Define functions for plotting graph networks ###\n",
    "####################################################\n",
    "def split_antimeridian_line(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Split a line crossing the antimeridian into two segments,\n",
    "    one in the eastern hemisphere and one in the western.\n",
    "\n",
    "    Returns:\n",
    "        western_segment: ((lon_a, lat_a), (lon_b, lat_b)) or None\n",
    "        eastern_segment: ((lon_c, lat_c), (lon_d, lat_d)) or None\n",
    "    \"\"\"\n",
    "    # Normalize longitudes to [-180, 180]\n",
    "    lon1 = (lon1 + 180) % 360 - 180\n",
    "    lon2 = (lon2 + 180) % 360 - 180\n",
    "\n",
    "    if abs(lon2 - lon1) <= 180:\n",
    "        # No crossing: return the full segment and None for the other\n",
    "        if lon1 < 0:\n",
    "            return ((lon1, lat1), (lon2, lat2)), None\n",
    "        else:\n",
    "            return None, ((lon1, lat1), (lon2, lat2))\n",
    "\n",
    "    # Antimeridian crossing\n",
    "    # Determine direction of crossing\n",
    "    if lon1 > lon2:\n",
    "        lon2 += 360\n",
    "    else:\n",
    "        lon1 += 360\n",
    "\n",
    "    # Interpolation factor for crossing at 180\n",
    "    frac = (180 - lon1) / (lon2 - lon1)\n",
    "    lat_mid = lat1 + frac * (lat2 - lat1)\n",
    "\n",
    "    # First segment: lon1 -> 180\n",
    "    western_segment = ((lon1, lat1), (180, lat_mid))\n",
    "    # Second segment: -180 -> lon2\n",
    "    eastern_segment = ((180, lat_mid), (lon2, lat2))\n",
    "\n",
    "    return western_segment, eastern_segment\n",
    "\n",
    "def plotNodes(G, latitude, longitude,\n",
    "              drawEdges=False, showSideEdges=True,\n",
    "              markersize =.3,\n",
    "              fidName='test.png', savePNG=False, saveSVG=False):\n",
    "    \n",
    "    # Imports\n",
    "    import cartopy.crs as ccrs # type: ignore\n",
    "    # Plot the network on a geographic map\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), subplot_kw={'projection': ccrs.Mollweide()})\n",
    "    ax.set_global()\n",
    "\n",
    "    # Draw the edges (connections)\n",
    "    if drawEdges:\n",
    "        for edge in G.edges(data=True):\n",
    "            node1, node2, weight = edge\n",
    "            lon1, lat1 = longitude[node1], latitude[node1]\n",
    "            lon2, lat2 = longitude[node2], latitude[node2]\n",
    "            cutoff = 90;\n",
    "            if ((lon2<-cutoff) & (lon1>cutoff)) | ((lon1<-cutoff) & (lon2>cutoff)):\n",
    "                # Node connection passes through antimeridian\n",
    "                if showSideEdges:\n",
    "                    #lats, lons = split_antimeridian([lon1, lon2], [lat1, lat2])\n",
    "                    segment1, segment2 = split_antimeridian_line(lon1, lat1, lon2, lat2)\n",
    "                    ax.plot([segment1[0][0],segment1[1][0]], [segment1[0][1],segment1[1][1]],\n",
    "                            'k-', linewidth=1, transform=ccrs.PlateCarree())\n",
    "                    ax.plot([segment2[0][0],segment2[1][0]], [segment2[0][1],segment2[1][1]],\n",
    "                            'k-', linewidth=1, transform=ccrs.PlateCarree())\n",
    "                pass\n",
    "            else:\n",
    "                # Node connection does not pass through antimeridian\n",
    "                ax.plot([lon1, lon2], [lat1, lat2], 'k-', linewidth=1, transform=ccrs.PlateCarree())\n",
    "            \n",
    "            \n",
    "    # Draw the nodes (points) on the map\n",
    "    ax.plot(longitude, latitude, 'ro', markersize=markersize, transform=ccrs.PlateCarree())  # longitude, latitude\n",
    "\n",
    "    # Add coastlines and gridlines\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "\n",
    "    #plt.title(\"Geographic Network of points\")\n",
    "    \n",
    "    # Save figure\n",
    "    if savePNG:\n",
    "        plt.savefig(fidName, dpi=600, transparent=True)\n",
    "    if saveSVG:\n",
    "        plt.savefig(fidName.replace(\".png\", \".svg\"))\n",
    "\n",
    "        \n",
    "######################################\n",
    "# Add details of community reduction #\n",
    "######################################\n",
    "        \n",
    "# Make folder to hold figure results\n",
    "fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden-GirvanNewman-PP-Nodes')\n",
    "print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "# Short readme text to write to folder with images\n",
    "readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "    \n",
    "with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "    text_file.write(readmetxt)\n",
    "\n",
    "###############################\n",
    "# 1) Base 1 degree resolution #\n",
    "###############################\n",
    "# Define node locations (latitude/longitude)\n",
    "baseNodesLat = np.array([],dtype=float);\n",
    "baseNodesLon = np.array([],dtype=float);\n",
    "for x in basins.G:\n",
    "    baseNodesLat = np.append(baseNodesLat, basins.G.nodes[x]['pos'][0])\n",
    "    baseNodesLon = np.append(baseNodesLon, basins.G.nodes[x]['pos'][1])\n",
    "\n",
    "\n",
    "plotNodes(basins.G, baseNodesLat, baseNodesLon,\n",
    "          drawEdges=False, showSideEdges=False,\n",
    "          fidName=fldName+'/BaseNodes.png',\n",
    "          savePNG=True)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# 2) Louvain community nodes (i.e., input to Girvan-Newman) #\n",
    "#############################################################\n",
    "import copy as cp\n",
    "LNodesLat = np.array([],dtype=float);\n",
    "LNodesLon = np.array([],dtype=float);\n",
    "\n",
    "for x in basins.Gnew:\n",
    "    # Set nodes idx that are compiled into new nodes for\n",
    "    # girvan-newman algorithm\n",
    "    nodesInGnew = np.array(list(basins.Rcommunities[x]), dtype=np.int32)\n",
    "    # Set average latitude and longitude of nodes in louvain community\n",
    "    cutoff = 90;\n",
    "    if (np.min(baseNodesLon[nodesInGnew])<-cutoff) & (np.max(baseNodesLon[nodesInGnew])>cutoff):\n",
    "        # At the -180,180 boundary find the mean latitude/longitude\n",
    "        # A mean is fine since nodes represent equal area quadrangles.\n",
    "        Lons = cp.deepcopy(baseNodesLon[nodesInGnew]);\n",
    "        Lons[Lons<0] += 360;\n",
    "        aveLon = np.mean(Lons)\n",
    "        if aveLon>180:\n",
    "            aveLon -=360;\n",
    "    else:\n",
    "        aveLon = np.mean(baseNodesLon[nodesInGnew])\n",
    "    \n",
    "    LNodesLat = np.append(LNodesLat, np.mean(baseNodesLat[nodesInGnew]) )\n",
    "    LNodesLon = np.append(LNodesLon, aveLon )\n",
    "\n",
    "\n",
    "#########################\n",
    "### Plot input fields ###\n",
    "#########################\n",
    "plotNodes(basins.Gnew, LNodesLat, LNodesLon,\n",
    "          drawEdges=True, showSideEdges=True,\n",
    "          markersize =3,\n",
    "          fidName=fldName+'/LeidenCommunityNodes.png',\n",
    "          savePNG=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a830808",
   "metadata": {},
   "source": [
    "# F05: Weight Construction Using the DQT-CDF Method\n",
    "\n",
    "This method is described in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#### Define functions to show weight scheme process ####\n",
    "########################################################\n",
    "# Scheme processes\n",
    "# 1. Create distribution of absolute value differences between adjacent node  \n",
    "# 2. Mirror distribition about 0 difference value (D)\n",
    "# 3. IQR filter to remove outliers (D_{filter})\n",
    "# 4. Normally distribute the using a data quantile transformation (D_{QT}) \n",
    "# 5. Construct shorten and shifted distribution and cumulative density function\n",
    "# 6. Plot everything to construct manuscript figure\n",
    "\n",
    "def createDataTreatmentFigures(basins, field,\n",
    "                               RawDiff=True, IQRFilter=True,  QT=True, QT2=True, QT_CDF=True, \n",
    "                               compiledFig=True,\n",
    "                               savePNG=False, saveSVG=False, directory=os.getcwd()):\n",
    "    \"\"\"\n",
    "    createDataTreatmentFigures create figures to\n",
    "    visualize the data treatment process in making\n",
    "    graph edge weights.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    RawDiff : BOOLEAN\n",
    "        Plot a distribution of the raw differences\n",
    "        between connected nodes within the graph.\n",
    "    IQRFilter : BOOLEAN\n",
    "        Plot a distribution of the IQR filtered\n",
    "        differences between connected nodes within\n",
    "        the graph.\n",
    "    QT : BOOLEAN\n",
    "        Plot a distribution of the IQR filtered\n",
    "        and QT distributed differences between\n",
    "        connected nodes within the graph.\n",
    "    QT2 : BOOLEAN\n",
    "        Similar to QT option.\n",
    "    QT_CDF : BOOLEAN\n",
    "        Plot a distribution of the QT distributed\n",
    "        differences between connected nodes within\n",
    "        the graph, with a overlay of the CDF function\n",
    "        used to determine node edge weights.\n",
    "    compiledFig : BOOLEAN\n",
    "        2x2 subplots of A) raw difference, B) IQR filtered\n",
    "        difference, C) DQT-IQR, D) Weight distributions with\n",
    "        CDF lines.\n",
    "    savePNG : BOOLEAN\n",
    "        An option to plot PNGs.\n",
    "    saveSVG : BOOLEAN\n",
    "        An option to plot SVGs.\n",
    "    directory : STRING\n",
    "        An output directory for the saved figures.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Set a directory / general name for figure naming convention.\n",
    "    fidName = basins.Fields[field]['parameterName']\n",
    "    \n",
    "    ###################################\n",
    "    ############# Imports #############\n",
    "    ###################################\n",
    "    from scipy.stats import norm\n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ########## Create figures #########\n",
    "    ###################################\n",
    "    if RawDiff:\n",
    "        # Define mirrored difference data\n",
    "        xValues = np.append(basins.Fields[field]['dataEdgeDiff'], -basins.Fields[field]['dataEdgeDiff'])\n",
    "        bins   = np.linspace(np.min(xValues), np.max(xValues), 20);\n",
    "        \n",
    "        # Plot subplot\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6.4, 4.8/2));\n",
    "\n",
    "        # Compare original vs QT \n",
    "        hist = plt.hist(xValues, alpha=.5, color='crimson', bins=bins, label='Raw Difference', density=True)\n",
    "        plt.vlines(x=[np.min(xValues), np.max(xValues)],\n",
    "                   ymin=0, ymax=np.max(hist[0]), colors='r', alpha=.2,\n",
    "                   label='Max difference')\n",
    "        \n",
    "        # Formatting\n",
    "        plt.ylabel(\"UnNormalized Distribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(\"Difference in Node Property\");\n",
    "        axes.spines['top'].set_visible(False)\n",
    "        axes.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"RawDiff_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"RawDiff_{}.svg\".format(fidName))\n",
    "        \n",
    "        \n",
    "    if IQRFilter:\n",
    "        # Define mirrored difference data\n",
    "        xValues = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'], -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "        bins   = np.linspace(np.min(xValues), np.max(xValues), 20);\n",
    "        \n",
    "        # Plot subplot\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6.4, 4.8/2));\n",
    "\n",
    "        # Compare original vs QT \n",
    "        hist = plt.hist(xValues, alpha=.5, color='crimson', bins=bins, label='IQR Filtered', density=True)\n",
    "        plt.vlines(x=[np.min(xValues), np.max(xValues)],\n",
    "                   ymin=0, ymax=np.max(hist[0]), colors='r', alpha=.2,\n",
    "                   label='Max difference')\n",
    "        \n",
    "        # Formatting\n",
    "        plt.ylabel(\"UnNormalized Distribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(\"Difference in Node Property\");\n",
    "        axes.spines['top'].set_visible(False)\n",
    "        axes.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"IQRFilter_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"IQRFilter_{}.svg\".format(fidName))\n",
    "\n",
    "        \n",
    "    if QT:\n",
    "        xValues = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'], -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "        basins.Fields[field]['weightMethodPara']['qt'] = \\\n",
    "        QuantileTransformer(n_quantiles=1000,\n",
    "                            random_state=0,\n",
    "                            output_distribution='normal')\n",
    "        qtDiss  = basins.Fields[field]['weightMethodPara']['qt'].fit_transform(np.reshape(xValues, (len(xValues),1)))\n",
    "\n",
    "        # Create a set of equal space values in the data domain\n",
    "        # These can be plotted on the gaussian domain to see the data stretching\n",
    "        bins   = np.linspace(np.min(xValues), np.max(xValues), 20);\n",
    "        binsqt = basins.Fields[field]['weightMethodPara']['qt'].transform(np.reshape(bins, (len(bins),1)))\n",
    "\n",
    "        # Plot subplot\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=1);\n",
    "        # QT distribution\n",
    "        plt.sca(axes[1])\n",
    "        plt.hist(qtDiss, alpha=.5, color='b', bins=np.arange(-6, 6, .1), label='IQR Filtered', density=True)\n",
    "        plt.vlines(x=binsqt, ymin=0, ymax=1.25, colors='r', alpha=.2)\n",
    "\n",
    "        # Compare original vs QT \n",
    "        plt.sca(axes[0])\n",
    "        hist = plt.hist(xValues, alpha=.5, color='crimson', bins=bins, label='IQR Filtered', density=True)\n",
    "        plt.vlines(x=bins, ymin=0, ymax=np.max(hist[0]), colors='r', alpha=.2)\n",
    "        qtxValues = basins.Fields[field]['weightMethodPara']['qt'].inverse_transform(qtDiss)\n",
    "        plt.hist(qtxValues, alpha=.5, color='b', bins=bins, label='QT to data', density=True);\n",
    "\n",
    "        plt.ylabel(\"UnNormalized Distribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.sca(axes[1])\n",
    "        plt.ylim([0,1.25])\n",
    "        plt.ylabel(\"Normalized Distribution\")\n",
    "        plt.xlabel(\"Difference in Node Property [{}/std]\".format(basins.Fields[field]['parameterUnit']));\n",
    "        \n",
    "        axes[0].spines['top'].set_visible(False)\n",
    "        axes[0].spines['right'].set_visible(False)\n",
    "        axes[0].spines['bottom'].set_visible(False)\n",
    "        \n",
    "        axes[1].spines['top'].set_visible(False)\n",
    "        axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "        \n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"QT_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"QT_{}.svg\".format(fidName))\n",
    "            \n",
    "    if QT2:\n",
    "        xValues = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'], -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "        basins.Fields[field]['weightMethodPara']['qt'] = \\\n",
    "        QuantileTransformer(n_quantiles=1000,\n",
    "                            random_state=0,\n",
    "                            output_distribution='normal')\n",
    "        qtDiss  = basins.Fields[field]['weightMethodPara']['qt'].fit_transform(np.reshape(xValues, (len(xValues),1)))\n",
    "\n",
    "        # Create a set of equal space values in the data domain\n",
    "        # These can be plotted on the gaussian domain to see the data stretching\n",
    "        bins   = np.linspace(np.min(xValues), np.max(xValues), 20);\n",
    "        binsqt = basins.Fields[field]['weightMethodPara']['qt'].transform(np.reshape(bins, (len(bins),1)))\n",
    "\n",
    "        # Plot subplot\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=1);\n",
    "        # QT distribution\n",
    "        plt.sca(axes[1])\n",
    "        plt.hist(qtDiss, alpha=.5, color='b', bins=np.arange(-6, 6, .1), label='DQT-IQR', density=True)\n",
    "        plt.vlines(x=binsqt, ymin=0, ymax=1.25, colors='r', alpha=.2)\n",
    "\n",
    "        # Compare original vs QT \n",
    "        plt.sca(axes[0])\n",
    "        hist = plt.hist(xValues, alpha=.5, color='crimson', bins=bins, label='IQR Filtered', density=True)\n",
    "        plt.vlines(x=bins, ymin=0, ymax=np.max(hist[0]), colors='r', alpha=.2)\n",
    "        qtxValues = basins.Fields[field]['weightMethodPara']['qt'].inverse_transform(qtDiss)\n",
    "        #plt.hist(qtxValues, alpha=.5, color='b', bins=bins, label='QT to data', density=True);\n",
    "\n",
    "        plt.ylabel(\"UnNormalized Distribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.sca(axes[1])\n",
    "        plt.legend();\n",
    "        plt.ylim([0,1.25])\n",
    "        plt.ylabel(\"Normalized Distribution\")\n",
    "        plt.xlabel(\"Difference in Node Property [{}/std]\".format(basins.Fields[field]['parameterUnit']));\n",
    "        \n",
    "        axes[0].spines['top'].set_visible(False)\n",
    "        axes[0].spines['right'].set_visible(False)\n",
    "        axes[0].spines['bottom'].set_visible(False)\n",
    "        \n",
    "        axes[1].spines['top'].set_visible(False)\n",
    "        axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "        \n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"QT_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"QT_{}.svg\".format(fidName))\n",
    "        \n",
    "        \n",
    "    if QT_CDF:\n",
    "        # Set data as IQRFiltered that is mirrored on the at dataEdgeDiffIQRFiltered=0\n",
    "        # (no difference in adjacent node values)\n",
    "        xValuesFiltered = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'],\n",
    "                                    -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "\n",
    "        # Create QT object and fit\n",
    "        qt = QuantileTransformer(n_quantiles=1000, random_state=0,  output_distribution='normal')\n",
    "        x  = qt.fit_transform(np.reshape(xValuesFiltered, (len(xValuesFiltered),1)))\n",
    "\n",
    "        # Use the QT to convert the xValuesFiltered difference data into z-score space. \n",
    "        xFiltered  = qt.fit_transform(np.reshape(xValuesFiltered, (len(xValuesFiltered),1)))\n",
    "\n",
    "        # Define the cumulative density function in the z-score space. \n",
    "        stretchFactor = 3;\n",
    "        qtDissSTD = 1\n",
    "        cdfCenter  = qtDissSTD*1\n",
    "        cdfStretch = qtDissSTD/stretchFactor\n",
    "        normCDF = 1-1*norm.cdf(xFiltered, loc=0, scale=cdfStretch)\n",
    "        normCDF2 = 1-1*norm.cdf(xFiltered, loc=0, scale=1)\n",
    "\n",
    "        distribution = norm.ppf(normCDF.T[0], loc=cdfCenter, scale=cdfStretch/stretchFactor)\n",
    "\n",
    "\n",
    "        ################################\n",
    "        ############# Plot #############\n",
    "        ################################\n",
    "        # Plot subplot\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6.4, 4.8/2));\n",
    "\n",
    "\n",
    "        \n",
    "        # QT distribution\n",
    "        plt.sca(axes)\n",
    "\n",
    "        plt.hist(xFiltered, alpha=.5, color='b', bins=np.arange(-6, 6, .1), label='DQT-IQR', density=True);\n",
    "        sorted_indices = np.argsort(normCDF2.T[0])\n",
    "        plt.plot(xFiltered[sorted_indices], normCDF2.T[0][sorted_indices], 'b-',  alpha=.5, label='1-CDF(DQT-IQR)');\n",
    "\n",
    "        minWeight = 0.01;\n",
    "        plt.hist(distribution, alpha=.5, color='r', bins=np.arange(-6, 6, .1), label='Shortened/Shifted', density=True);\n",
    "        sorted_indices = np.argsort( (normCDF.T[0]+minWeight)/(1+minWeight) )\n",
    "        plt.plot( (xFiltered+cdfCenter)[sorted_indices], ((normCDF.T[0]+minWeight)/(1+minWeight))[sorted_indices], 'r-',  alpha=.5,\n",
    "                 label='S = 1-CDF\\nshorten = $\\sigma/{}$\\nshift = $\\sigma$'.format(stretchFactor));\n",
    "\n",
    "        # Formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(r\"Difference in Node Property $[\\sigma]$\");\n",
    "        plt.ylabel(\"Normalized weight\")\n",
    "        plt.ylim([0,1.25])\n",
    "        axes.spines['top'].set_visible(False)\n",
    "        axes.spines['right'].set_visible(False)\n",
    "\n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"QT_CDF_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"QT_CDF_{}.svg\".format(fidName))\n",
    "            \n",
    "        \n",
    "    if compiledFig:\n",
    "        # 2x2 Subplots\n",
    "        # A) raw difference\n",
    "        # B) IQR filtered difference\n",
    "        # C) DQT-IQR\n",
    "        # D) Weight distributions with CDF lines.\n",
    "        \n",
    "        #############################\n",
    "        ####### Create figure #######\n",
    "        #############################\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8,5));\n",
    "        \n",
    "        \n",
    "        #########################\n",
    "        ####### Subplot 1 #######\n",
    "        #########################\n",
    "        # Set axis\n",
    "        plt.sca(axes[0][0])\n",
    "        \n",
    "        # Define mirrored difference data\n",
    "        rawDiff = np.append(basins.Fields[field]['dataEdgeDiff'], -basins.Fields[field]['dataEdgeDiff'])\n",
    "        bins   = np.linspace(np.min(rawDiff), np.max(rawDiff), 20);\n",
    "        \n",
    "        # Compare original vs QT \n",
    "        hist = plt.hist(rawDiff, alpha=.5, color='k', bins=bins, label='Raw Difference', density=True)\n",
    "        plt.vlines(x=[np.min(rawDiff), np.max(rawDiff)],\n",
    "                   ymin=0, ymax=np.max(hist[0]), colors='r', alpha=.5,\n",
    "                   label='Max difference')\n",
    "        \n",
    "        # Formatting\n",
    "        plt.ylabel(\"UnNormalized\\nDistribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(\"Difference in Node Property [m]\");\n",
    "        axes[0][0].spines['top'].set_visible(False)\n",
    "        axes[0][0].spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        \n",
    "        #########################\n",
    "        #### For subplot 2/3 ####\n",
    "        #########################\n",
    "        IQRFiltered = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'], -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "        basins.Fields[field]['weightMethodPara']['qt'] = \\\n",
    "        QuantileTransformer(n_quantiles=1000,\n",
    "                            random_state=0,\n",
    "                            output_distribution='normal')\n",
    "        qtDiss  = basins.Fields[field]['weightMethodPara']['qt'].fit_transform(np.reshape(IQRFiltered, (len(IQRFiltered),1)))\n",
    "\n",
    "        # Create a set of equal space values in the data domain\n",
    "        # These can be plotted on the gaussian domain to see the data stretching\n",
    "        bins   = np.linspace(np.min(IQRFiltered), np.max(IQRFiltered), 20);\n",
    "        binsqt = basins.Fields[field]['weightMethodPara']['qt'].transform(np.reshape(bins, (len(bins),1)))\n",
    "\n",
    "        #########################\n",
    "        ####### Subplot 2 #######\n",
    "        #########################\n",
    "        # Set axis\n",
    "        plt.sca(axes[0][1])\n",
    "        \n",
    "        # Define mirrored difference data\n",
    "        IQRFiltered = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'], -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "        bins   = np.linspace(np.min(IQRFiltered), np.max(IQRFiltered), 20);\n",
    "        \n",
    "        # Plot subplot\n",
    "        #fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6.4, 4.8/2));\n",
    "\n",
    "        # Compare original vs QT \n",
    "        hist = plt.hist(IQRFiltered, alpha=.5, color='orange', bins=bins, label='IQR Filtered', density=True)\n",
    "        plt.vlines(x=bins, ymin=0, ymax=np.max(hist[0]), colors='k', alpha=.5)\n",
    "        qtxValues = basins.Fields[field]['weightMethodPara']['qt'].inverse_transform(qtDiss)\n",
    "        \n",
    "        # Formatting\n",
    "        #axes[0][1].yaxis.set_label_position(\"right\")\n",
    "        #plt.ylabel(\"UnNormalized Distribution\")\n",
    "\n",
    "        # Plot formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(\"Difference in Node Property [m]\");\n",
    "        axes[0][1].spines['top'].set_visible(False)\n",
    "        axes[0][1].spines['left'].set_visible(False)\n",
    "        axes[0][1].spines['right'].set_visible(False)\n",
    "        \n",
    "        axes[0][1].set_yticks([])\n",
    "        \n",
    "        # Set subplot 1 ylim equal to subplot 2 ylim\n",
    "        ymin, ymax = axes[0][1].get_ylim()\n",
    "        axes[0][0].set_ylim(ymin=ymin, ymax=ymax)\n",
    "        \n",
    "        #########################\n",
    "        ####### Subplot 3 #######\n",
    "        #########################\n",
    "        # Set axis\n",
    "        plt.sca(axes[1][0])\n",
    "        \n",
    "        # QT distribution\n",
    "        plt.hist(qtDiss, alpha=.5, color='b', bins=np.arange(-6, 6, .1), label='DQT-IQR', density=True)\n",
    "        plt.vlines(x=binsqt, ymin=0, ymax=1.25, colors='k', alpha=.5)\n",
    "\n",
    "        # Plot formatting\n",
    "        #plt.legend();\n",
    "        plt.ylim([0,1.25])\n",
    "        plt.ylabel(\"Normalized Distribution\")\n",
    "        plt.xlabel(r\"Difference in Node Property $[\\sigma]$\");\n",
    "        \n",
    "        axes[1][0].spines['top'].set_visible(False)\n",
    "        axes[1][0].spines['right'].set_visible(False)\n",
    "        \n",
    "                \n",
    "        #########################\n",
    "        ####### Subplot 4 #######\n",
    "        #########################\n",
    "        # Set axis\n",
    "        plt.sca(axes[1][1])\n",
    "        \n",
    "        \n",
    "        # Set data as IQRFiltered that is mirrored on the at dataEdgeDiffIQRFiltered=0\n",
    "        # (no difference in adjacent node values)\n",
    "        IQRFiltered = np.append(basins.Fields[field]['dataEdgeDiffIQRFiltered'],\n",
    "                                -basins.Fields[field]['dataEdgeDiffIQRFiltered'])\n",
    "\n",
    "        # Create QT object and fit\n",
    "        qt = QuantileTransformer(n_quantiles=1000, random_state=0,  output_distribution='normal')\n",
    "        x  = qt.fit_transform(np.reshape(IQRFiltered, (len(IQRFiltered),1)))\n",
    "\n",
    "        # Use the QT to convert the xValuesFiltered difference data into z-score space. \n",
    "        xFiltered  = qt.fit_transform(np.reshape(IQRFiltered, (len(IQRFiltered),1)))\n",
    "\n",
    "        # Define the cumulative density function in the z-score space. \n",
    "        stretchFactor = 3;\n",
    "        qtDissSTD = 1\n",
    "        cdfCenter  = qtDissSTD*1\n",
    "        cdfStretch = qtDissSTD/stretchFactor\n",
    "        normCDF = 1-1*norm.cdf(xFiltered, loc=0, scale=cdfStretch)\n",
    "        normCDF2 = 1-1*norm.cdf(xFiltered, loc=0, scale=1)\n",
    "\n",
    "        distribution = norm.ppf(normCDF.T[0], loc=cdfCenter, scale=cdfStretch/stretchFactor)\n",
    "        \n",
    "        # Plot\n",
    "        plt.hist(xFiltered, alpha=.5, color='b', bins=np.arange(-6, 6, .1), label='DQT-IQR', density=True);\n",
    "        sorted_indices = np.argsort(normCDF2.T[0])\n",
    "        plt.plot(xFiltered[sorted_indices], normCDF2.T[0][sorted_indices], 'b-',  alpha=.5, label='1-CDF(DQT-IQR)');\n",
    "\n",
    "        minWeight = 0.01;\n",
    "        plt.hist(distribution, alpha=.5, color='r', bins=np.arange(-6, 6, .1), label='Shortened/Shifted', density=True);\n",
    "        sorted_indices = np.argsort( (normCDF.T[0]+minWeight)/(1+minWeight) )\n",
    "        plt.plot( (xFiltered+cdfCenter)[sorted_indices], ((normCDF.T[0]+minWeight)/(1+minWeight))[sorted_indices], 'r-',  alpha=.5,\n",
    "                 label='S = 1-CDF\\nshorten = $\\sigma/{}$\\nshift = $\\sigma$'.format(stretchFactor));\n",
    "\n",
    "        # Formatting\n",
    "        plt.legend();\n",
    "        plt.xlabel(r\"Difference in Node Property $[\\sigma]$\");\n",
    "        #plt.ylabel(\"Normalized weight\")\n",
    "        plt.ylim([0,1.25])\n",
    "        axes[1][1].spines['top'].set_visible(False)\n",
    "        axes[1][1].spines['right'].set_visible(False)\n",
    "        axes[1][1].spines['left'].set_visible(False)\n",
    "        \n",
    "        axes[1][1].set_yticks([])\n",
    "\n",
    "        # More formatting\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        if savePNG:\n",
    "            plt.savefig(directory+\"Compiled_{}.png\".format(fidName), dpi=600, transparent=True)\n",
    "        if saveSVG:\n",
    "            plt.savefig(directory+\"Compiled_{}.svg\".format(fidName))\n",
    "\n",
    "\n",
    "            \n",
    "#########################################\n",
    "#### Run functions to create figures ####\n",
    "#########################################\n",
    "# Create the directory if it doesn't exist\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/DQT-CDF-WeightingMethod\"\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Create figures using field 1 data (etopo bathymetry)\n",
    "field = 'Field1'\n",
    "createDataTreatmentFigures(basins, field,\n",
    "                           RawDiff=False, IQRFilter=False,  QT=False,\n",
    "                           QT2=False, QT_CDF=False, compiledFig=True,\n",
    "                           savePNG=True, saveSVG=True,\n",
    "                           directory=directory_name+\"/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92be29",
   "metadata": {},
   "source": [
    "# F10: Calculate metrics for Changing Gamma Resolution=[0.005-0.05] and Y Ensemble Size [1, 5, 10, 20, 30, 40, 50] For Community Detection Using Leiden Only Method\n",
    "\n",
    "Subplots (2): metrics of modularity and large basin count given resolution and ensemble size.\n",
    "\n",
    "Subplots (6): example maps of basins at 10, 30, 50 ensembles for 0.01 and .04 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11234b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Create nodeclustering object for community evaluation\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"None\"; # ['threshold'] = [0]\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, .04, 0.045, 0.05];\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [1, 5, 10, 20, 30, 40, 50];\n",
    "\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, int(ensembleSize), int(minBasinCnt))\n",
    "    \n",
    "# Make base directory\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/SensitivityMethodLeidenGammaEnsemble\"\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    # Change data type to avoid errors\n",
    "    minBasinCnt = int(minBasinCnt)\n",
    "    ensembleSize = int(ensembleSize)\n",
    "    \n",
    "    # Set detection method parameters\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":False,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    #    \"multiFieldMethod\" can be set to min, max, prod, mean.\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01,\n",
    "                       \"multiFieldMethod\":\"min\"}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/SensitivityMethodLeidenGammaEnsemble/Run')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a9f0f",
   "metadata": {},
   "source": [
    "# F06: Multi-field Weight Construction Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c410585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "\n",
    "# === Control font sizes here ===\n",
    "label_fontsize = 18\n",
    "annotation_fontsize = 14\n",
    "legend_fontsize = 14\n",
    "\n",
    "# 1. Create two distributions\n",
    "shortenFactor = 3\n",
    "shiftFactor = 1\n",
    "Field1Dis = np.random.normal(loc=shiftFactor, scale=1/shortenFactor, size=50000)\n",
    "Field2Dis = np.random.normal(loc=shiftFactor, scale=1/shortenFactor, size=50000)\n",
    "\n",
    "# 2. Create CDFs\n",
    "x1 = np.sort(Field1Dis)\n",
    "y1 = 1 - np.arange(1, len(x1)+1) / len(x1)\n",
    "\n",
    "x2 = np.sort(Field2Dis)\n",
    "y2 = 1 - np.arange(1, len(x2)+1) / len(x2)\n",
    "\n",
    "# 3. Plot CDFs\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "plt.plot(x1, y1, linestyle=(0, (4, 2)),  color='red', label='Field 1')\n",
    "plt.plot(x2, y2, linestyle=(3, (4, 2)), color='blue', label='Field 2')\n",
    "\n",
    "# 4. Points\n",
    "std_point1 = 1\n",
    "std_point2 = -0.5\n",
    "\n",
    "mean1, std1 = np.mean(Field1Dis), np.std(Field1Dis)\n",
    "mean2, std2 = np.mean(Field2Dis), np.std(Field2Dis)\n",
    "\n",
    "point1_x = mean1 + std_point1 * std1\n",
    "point2_x = mean2 + std_point2 * std2\n",
    "\n",
    "point1_y = 1 - np.searchsorted(x1, point1_x) / len(x1)\n",
    "point2_y = 1 - np.searchsorted(x2, point2_x) / len(x2)\n",
    "\n",
    "plt.scatter(point1_x, point1_y, color='red', s=80, zorder=5)\n",
    "plt.scatter(point2_x, point2_y, color='blue', s=80, zorder=5)\n",
    "\n",
    "weights = np.array([point1_y, point2_y])\n",
    "\n",
    "plt.hlines(np.min(weights), xmin=0, xmax=2.5, color='black', zorder=4)\n",
    "plt.hlines(np.max(weights), xmin=0, xmax=2.5, color='black', zorder=4)\n",
    "plt.hlines(np.mean(weights), xmin=0, xmax=2.5, color='black', zorder=4)\n",
    "plt.hlines(np.prod(weights), xmin=0, xmax=2.5, color='black', zorder=4)\n",
    "\n",
    "# Annotate\n",
    "plt.annotate(f'$S_{1}$', (point1_x, point1_y), textcoords=\"offset points\", xytext=(10,10), ha='left', color='red', fontsize=annotation_fontsize)\n",
    "plt.annotate(f'$S_{1}$', (point2_x, point2_y), textcoords=\"offset points\", xytext=(10,10), ha='left', color='blue', fontsize=annotation_fontsize)\n",
    "\n",
    "plt.annotate(f'Minimum ({np.min(weights):0.2f})',  (.1, np.min(weights)), textcoords=\"offset points\", xytext=(10,10), ha='left', fontsize=annotation_fontsize)\n",
    "plt.annotate(f'Maximum ({np.max(weights):0.2f})',  (.1, np.max(weights)), textcoords=\"offset points\", xytext=(10,10), ha='left', fontsize=annotation_fontsize)\n",
    "plt.annotate(f'Mean ({np.mean(weights):0.2f})',    (.1, np.mean(weights)), textcoords=\"offset points\", xytext=(10,10), ha='left', fontsize=annotation_fontsize)\n",
    "plt.annotate(f'Product ({np.prod(weights):0.2f})', (.1, np.prod(weights)), textcoords=\"offset points\", xytext=(10,-15), ha='left', fontsize=annotation_fontsize)\n",
    "\n",
    "# Formatting\n",
    "plt.xlim([0, 2])\n",
    "plt.xticks([0, 0.5, 1, 1.5, 2])\n",
    "plt.xlabel('Difference in Node Property [$\\\\sigma$]', fontsize=label_fontsize)\n",
    "plt.ylabel('1 - Cumulative Density Functions', fontsize=label_fontsize)\n",
    "plt.legend(fontsize=legend_fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Create directory for saving diagram\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/MultiFieldWeightDiagram\"\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(directory_name+\"/diagram.png\", dpi=600, transparent=True)\n",
    "plt.savefig(directory_name+\"/diagram.svg\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa066d",
   "metadata": {},
   "source": [
    "# F12: Multi-field Community Detection\n",
    "#### A-B): Surface Salinity and Temperature Fields (1998)\n",
    "#### C-D): Quantile input field for Surface Salinity and Temperature Fields \n",
    "#### E-F):  Community detection given DQT-CDF (shorten=XX, shifted=YY), Leiden Ensemble Algorithm (gamma=ZZ, ensembleSize=50), and post-process small basin merge with no Girvan-Newman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c897ce",
   "metadata": {},
   "source": [
    "#### F12: make surface(>200 m) / intermediate (>200 m, <1000 m) / deep (>1000 m) averaged and time averaged Salinity and Potential Temperature fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "############# Imports #############\n",
    "###################################\n",
    "import ExoCcycle as EC\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#########################################\n",
    "############# Define QT/CDF #############\n",
    "#########################################\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'so'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [1000,6000]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Deep Salinity\")\n",
    "\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'thetao'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [1000,6000]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Deep Temperature\")\n",
    "\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'so'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [200,1000]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Intermediate Salinity\")\n",
    "\n",
    "\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'thetao'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [200,1000]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Intermediate Temperature\")\n",
    "\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'so'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [0,200]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Shallow Salinity\")\n",
    "\n",
    "# Initialize object (Defaults to using 1994, bottomT data)\n",
    "dataType = 'thetao'\n",
    "options = {\"download\": False,\n",
    "           \"dataDir\":os.getcwd()+\"/GLORYS12V1\",\n",
    "           \"year\":[1994],\n",
    "           \"data\": dataType,\n",
    "           \"depthAve\": [0,200]}\n",
    "\n",
    "GLORYS12V1 = EC.utils.GLORYS12V1(options)\n",
    "\n",
    "# Average models all months in 1994\n",
    "GLORYS12V1.averageModels()\n",
    "print(\"Finished Shallow Temperature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f193ee",
   "metadata": {},
   "source": [
    "#### F12: Create community detection and field plots (A-F)\n",
    "\n",
    "Assign multiFieldMethod with 'min' and 'mean' to reproduce figure subplots from paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c921cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "\n",
    "# Create nodeclustering object for community evaluation\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#################################\n",
    "### User define fields to use ###\n",
    "#################################\n",
    "useTemp = True;\n",
    "useSalinity = True;\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "#mergerPackageName = \"None\"; # ['threshold'] = [0]\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01];\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "#ensembleSizes = [1, 5, 10, 20, 30, 40, 50];\n",
    "ensembleSizes = [50];\n",
    "\n",
    "# MultiField merger method\n",
    "# Can be set to \"min\", \"mean\", \"max\", \"prod\"\n",
    "# multiFieldMethod = \"mean\";\n",
    "multiFieldMethod = \"min\";\n",
    "\n",
    "\n",
    "# Define all depth ranges to calculate community division for\n",
    "# depthRanges = np.array([[0,200],[200,1000],[1000,6000]]);\n",
    "depthRanges = np.array([[0,200]]);\n",
    "\n",
    "# Define fields to detect communities on\n",
    "subfld = \"\"\n",
    "\n",
    "scalarValue1 =  \"so_average\"\n",
    "unit1 = \"PSU\"\n",
    "scalarValue2 = \"thetao_average\"\n",
    "unit2 = \"PotTemp\"\n",
    "\n",
    "# Short readme text to write to folder with images\n",
    "if useTemp & useSalinity:\n",
    "    usedFieldsStr = \"{}/{}\".format(unit1,unit2);\n",
    "    fieldNums = [\"Field2\", \"Field3\"]\n",
    "elif useSalinity:\n",
    "    usedFieldsStr = \"{}\".format(unit1);\n",
    "    fieldNums = [\"Field2\"]\n",
    "elif useTemp:\n",
    "    usedFieldsStr = \"{}\".format(unit2);\n",
    "    fieldNums = [\"Field3\"]\n",
    "\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):   \n",
    "    for i in range(depthRanges.shape[0]):\n",
    "        # Define ith depth range to evaluate\n",
    "        depthRange = depthRanges[i,:];\n",
    "        print(resolution, int(ensembleSize), int(minBasinCnt), multiFieldMethod, depthRange)\n",
    "    \n",
    "# Make base directory\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/GLORYS12V1-MultiField\"+subfld\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    for i in range(depthRanges.shape[0]):\n",
    "        # Define ith depth range to evaluate\n",
    "        depthRange = depthRanges[i,:];\n",
    "\n",
    "        # Change data type to avoid errors\n",
    "        minBasinCnt = int(minBasinCnt)\n",
    "        ensembleSize = int(ensembleSize)\n",
    "\n",
    "        # Set detection method parameters\n",
    "        detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                           \"resolution\":resolution,\n",
    "                           \"minBasinCnt\":minBasinCnt,\n",
    "                           \"ensembleSize\":ensembleSize,\n",
    "                           \"minBasinLargerThanSmallMergers\":False,\n",
    "                           \"mergerPackage\":mergerPackage,\n",
    "                           \"njobs\":4}\n",
    "\n",
    "        # Set the edge weight scheme for node connections\n",
    "        # Options:\n",
    "        #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "        #    \"multiFieldMethod\" can be set to min, max, prod, mean.\n",
    "        edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                           \"shortenFactor\": 3,\n",
    "                           \"shiftFactor\": 1,\n",
    "                           \"minWeight\": 0.01,\n",
    "                           \"multiFieldMethod\":multiFieldMethod}\n",
    "\n",
    "        # Make folder to hold figure results\n",
    "        fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/GLORYS12V1-MultiField{}/GLORYS12V1_1994_{}_{}'.format(subfld, usedFieldsStr.replace(\"/\", \"_\"), multiFieldMethod))\n",
    "        print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "        # Short readme text to write to folder with images\n",
    "        readmetxt = \"{} used to calculate basin boundaries.\".format(usedFieldsStr);\n",
    "        readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "        readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "        readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "        readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "        readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "        readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "        readmetxt += \"\\nMulti-field merger method {}\".format(edgeWeightMethod[\"multiFieldMethod\"])\n",
    "\n",
    "        #################################################################\n",
    "        ### Create basin object and set Field for Community detection ###\n",
    "        #################################################################\n",
    "\n",
    "        # Create basin object\n",
    "        body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "        body = body[0]\n",
    "        basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                                 filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                                 body=body);\n",
    "\n",
    "        # Define the equal area node options s.t. salinity is used for edge connections\n",
    "        basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                        dataGrid =  os.getcwd()+\"/GLORYS12V1/{0}_{1}_{2}m{3}.nc\".format(scalarValue1, depthRange[0], depthRange[1], subfld),\n",
    "                        parameter = \"z\",\n",
    "                        parameterUnit = unit1,\n",
    "                        parameterName = scalarValue1)\n",
    "        basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                        dataGrid =  os.getcwd()+\"/GLORYS12V1/{0}_{1}_{2}m{3}.nc\".format(scalarValue2, depthRange[0], depthRange[1], subfld),\n",
    "                        parameter = \"z\",\n",
    "                        parameterUnit = unit2,\n",
    "                        parameterName = scalarValue2)\n",
    "\n",
    "        # Assign fields to use in community detection\n",
    "        if useTemp & useSalinity:\n",
    "            basins.useFields(fieldList=np.array([\"Field2\",\"Field3\"]));\n",
    "        elif useSalinity:\n",
    "            basins.useFields(fieldList=np.array([\"Field2\"]));\n",
    "        elif useTemp:\n",
    "            basins.useFields(fieldList=np.array([\"Field3\"]));\n",
    "\n",
    "        # Show all fields stored in basins object\n",
    "        basins.getFields(usedFields = False)\n",
    "\n",
    "        # Show all fields stored in basins object that will be used\n",
    "        # for community detection.\n",
    "        basins.getFields(usedFields = True)\n",
    "        \n",
    "\n",
    "        #########################################\n",
    "        ### Run Community Detection Algorithm ###\n",
    "        #########################################\n",
    "\n",
    "        # Define basins based on user input boundaries.\n",
    "        # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "        # minBasinCnt refers to the number of basins to maintain that are\n",
    "        # not completely isolated after running the louvain algorithm.\n",
    "        basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                            edgeWeightMethod = edgeWeightMethod,\n",
    "                            reducedRes={\"on\":True,\"factor\":1},\n",
    "                            read=False,\n",
    "                            write=True,\n",
    "                            verbose=False)\n",
    "\n",
    "\n",
    "        # Merge communities based off criteria\n",
    "        # Note that etopo is used as a mask for merging small basins and\n",
    "        # plotting communities.\n",
    "        basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "        # Convert basinID equal area grid to regular grid\n",
    "        basins.interp2regularGrid(mask=True)\n",
    "\n",
    "        # Get small and large basins\n",
    "        percentThreshold = 0.5;\n",
    "        basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "\n",
    "        readmetxt += basinSizeDic[\"text\"]\n",
    "\n",
    "        # Get community detection metrics\n",
    "        metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                             resolution=resolution,\n",
    "                                                             ensembleSize=ensembleSize,\n",
    "                                                             distance_threshold=0.3)\n",
    "        readmetxt += (\"\\n\\n\" + metricText)\n",
    "        \n",
    "        ##################################\n",
    "        ### Calculate Silhouette field ###\n",
    "        ##################################\n",
    "        silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "        # Calculate area weighted average and standard deviation (for plotting)\n",
    "        areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                                  LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                                  LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "        ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "        aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "        print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "        readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        ### Report community evaluation metrics ###\n",
    "        ###########################################\n",
    "        with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "            text_file.write(readmetxt)\n",
    "            \n",
    "        #####################################\n",
    "        ### Plot results of community IDs ###\n",
    "        #####################################\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal.png\",\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(usedFieldsStr.replace(\"/\", \" & \")),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"mesh\":True,\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "        ##############################\n",
    "        ### Plot Silhouette fields ###\n",
    "        ##############################\n",
    "        EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1],\n",
    "                                      \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                     \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "        \n",
    "        #####################\n",
    "        ### Plot Salinity ###\n",
    "        #####################\n",
    "        if useSalinity:\n",
    "            # Write temp.nc that only has lat/lon/value\n",
    "            #basins.simplifyNetCDF(inputPath=basins.EAinputs['dataGrid'],\n",
    "            #                    outputPath='tempSimp.nc',\n",
    "            #                    parameter=basins.EAinputs['parameter'])\n",
    "            # Read netCDF4\n",
    "            nc = Dataset('tempSimp_{}.nc'.format(scalarValue1))\n",
    "            XX, YY = np.meshgrid(nc['lon'][:].data, nc['lat'][:].data)\n",
    "\n",
    "            # Calculate area weighted average and standard deviation (for plotting)\n",
    "            areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=np.diff(nc['lon'][:].data)[0],\n",
    "                                                                                                      LonStEd = [-180,180],\n",
    "                                                                                                      LatStEd = [-80-np.diff(nc['lon'][:].data)[0],90])\n",
    "            ave, std = EC.utils.weightedAvgAndStd(nc['z'][:].data, areaWeights)\n",
    "\n",
    "            # Plot PSU at depth interval\n",
    "            EC.plotHelper.plotGlobal(YY, XX, nc['z'][:].data,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_{0}_{1}m_{2}.png\".format(depthRange[0], depthRange[1], unit1),\n",
    "                                cmapOpts={\"cmap\":\"jet\",\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[ave-1*std,\n",
    "                                                        ave+1*std]},\n",
    "                                pltOpts={\"valueType\": \"{2} {0}-{1} m\".format(depthRange[0], depthRange[1], unit1),\n",
    "                                         \"valueUnits\": \"1e3\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "            nc.close()\n",
    "\n",
    "        ##################################\n",
    "        ### Plot Potential Temperature ###\n",
    "        ##################################\n",
    "        if useTemp:\n",
    "            # Write temp.nc that only has lat/lon/value\n",
    "            #basins.simplifyNetCDF(inputPath=basins.EAinputs['dataGrid'],\n",
    "            #                    outputPath='tempSimp.nc',\n",
    "            #                    parameter=basins.EAinputs['parameter'])\n",
    "            # Read netCDF4\n",
    "            nc = Dataset('tempSimp_{}.nc'.format(scalarValue2))\n",
    "            XX, YY = np.meshgrid(nc['lon'][:].data, nc['lat'][:].data)\n",
    "\n",
    "            # Calculate area weighted average and standard deviation (for plotting)\n",
    "            areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=np.diff(nc['lon'][:].data)[0],\n",
    "                                                                                                      LonStEd = [-180,180],\n",
    "                                                                                                      LatStEd = [-80-np.diff(nc['lon'][:].data)[0],90])\n",
    "            ave, std = EC.utils.weightedAvgAndStd(nc['z'][:].data, areaWeights)\n",
    "\n",
    "            # Plot PSU at depth interval\n",
    "            EC.plotHelper.plotGlobal(YY, XX, nc['z'][:].data,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_{0}_{1}m_{2}.png\".format(depthRange[0], depthRange[1], unit2),\n",
    "                                cmapOpts={\"cmap\":\"jet\",\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[ave-1*std,\n",
    "                                                        ave+1*std]},\n",
    "                                pltOpts={\"valueType\": \"{2} {0}-{1} m\".format(depthRange[0], depthRange[1], unit2),\n",
    "                                         \"valueUnits\": \"C\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "            nc.close()\n",
    "\n",
    "\n",
    "        ###########################\n",
    "        ### Plot DQT-CDF Values ###\n",
    "        ###########################\n",
    "        for fieldNum in fieldNums:\n",
    "            #####################################################\n",
    "            ####### Find average node neighbor difference #######\n",
    "            #####################################################\n",
    "            # Iterate over each node\n",
    "            attrs = None;\n",
    "            for node in basins.G.nodes:\n",
    "                # Average node connection difference for each node\n",
    "                temp = 0; cnt = 0;\n",
    "                for conNode in basins.G.neighbors(node):\n",
    "                    temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                    cnt+=1;\n",
    "                try:\n",
    "                    diffAve = temp/cnt; \n",
    "                except:\n",
    "                    # If node has no connections. This rarely happens.\n",
    "                    #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                    diffAve = 0\n",
    "                # Collect average node neighbor difference property\n",
    "                if attrs == None:\n",
    "                    attrs = {node: {\"diffAve\": diffAve}};\n",
    "                else:\n",
    "                    attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "            # Assign average node neighbor difference node property to graph\n",
    "            G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "            # List values\n",
    "            diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "            #####################################################\n",
    "            ################ Interpolate to grid ################\n",
    "            #####################################################\n",
    "            def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "                \"\"\"\n",
    "                interp2regularGrid method is used to interpolate data to\n",
    "                a regular grid given an input of irregular spaced data.\n",
    "\n",
    "                Parameters\n",
    "                -----------\n",
    "                dataIrregular : NUMPY ARRAY\n",
    "                    3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                    The default is None. This will make the function define the \n",
    "                    dataIrregular variable with basinIDs.\n",
    "                mask : STRING\n",
    "                    The path to a netCDF4 file that can be used to mask the result\n",
    "                    of interpolation. The default is None.\n",
    "\n",
    "                Returns\n",
    "                --------\n",
    "                array : NUMPY ARRAY\n",
    "                    A 2nxn array that hold node properties for each corresponding\n",
    "                    entry in basins.lat and basins.lon. \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                import copy as cp\n",
    "\n",
    "                # Get basin IDs from network object.\n",
    "                tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "                tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "                # Define an array to hold longitude, latitude, and basinID\n",
    "                dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "                # Iterate over all nodes so each node's longitude, latitude,\n",
    "                # and basinID can be added to the dataIrregular array.\n",
    "                for i in tmpValuesID:\n",
    "                    dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "                # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "                # on the surface of the a sphere (planet). \n",
    "                array = cp.deepcopy(basins.lat)\n",
    "\n",
    "                # Define a mapping function that maps node indecies on a irregular grid\n",
    "                # to those on the regular grid. This will speed up calculations if this\n",
    "                # function is called more than once.\n",
    "\n",
    "                # Iterate over all latitude and longitudes of the input grid.\n",
    "                for i in range(len(basins.lat[:,0])):\n",
    "                    for j in range(len(basins.lat[0,:])):\n",
    "                        # Find the distances from each regular grid point (i,j) to all\n",
    "                        # irregular grid points.\n",
    "                        x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                                lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                                radius=1)\n",
    "\n",
    "                        # Assign the nearest basin ID to element (i,j) \n",
    "                        array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "                ## Apply the mask\n",
    "                if mask:\n",
    "                    array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "                return array;\n",
    "\n",
    "            # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "            diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "            #####################################################\n",
    "            ####################### Plot ########################\n",
    "            #####################################################\n",
    "            # Transform using the QT\n",
    "            DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "            shape = np.shape(DQT_zscore)\n",
    "            DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "            DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "            DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "            DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "            DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "            # Plot using ExoCcycle plotGlobal function\n",
    "            EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[0,\n",
    "                                                        2]},\n",
    "                                pltOpts={\"valueType\": \"DQT\",\n",
    "                                         \"valueUnits\": \"zscore\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6787150",
   "metadata": {},
   "source": [
    "# F11: Community Detection throughout water column (Shallow/Intermediate/Deep): Potential temperature or Salinity\n",
    "\n",
    "Change useTemp, useSalinity, and communityDetectionMethod to produce basin detection at different water column depths, using either the temperature or salinity field with either the Leiden or Louvain detection method.\n",
    "\n",
    "Assign communityDetectionMethod to 'Leiden' and 'Louvain' to reproduce paper figure subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4798b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "\n",
    "# Create nodeclustering object for community evaluation\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#################################\n",
    "### User define fields to use ###\n",
    "#################################\n",
    "useTemp = True;\n",
    "useSalinity = False;\n",
    "# useTemp = False;\n",
    "# useSalinity = True;\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "# communityDetectionMethod = \"Leiden\"\n",
    "communityDetectionMethod = \"Louvain\"\n",
    "\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01];\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Define all depth ranges to calculate community division for\n",
    "depthRanges = np.array([[0,200],[200,1000],[1000,6000]]);\n",
    "\n",
    "# Define fields to detect communities on\n",
    "subfldPrefix = \"\"\n",
    "\n",
    "scalarValue1 =  \"so_average\"\n",
    "unit1 = \"PSU\"\n",
    "scalarValue2 = \"thetao_average\"\n",
    "unit2 = \"PotTemp\"\n",
    "\n",
    "# Short readme text to write to folder with images\n",
    "if useTemp & useSalinity:\n",
    "    usedFieldsStr = \"{}/{}\".format(unit1,unit2);\n",
    "    fieldNums = [\"Field2\", \"Field3\"]\n",
    "elif useSalinity:\n",
    "    usedFieldsStr = \"{}\".format(unit1);\n",
    "    fieldNums = [\"Field2\"]\n",
    "elif useTemp:\n",
    "    usedFieldsStr = \"{}\".format(unit2);\n",
    "    fieldNums = [\"Field3\"]\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):   \n",
    "    for i in range(depthRanges.shape[0]):\n",
    "        # Define ith depth range to evaluate\n",
    "        depthRange = depthRanges[i,:];\n",
    "        print(resolution, int(ensembleSize), int(minBasinCnt), depthRange)\n",
    "    \n",
    "# Make base directory\n",
    "subFolder = \"GLORYS12V1-WaterColumn{}/{}-{}\".format(subfldPrefix, communityDetectionMethod, usedFieldsStr.replace(\"/\",\"_\"))\n",
    "directory_name = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/\"+subFolder\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    for i in range(depthRanges.shape[0]):\n",
    "        # Define ith depth range to evaluate\n",
    "        depthRange = depthRanges[i,:];\n",
    "\n",
    "        # Change data type to avoid errors\n",
    "        minBasinCnt = int(minBasinCnt)\n",
    "        ensembleSize = int(ensembleSize)\n",
    "\n",
    "        # Set detection method parameters\n",
    "        detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                           \"resolution\":resolution,\n",
    "                           \"minBasinCnt\":minBasinCnt,\n",
    "                           \"ensembleSize\":ensembleSize,\n",
    "                           \"minBasinLargerThanSmallMergers\":False,\n",
    "                           \"mergerPackage\":mergerPackage}\n",
    "\n",
    "        # Set the edge weight scheme for node connections\n",
    "        # Options:\n",
    "        #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "        #    \"multiFieldMethod\" can be set to min, max, prod, mean.\n",
    "        edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                           \"shortenFactor\": 3,\n",
    "                           \"shiftFactor\": 1,\n",
    "                           \"minWeight\": 0.01,\n",
    "                           \"multiFieldMethod\":\"max\"}\n",
    "\n",
    "        # Make folder to hold figure results\n",
    "        !mkdir -p figures/GMD_Manuscript/CodeOutputs/GLORYS12V1-MultiField\n",
    "        fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/{0}/GLORYS12V1_1994_{1}'.format(subFolder, usedFieldsStr.replace(\"/\", \"_\")))\n",
    "        print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "        # Short readme text to write to folder with images\n",
    "        readmetxt = \"{} used to calculate basin boundaries.\".format(usedFieldsStr);\n",
    "        readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "        readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "        readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "        readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "        readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "        readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "        #################################################################\n",
    "        ### Create basin object and set Field for Community detection ###\n",
    "        #################################################################\n",
    "\n",
    "        # Create basin object\n",
    "        body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "        body = body[0]\n",
    "        basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                                 filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                                 body=body);\n",
    "\n",
    "        # Define the equal area node options s.t. salinity is used for edge connections\n",
    "        basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                        dataGrid =  os.getcwd()+\"/GLORYS12V1/{0}_{1}_{2}m{3}.nc\".format(scalarValue1, depthRange[0], depthRange[1], subfldPrefix),\n",
    "                        parameter = \"z\",\n",
    "                        parameterUnit = unit1,\n",
    "                        parameterName = scalarValue1)\n",
    "        basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                        dataGrid =  os.getcwd()+\"/GLORYS12V1/{0}_{1}_{2}m{3}.nc\".format(scalarValue2, depthRange[0], depthRange[1], subfldPrefix),\n",
    "                        parameter = \"z\",\n",
    "                        parameterUnit = unit2,\n",
    "                        parameterName = scalarValue2)\n",
    "\n",
    "        # Assign fields to use in community detection\n",
    "        if useTemp & useSalinity:\n",
    "            basins.useFields(fieldList=np.array([\"Field2\",\"Field3\"]));\n",
    "        elif useSalinity:\n",
    "            basins.useFields(fieldList=np.array([\"Field2\"]));\n",
    "        elif useTemp:\n",
    "            basins.useFields(fieldList=np.array([\"Field3\"]));\n",
    "\n",
    "        # Show all fields stored in basins object\n",
    "        basins.getFields(usedFields = False)\n",
    "\n",
    "        # Show all fields stored in basins object that will be used\n",
    "        # for community detection.\n",
    "        basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "        #########################################\n",
    "        ### Run Community Detection Algorithm ###\n",
    "        #########################################\n",
    "\n",
    "        # Define basins based on user input boundaries.\n",
    "        # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "        # minBasinCnt refers to the number of basins to maintain that are\n",
    "        # not completely isolated after running the louvain algorithm.\n",
    "        basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                            edgeWeightMethod = edgeWeightMethod,\n",
    "                            reducedRes={\"on\":True,\"factor\":1},\n",
    "                            read=False,\n",
    "                            write=True,\n",
    "                            verbose=False)\n",
    "\n",
    "\n",
    "        # Merge communities based off criteria \n",
    "        basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "        # Convert basinID equal area grid to regular grid\n",
    "        basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "        # Get small and large basins\n",
    "        percentThreshold = 0.5;\n",
    "        basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "\n",
    "        readmetxt += basinSizeDic[\"text\"]\n",
    "\n",
    "        # Get community detection metrics\n",
    "        metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                             resolution=resolution,\n",
    "                                                             ensembleSize=ensembleSize,\n",
    "                                                             distance_threshold=0.3)\n",
    "        readmetxt += (\"\\n\\n\" + metricText)\n",
    "        \n",
    "        ##################################\n",
    "        ### Calculate Silhouette field ###\n",
    "        ##################################\n",
    "        silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "        # Calculate area weighted average and standard deviation (for plotting)\n",
    "        areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                                  LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                                  LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "        ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "        aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "        print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "        readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        ### Report community evaluation metrics ###\n",
    "        ###########################################\n",
    "        with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "            text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "        #####################################\n",
    "        ### Plot results of community IDs ###\n",
    "        #####################################\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal.png\",\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(usedFieldsStr),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"mesh\":True,\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_Contour.png\",\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(usedFieldsStr),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"mesh\":False,\n",
    "                                     \"coastlines\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "        \n",
    "        ##############################\n",
    "        ### Plot Silhouette fields ###\n",
    "        ##############################\n",
    "        EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1],\n",
    "                                      \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                     \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        #####################\n",
    "        ### Plot Salinity ###\n",
    "        #####################\n",
    "        if useSalinity:\n",
    "            # Read netCDF4\n",
    "            nc = Dataset('tempSimp_{}.nc'.format(scalarValue1))\n",
    "            XX, YY = np.meshgrid(nc['lon'][:].data, nc['lat'][:].data)\n",
    "\n",
    "            # Calculate area weighted average and standard deviation (for plotting)\n",
    "            areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=np.diff(nc['lon'][:].data)[0],\n",
    "                                                                                                      LonStEd = [-180,180],\n",
    "                                                                                                      LatStEd = [-80-np.diff(nc['lon'][:].data)[0],90])\n",
    "            ave, std = EC.utils.weightedAvgAndStd(nc['z'][:].data, areaWeights)\n",
    "\n",
    "            # Plot PSU at depth interval\n",
    "            EC.plotHelper.plotGlobal(YY, XX, nc['z'][:].data,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_{0}_{1}m_{2}.png\".format(depthRange[0], depthRange[1], unit1),\n",
    "                                cmapOpts={\"cmap\":\"jet\",\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[ave-1*std,\n",
    "                                                        ave+1*std]},\n",
    "                                pltOpts={\"valueType\": \"{2} {0}-{1} m\".format(depthRange[0], depthRange[1], unit1),\n",
    "                                         \"valueUnits\": \"1e3\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "            nc.close()\n",
    "\n",
    "        ##################################\n",
    "        ### Plot Potential Temperature ###\n",
    "        ##################################\n",
    "        if useTemp:\n",
    "            # Read netCDF4\n",
    "            nc = Dataset('tempSimp_{}.nc'.format(scalarValue2))\n",
    "            XX, YY = np.meshgrid(nc['lon'][:].data, nc['lat'][:].data)\n",
    "\n",
    "            # Calculate area weighted average and standard deviation (for plotting)\n",
    "            areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=np.diff(nc['lon'][:].data)[0],\n",
    "                                                                                                      LonStEd = [-180,180],\n",
    "                                                                                                      LatStEd = [-80-np.diff(nc['lon'][:].data)[0],90])\n",
    "            ave, std = EC.utils.weightedAvgAndStd(nc['z'][:].data, areaWeights)\n",
    "\n",
    "            # Plot PSU at depth interval\n",
    "            EC.plotHelper.plotGlobal(YY, XX, nc['z'][:].data,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_{0}_{1}m_{2}.png\".format(depthRange[0], depthRange[1], unit2),\n",
    "                                cmapOpts={\"cmap\":\"jet\",\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[ave-1*std,\n",
    "                                                        ave+1*std]},\n",
    "                                pltOpts={\"valueType\": \"{2} {0}-{1} m\".format(depthRange[0], depthRange[1], unit2),\n",
    "                                         \"valueUnits\": \"C\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "            nc.close()\n",
    "\n",
    "\n",
    "        ###########################\n",
    "        ### Plot DQT-CDF Values ###\n",
    "        ###########################\n",
    "        for fieldNum in fieldNums:\n",
    "            #####################################################\n",
    "            ####### Find average node neighbor difference #######\n",
    "            #####################################################\n",
    "            # Iterate over each node\n",
    "            attrs = None;\n",
    "            for node in basins.G.nodes:\n",
    "                # Average node connection difference for each node\n",
    "                temp = 0; cnt = 0;\n",
    "                for conNode in basins.G.neighbors(node):\n",
    "                    temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                    cnt+=1;\n",
    "                try:\n",
    "                    diffAve = temp/cnt; \n",
    "                except:\n",
    "                    # If node has no connections. This rarely happens.\n",
    "                    #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                    diffAve = 0\n",
    "                # Collect average node neighbor difference property\n",
    "                if attrs == None:\n",
    "                    attrs = {node: {\"diffAve\": diffAve}};\n",
    "                else:\n",
    "                    attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "            # Assign average node neighbor difference node property to graph\n",
    "            G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "            # List values\n",
    "            diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "            #####################################################\n",
    "            ################ Interpolate to grid ################\n",
    "            #####################################################\n",
    "            def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "                \"\"\"\n",
    "                interp2regularGrid method is used to interpolate data to\n",
    "                a regular grid given an input of irregular spaced data.\n",
    "\n",
    "                Parameters\n",
    "                -----------\n",
    "                dataIrregular : NUMPY ARRAY\n",
    "                    3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                    The default is None. This will make the function define the \n",
    "                    dataIrregular variable with basinIDs.\n",
    "                mask : STRING\n",
    "                    The path to a netCDF4 file that can be used to mask the result\n",
    "                    of interpolation. The default is None.\n",
    "\n",
    "                Returns\n",
    "                --------\n",
    "                array : NUMPY ARRAY\n",
    "                    A 2nxn array that hold node properties for each corresponding\n",
    "                    entry in basins.lat and basins.lon. \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                import copy as cp\n",
    "\n",
    "                # Get basin IDs from network object.\n",
    "                tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "                tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "                # Define an array to hold longitude, latitude, and basinID\n",
    "                dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "                # Iterate over all nodes so each node's longitude, latitude,\n",
    "                # and basinID can be added to the dataIrregular array.\n",
    "                for i in tmpValuesID:\n",
    "                    dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "                # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "                # on the surface of the a sphere (planet). \n",
    "                array = cp.deepcopy(basins.lat)\n",
    "\n",
    "                # Define a mapping function that maps node indecies on a irregular grid\n",
    "                # to those on the regular grid. This will speed up calculations if this\n",
    "                # function is called more than once.\n",
    "\n",
    "                # Iterate over all latitude and longitudes of the input grid.\n",
    "                for i in range(len(basins.lat[:,0])):\n",
    "                    for j in range(len(basins.lat[0,:])):\n",
    "                        # Find the distances from each regular grid point (i,j) to all\n",
    "                        # irregular grid points.\n",
    "                        x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                                lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                                radius=1)\n",
    "\n",
    "                        # Assign the nearest basin ID to element (i,j) \n",
    "                        array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "                ## Apply the mask\n",
    "                if mask:\n",
    "                    array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "                return array;\n",
    "\n",
    "            # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "            diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "            #####################################################\n",
    "            ####################### Plot ########################\n",
    "            #####################################################\n",
    "            # Transform using the QT\n",
    "            DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "            shape = np.shape(DQT_zscore)\n",
    "            DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "            DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "            DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "            DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "            DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "            # Plot using ExoCcycle plotGlobal function\n",
    "            EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[0,\n",
    "                                                        2]},\n",
    "                                pltOpts={\"valueType\": \"DQT\",\n",
    "                                         \"valueUnits\": \"zscore\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "            \n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        # Same as above except plots the weight values\n",
    "        # excluding the distance dependence between nodes.\n",
    "        # However, this should be negligible.\n",
    "        def complementCDF(diff,\n",
    "                          transformer,\n",
    "                          std,\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight']):\n",
    "            \"\"\"\n",
    "            complementCDF is function used to calculate the weight of a node\n",
    "            pair connection given the following inputs.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            diff : FLOAT\n",
    "                A node pair difference value from field of data.\n",
    "            transformer : OBJECT\n",
    "                Quantile transformation that is used to convert diff\n",
    "                input into z-score value.\n",
    "            std : FLAOT\n",
    "                Standard devitaion of total field data input after\n",
    "                being quantile transformed (i.e., this value should\n",
    "                be ~0). \n",
    "            shortenFactor : FLOAT\n",
    "                Factor to shorten CDF distribution by.\n",
    "            shiftFactor : FLOAT\n",
    "                Factor to shift CDF distribution by.\n",
    "            minWeight : FLOAT\n",
    "                A value between 0 and 1 that determines the minimum\n",
    "                weight to assign to a diff value. \n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            node pair edge weight(s)\n",
    "\n",
    "            \"\"\"\n",
    "            from scipy import stats\n",
    "            # Transform from diff-space to gaussian-space\n",
    "            if len(diff) == 1:\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "            else:\n",
    "                shape = np.shape(diff)\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "                QTGdiff = np.reshape(QTGdiff, shape);\n",
    "            # Get probablity in stretched distribution\n",
    "            cdfCenter  = std*shiftFactor\n",
    "            cdfStretch = std/shortenFactor\n",
    "            CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "            # Divide by probablity in normal distribution. This\n",
    "            # scales probablility between 0-1.\n",
    "            # Note that:\n",
    "            #   S->1 for |value1 - value2|-> 0   and\n",
    "            #   S->0 for |value1 - value2|-> inf\n",
    "            Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "            return Ss\n",
    "        \n",
    "        Ss= complementCDF(diffAveGrd,\n",
    "                          transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                          std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"Weights\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ad3f7",
   "metadata": {},
   "source": [
    "# F14: Community Detection of etopo (resolution tests) 1, 2, 4, 8 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f2ffb",
   "metadata": {},
   "source": [
    "#### Create different resolution sampled etopo grids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "spatialResolutions = [1, 2, 4, 8];\n",
    "\n",
    "for resolution in spatialResolutions:\n",
    "    # Create bathymetry object with body=... attributes\n",
    "    # Try setting body='mars' | 'earth' | 'moon', 'Venus'\n",
    "    body=\"Earth\"\n",
    "    planetBathy = EC.Bathymetry.BathyMeasured(body=body)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory_name = os.getcwd()+\"/topographies/{}\".format(planetBathy.model)\n",
    "    os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "    # Download topography model (note that is must only be done once per body).\n",
    "    # NOTE: UNCOMMENT THIS SECTION TO DOWNLOAD TOPOGRAPHY MODEL\n",
    "    planetBathy.getTopo(os.getcwd(),\n",
    "                      verbose=True);\n",
    "\n",
    "    # Read topography. This method will generate a topography model netCDF4 file with \n",
    "    # new_resolution, in degrees. Note that the generated topography model will be \n",
    "    # cell registered (All calculations from here on out are in cell registered to\n",
    "    # simplify codes and reduce data loss on conversions).\n",
    "    planetBathy.readTopo(os.getcwd(),\n",
    "                       new_resolution=resolution,\n",
    "                       verbose=False);\n",
    "\n",
    "    # Generate a bathymetry model base on a set of input methods and properties. The setSeaLelvel\n",
    "    # method has multiple ways to fill topography with oceans. The two currently implemented at\n",
    "    # the time of this JN creation are as follows:\n",
    "    #     1) basinVolume : An option to define bathymetry by flooding topography with\n",
    "    #                      basinVolume['uncompactedVol'] amount of ocean water, in m3.\n",
    "    #     2) OceanArea : Option to define bathymetry by flooding topography until\n",
    "    #                    oceanArea['area'], decimal percent, of global area is covered\n",
    "    #                    with oceans.\n",
    "    # \n",
    "    # Here, I use the OceanArea constraint and block the basinVolume constraint with comments.\n",
    "    # \n",
    "    planetBathy.setSeaLevel(basinVolume = {\"on\":False, 'uncompactedVol':None},\n",
    "                          oceanArea = {\"on\":True, \"area\":0.7},\n",
    "                          isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "    # Note that in this basinVolume example the uncompactedVol was set to the oceanArea\n",
    "    # bathymetry model's VOC, where oceanArea = {\"on\":True, \"area\":0.7}. \n",
    "    #\n",
    "    # planetBathy.setSeaLevel(basinVolume = {\"on\":True, 'uncompactedVol':3.299187952154623e+17},\n",
    "    #                       oceanArea = {\"on\":False, \"area\":0.7},\n",
    "    #                       isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "\n",
    "    # Save bathymetry model as netCDF4. Note that models will be saved under the same root folder\n",
    "    # that was supplied to the readTopo(...) method.\n",
    "    # \n",
    "    # only the bathymetry array is saved in this file. Other relevant values are represented\n",
    "    # as vectors (e.g., lat, lon, area-weights, global bathymetery distributions, etc) or\n",
    "    # attributes (e.g., VOC, AOC, high latitude cutoff, etc).\n",
    "    # \n",
    "    planetBathy.saveBathymetry()\n",
    "\n",
    "    #\n",
    "    # To see a full set of stored netCDF4 values, the user can uncomment the code below\n",
    "    # \n",
    "    # planetBathy.readBathymetry()\n",
    "    # print(planetBathy.bathync)\n",
    "    # print(planetBathy.bathync.variables)\n",
    "\n",
    "    # Plot bathymetry model\n",
    "    plotRange = [np.nanmin(np.nanmin(planetBathy.bathymetry)), np.nanmean(planetBathy.bathymetry)+2*np.nanstd(planetBathy.bathymetry)]\n",
    "    plotRange = [0, 6000];\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(100)\n",
    "    EC.plotHelper.plotGlobal(planetBathy.lat, planetBathy.lon, planetBathy.bathymetry,\n",
    "                        outputDir = planetBathy.data_dir+\"/bathymetries/{}\".format(planetBathy.model),\n",
    "                        fidName = \"{}-setSeaLevel_Area0p7-resolution_{}deg.png\".format(planetBathy.model, resolution),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"Bathymetry\",\n",
    "                                 \"valueUnits\": \"m\",\n",
    "                                 \"plotTitle\":\"{}\".format(planetBathy.model),\n",
    "                                 \"plotZeroContour\":True},\n",
    "                        savePNG = True)\n",
    "\n",
    "\n",
    "    # # Plot bathymetry model w/ bathymetry histograms\n",
    "    # EC.plotHelper.plotGlobalwHist(planetBathy.lat, planetBathy.lon, planetBathy.bathymetry,\n",
    "    #                         planetBathy.binEdges, planetBathy.bathymetryAreaDist_wHighlat, planetBathy.bathymetryAreaDist, planetBathy.highlatlat,\n",
    "    #                         outputDir = planetBathy.data_dir+\"/bathymetries/{}\".format(planetBathy.model),\n",
    "    #                         fidName = \"{}-setSeaLevel_Area0p7.png\".format(planetBathy.model),\n",
    "    #                         cmapOpts={\"cmap\":blues_cm,\n",
    "    #                                   \"cbar-title\":\"cbar-title\",\n",
    "    #                                   \"cbar-range\":[np.nanmin(np.nanmin(planetBathy.bathymetry)),\n",
    "    #                                                 np.nanmean(planetBathy.bathymetry)+2*np.nanstd(planetBathy.bathymetry)]},\n",
    "    #                         pltOpts={\"valueType\": \"Bathymetry\",\n",
    "    #                                  \"valueUnits\": \"m\",\n",
    "    #                                  \"plotTitle\":\"{}\".format(planetBathy.model),\n",
    "    #                                  \"plotZeroContour\":True},\n",
    "    #                         savePNG = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66045e",
   "metadata": {},
   "source": [
    "#### Run community detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91368ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "import itertools\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "# Set of spatial resolutions to calculate basin for\n",
    "spatialResolutions = [8, 4, 2, 1];\n",
    "#spatialResolutions = [1];\n",
    "\n",
    "# Define fields to plot weights for. Note that weights must be calculated\n",
    "# for these fields.\n",
    "fieldNums = [\"Field1\"]\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    print(resolution, ensembleSize, minBasinCnt, spatialResolution)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    # Change data type to avoid errors\n",
    "    spatialResolution = int(spatialResolution)\n",
    "    minBasinCnt = int(minBasinCnt)\n",
    "    ensembleSize = int(ensembleSize)\n",
    "    \n",
    "    # Set detection method\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/SpatialResolutionTests\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/SpatialResolutionTests/{}-PP'.format(communityDetectionMethod))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_{:0.1f}deg.nc\".format(body, spatialResolution),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "        \n",
    "        \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "#     areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "#                                                                                               LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "#                                                                                               LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    ### Plot DQT-CDF Values ###\n",
    "    ###########################\n",
    "    for fieldNum in fieldNums:\n",
    "        #####################################################\n",
    "        ####### Find average node neighbor difference #######\n",
    "        #####################################################\n",
    "        # Iterate over each node\n",
    "        attrs = None;\n",
    "        for node in basins.G.nodes:\n",
    "            # Average node connection difference for each node\n",
    "            temp = 0; cnt = 0;\n",
    "            for conNode in basins.G.neighbors(node):\n",
    "                temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                cnt+=1;\n",
    "            try:\n",
    "                diffAve = temp/cnt; \n",
    "            except:\n",
    "                # If node has no connections. This rarely happens.\n",
    "                #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                diffAve = 0\n",
    "            # Collect average node neighbor difference property\n",
    "            if attrs == None:\n",
    "                attrs = {node: {\"diffAve\": diffAve}};\n",
    "            else:\n",
    "                attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "        # Assign average node neighbor difference node property to graph\n",
    "        G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "        # List values\n",
    "        diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "        #####################################################\n",
    "        ################ Interpolate to grid ################\n",
    "        #####################################################\n",
    "        def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "            \"\"\"\n",
    "            interp2regularGrid method is used to interpolate data to\n",
    "            a regular grid given an input of irregular spaced data.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            dataIrregular : NUMPY ARRAY\n",
    "                3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                The default is None. This will make the function define the \n",
    "                dataIrregular variable with basinIDs.\n",
    "            mask : STRING\n",
    "                The path to a netCDF4 file that can be used to mask the result\n",
    "                of interpolation. The default is None.\n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            array : NUMPY ARRAY\n",
    "                A 2nxn array that hold node properties for each corresponding\n",
    "                entry in basins.lat and basins.lon. \n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            import copy as cp\n",
    "\n",
    "            # Get basin IDs from network object.\n",
    "            tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "            tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "            # Define an array to hold longitude, latitude, and basinID\n",
    "            dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "            # Iterate over all nodes so each node's longitude, latitude,\n",
    "            # and basinID can be added to the dataIrregular array.\n",
    "            for i in tmpValuesID:\n",
    "                dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "            # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "            # on the surface of the a sphere (planet). \n",
    "            array = cp.deepcopy(basins.lat)\n",
    "\n",
    "            # Define a mapping function that maps node indecies on a irregular grid\n",
    "            # to those on the regular grid. This will speed up calculations if this\n",
    "            # function is called more than once.\n",
    "\n",
    "            # Iterate over all latitude and longitudes of the input grid.\n",
    "            for i in range(len(basins.lat[:,0])):\n",
    "                for j in range(len(basins.lat[0,:])):\n",
    "                    # Find the distances from each regular grid point (i,j) to all\n",
    "                    # irregular grid points.\n",
    "                    x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                            lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                            radius=1)\n",
    "\n",
    "                    # Assign the nearest basin ID to element (i,j) \n",
    "                    array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "            ## Apply the mask\n",
    "            if mask:\n",
    "                array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "            return array;\n",
    "\n",
    "        # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "        diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "        #####################################################\n",
    "        ####################### Plot ########################\n",
    "        #####################################################\n",
    "        # Transform using the QT\n",
    "        DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "        shape = np.shape(DQT_zscore)\n",
    "        DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "        DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "        DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "        DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "        DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    2]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"zscore\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "    # Plot using ExoCcycle plotGlobal function\n",
    "    # Same as above except plots the weight values\n",
    "    # excluding the distance dependence between nodes.\n",
    "    # However, this should be negligible.\n",
    "    def complementCDF(diff,\n",
    "                      transformer,\n",
    "                      std,\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight']):\n",
    "        \"\"\"\n",
    "        complementCDF is function used to calculate the weight of a node\n",
    "        pair connection given the following inputs.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        diff : FLOAT\n",
    "            A node pair difference value from field of data.\n",
    "        transformer : OBJECT\n",
    "            Quantile transformation that is used to convert diff\n",
    "            input into z-score value.\n",
    "        std : FLAOT\n",
    "            Standard devitaion of total field data input after\n",
    "            being quantile transformed (i.e., this value should\n",
    "            be ~0). \n",
    "        shortenFactor : FLOAT\n",
    "            Factor to shorten CDF distribution by.\n",
    "        shiftFactor : FLOAT\n",
    "            Factor to shift CDF distribution by.\n",
    "        minWeight : FLOAT\n",
    "            A value between 0 and 1 that determines the minimum\n",
    "            weight to assign to a diff value. \n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        node pair edge weight(s)\n",
    "\n",
    "        \"\"\"\n",
    "        from scipy import stats\n",
    "        # Transform from diff-space to gaussian-space\n",
    "        if len(diff) == 1:\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "        else:\n",
    "            shape = np.shape(diff)\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "            QTGdiff = np.reshape(QTGdiff, shape);\n",
    "        # Get probablity in stretched distribution\n",
    "        cdfCenter  = std*shiftFactor\n",
    "        cdfStretch = std/shortenFactor\n",
    "        CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "        # Divide by probablity in normal distribution. This\n",
    "        # scales probablility between 0-1.\n",
    "        # Note that:\n",
    "        #   S->1 for |value1 - value2|-> 0   and\n",
    "        #   S->0 for |value1 - value2|-> inf\n",
    "        Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "        return Ss\n",
    "\n",
    "    Ss= complementCDF(diffAveGrd,\n",
    "                      transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                      std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                        cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1]},\n",
    "                        pltOpts={\"valueType\": \"DQT\",\n",
    "                                 \"valueUnits\": \"Weights\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b994977",
   "metadata": {},
   "source": [
    "# F09, F17: Etopo versus reconstructed Bathymetry Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89972261",
   "metadata": {},
   "source": [
    "#### Leiden Detection + Post Processing with Etopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "import itertools\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Define fields to plot weights for. Note that weights must be calculated\n",
    "# for these fields.\n",
    "fieldNums = [\"Field2\"]\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts):\n",
    "    # Change data type to avoid errors\n",
    "    minBasinCnt = int(minBasinCnt)\n",
    "    ensembleSize = int(ensembleSize)\n",
    "    \n",
    "    # Set detection method\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/ReconVsMeasuredBathymetry\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/ReconVsMeasuredBathymetry/{}-PP'.format(communityDetectionMethod))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    ### Plot DQT-CDF Values ###\n",
    "    ###########################\n",
    "    for fieldNum in fieldNums:\n",
    "        #####################################################\n",
    "        ####### Find average node neighbor difference #######\n",
    "        #####################################################\n",
    "        # Iterate over each node\n",
    "        attrs = None;\n",
    "        for node in basins.G.nodes:\n",
    "            # Average node connection difference for each node\n",
    "            temp = 0; cnt = 0;\n",
    "            for conNode in basins.G.neighbors(node):\n",
    "                temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                cnt+=1;\n",
    "            try:\n",
    "                diffAve = temp/cnt; \n",
    "            except:\n",
    "                # If node has no connections. This rarely happens.\n",
    "                #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                diffAve = 0\n",
    "            # Collect average node neighbor difference property\n",
    "            if attrs == None:\n",
    "                attrs = {node: {\"diffAve\": diffAve}};\n",
    "            else:\n",
    "                attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "        # Assign average node neighbor difference node property to graph\n",
    "        G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "        # List values\n",
    "        diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "        #####################################################\n",
    "        ################ Interpolate to grid ################\n",
    "        #####################################################\n",
    "        def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "            \"\"\"\n",
    "            interp2regularGrid method is used to interpolate data to\n",
    "            a regular grid given an input of irregular spaced data.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            dataIrregular : NUMPY ARRAY\n",
    "                3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                The default is None. This will make the function define the \n",
    "                dataIrregular variable with basinIDs.\n",
    "            mask : STRING\n",
    "                The path to a netCDF4 file that can be used to mask the result\n",
    "                of interpolation. The default is None.\n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            array : NUMPY ARRAY\n",
    "                A 2nxn array that hold node properties for each corresponding\n",
    "                entry in basins.lat and basins.lon. \n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            import copy as cp\n",
    "\n",
    "            # Get basin IDs from network object.\n",
    "            tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "            tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "            # Define an array to hold longitude, latitude, and basinID\n",
    "            dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "            # Iterate over all nodes so each node's longitude, latitude,\n",
    "            # and basinID can be added to the dataIrregular array.\n",
    "            for i in tmpValuesID:\n",
    "                dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "            # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "            # on the surface of the a sphere (planet). \n",
    "            array = cp.deepcopy(basins.lat)\n",
    "\n",
    "            # Define a mapping function that maps node indecies on a irregular grid\n",
    "            # to those on the regular grid. This will speed up calculations if this\n",
    "            # function is called more than once.\n",
    "\n",
    "            # Iterate over all latitude and longitudes of the input grid.\n",
    "            for i in range(len(basins.lat[:,0])):\n",
    "                for j in range(len(basins.lat[0,:])):\n",
    "                    # Find the distances from each regular grid point (i,j) to all\n",
    "                    # irregular grid points.\n",
    "                    x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                            lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                            radius=1)\n",
    "\n",
    "                    # Assign the nearest basin ID to element (i,j) \n",
    "                    array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "            ## Apply the mask\n",
    "            if mask:\n",
    "                array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "            return array;\n",
    "\n",
    "        # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "        diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "        #####################################################\n",
    "        ####################### Plot ########################\n",
    "        #####################################################\n",
    "        # Transform using the QT\n",
    "        DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "        shape = np.shape(DQT_zscore)\n",
    "        DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "        DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "        DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "        DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "        DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    2]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"zscore\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "    # Plot using ExoCcycle plotGlobal function\n",
    "    # Same as above except plots the weight values\n",
    "    # excluding the distance dependence between nodes.\n",
    "    # However, this should be negligible.\n",
    "    def complementCDF(diff,\n",
    "                      transformer,\n",
    "                      std,\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight']):\n",
    "        \"\"\"\n",
    "        complementCDF is function used to calculate the weight of a node\n",
    "        pair connection given the following inputs.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        diff : FLOAT\n",
    "            A node pair difference value from field of data.\n",
    "        transformer : OBJECT\n",
    "            Quantile transformation that is used to convert diff\n",
    "            input into z-score value.\n",
    "        std : FLAOT\n",
    "            Standard devitaion of total field data input after\n",
    "            being quantile transformed (i.e., this value should\n",
    "            be ~0). \n",
    "        shortenFactor : FLOAT\n",
    "            Factor to shorten CDF distribution by.\n",
    "        shiftFactor : FLOAT\n",
    "            Factor to shift CDF distribution by.\n",
    "        minWeight : FLOAT\n",
    "            A value between 0 and 1 that determines the minimum\n",
    "            weight to assign to a diff value. \n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        node pair edge weight(s)\n",
    "\n",
    "        \"\"\"\n",
    "        from scipy import stats\n",
    "        # Transform from diff-space to gaussian-space\n",
    "        if len(diff) == 1:\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "        else:\n",
    "            shape = np.shape(diff)\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "            QTGdiff = np.reshape(QTGdiff, shape);\n",
    "        # Get probablity in stretched distribution\n",
    "        cdfCenter  = std*shiftFactor\n",
    "        cdfStretch = std/shortenFactor\n",
    "        CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "        # Divide by probablity in normal distribution. This\n",
    "        # scales probablility between 0-1.\n",
    "        # Note that:\n",
    "        #   S->1 for |value1 - value2|-> 0   and\n",
    "        #   S->0 for |value1 - value2|-> inf\n",
    "        Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "        return Ss\n",
    "\n",
    "    Ss= complementCDF(diffAveGrd,\n",
    "                      transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                      std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                        cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1]},\n",
    "                        pltOpts={\"valueType\": \"DQT\",\n",
    "                                 \"valueUnits\": \"Weights\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    \n",
    "    # Create node cluster\n",
    "    # Note that the small basin mergers are not inlcuded\n",
    "    # in the LGNClusters. Only large basin mergers such that\n",
    "    # small basin mergers results in X chosen basins.\n",
    "    LeidenClusters=NodeClustering(communities=basins.Rcommunities,\n",
    "                           graph=basins.G,\n",
    "                           method_name=\"consensus_ledien\",\n",
    "                           method_parameters={\n",
    "                               \"resolution_parameter\": resolution,\n",
    "                               \"runs\": ensembleSize,\n",
    "                               \"distance_threshold\": 0.3}\n",
    "                          )\n",
    "\n",
    "    LGNClusters=NodeClustering(communities=basins.communitiesFinal,\n",
    "                           graph=basins.G,\n",
    "                           method_name=\"consensus_ledien\",\n",
    "                           method_parameters={\n",
    "                               \"resolution_parameter\": resolution,\n",
    "                               \"runs\": ensembleSize,\n",
    "                               \"distance_threshold\": 0.3}\n",
    "                          )\n",
    "\n",
    "\n",
    "    # Calculate community detection metrics\n",
    "    for cluster, method in zip([LeidenClusters, LGNClusters], [\"LeidenClusters\", \"LGNClusters\"]):\n",
    "        newman_girvan_modularity = evaluation.newman_girvan_modularity(basins.G, cluster)\n",
    "        internal_edge_density = evaluation.internal_edge_density(basins.G, cluster)\n",
    "        erdos_renyi_modularity= evaluation.erdos_renyi_modularity(basins.G, cluster)\n",
    "        modularity_density    = evaluation.modularity_density(basins.G, cluster)\n",
    "        avg_embeddedness      = evaluation.avg_embeddedness(basins.G, cluster)\n",
    "        conductance           = evaluation.conductance(basins.G, cluster)\n",
    "        surprise              = evaluation.surprise(basins.G, cluster)\n",
    "\n",
    "        # Add community evaluation metrics to output\n",
    "        readmetxt += \"\\n\\nCommunity evaluation metrics ({}):\\n\".format(method);\n",
    "        readmetxt += \"newman_girvan_modularity:\\t {}\\n\".format(newman_girvan_modularity.score)\n",
    "        readmetxt += \"erdos_renyi_modularity:\\t\\t {}\\n\".format(erdos_renyi_modularity.score)\n",
    "        readmetxt += \"modularity_density:\\t\\t {}\\n\".format(modularity_density.score)\n",
    "        readmetxt += \"internal_edge_density:\\t\\t {} +- {} (std)\\n\".format(internal_edge_density.score, internal_edge_density.std)\n",
    "        readmetxt += \"avg_embeddedness:\\t\\t {} +- {} (std)\\n\".format(avg_embeddedness.score, avg_embeddedness.std)\n",
    "        readmetxt += \"conductance:\\t\\t\\t {} +- {} (std)\\n\".format(conductance.score, conductance.std)\n",
    "        readmetxt += \"surprise:\\t\\t\\t {}\\n\".format(surprise.score)\n",
    "        \n",
    "    \n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb47edf",
   "metadata": {},
   "source": [
    "#### Leiden Detection + Post Processing with Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "import itertools\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "\n",
    "####################################\n",
    "### Reconstruction period inputs ###\n",
    "####################################\n",
    "ages = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80];\n",
    "ages = [0, 60, 80]\n",
    "agestr = [ str(age) for age in ages ];\n",
    "\n",
    "# Unused unless communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "minBasinCntV = [10]\n",
    "minBasinCntVstr = [ str(cnt) for cnt in minBasinCntV ];\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Define fields to plot weights for. Note that weights must be calculated\n",
    "# for these fields.\n",
    "fieldNums = [\"Field2\"]\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt, age in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, ages):\n",
    "    print(resolution, ensembleSize, minBasinCnt, age)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt, age in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, ages):\n",
    "    # Change data type to avoid errors\n",
    "    minBasinCnt = int(minBasinCnt);\n",
    "    ensembleSize = int(ensembleSize);\n",
    "    age = int(age);\n",
    "    \n",
    "    # Set detection method\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/ReconVsMeasuredBathymetry\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/ReconVsMeasuredBathymetry/Reconstruction_{}Ma-{}-PP'.format(age, communityDetectionMethod))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "    ####################################\n",
    "    ####### Add bathymetry field #######\n",
    "    ####################################\n",
    "    basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                    dataGrid =  os.getcwd()+'/PNAS_Bogumil_Results/bathymetryNCFiles/Bathymetry_{}Ma.nc'.format(age),\n",
    "                    parameter = \"z\",\n",
    "                    parameterUnit = basins.Fields[\"Field1\"][\"parameterUnit\"],\n",
    "                    parameterName = basins.Fields[\"Field1\"][\"parameterName\"])\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field2\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "    \n",
    "    # Set field mask parameters\n",
    "    fieldMaskParameter = {\"usedField\":0, \"fliprl\":False, \"flipud\":False}\n",
    "    \n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        fieldMaskParameter = fieldMaskParameter,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field2\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field2\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    for fieldNum in fieldNums:\n",
    "        # Read reconstructed bathymetry to plot it\n",
    "\n",
    "        # Resample bathymetry at correct resolution and grid registration\n",
    "        os.system(\"gmt grdsample {0} -Rd -rp -I{2}d, -G{1}\".format(\"tempSimp_bathymetry.nc\",\n",
    "                                                                   \"tempSimp_bathymetry_resampled.nc\",\n",
    "                                                                   basins.Fields[fieldNum]['resolution']))\n",
    "        nc = Dataset(\"tempSimp_bathymetry_resampled.nc\")\n",
    "        bathymetry = nc[\"z\"][:];\n",
    "        lon = nc[\"lon\"][:];\n",
    "        lat = nc[\"lat\"][:];\n",
    "        nc.close()\n",
    "\n",
    "\n",
    "        # Calculate area weighted average and standard deviation (for plotting)\n",
    "        areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[fieldNum]['resolution'],\n",
    "                                                                                                  LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[fieldNum]['resolution']],\n",
    "                                                                                                  LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[fieldNum]['resolution']])\n",
    "        ave, std = EC.utils.weightedAvgAndStd(bathymetry, areaWeights)\n",
    "\n",
    "        #########################\n",
    "        ### Plot input fields ###\n",
    "        #########################\n",
    "        plotRange = [0, 6000];\n",
    "        N = 1000\n",
    "        blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "        #plotRange = [ave-1*std, ave+1*std];\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"boundaryColor\":'k',\n",
    "                                     \"boundaryLinewidth\":1.5,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)       \n",
    "        \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    ### Plot DQT-CDF Values ###\n",
    "    ###########################\n",
    "    for fieldNum in fieldNums:\n",
    "        #####################################################\n",
    "        ####### Find average node neighbor difference #######\n",
    "        #####################################################\n",
    "        # Iterate over each node\n",
    "        attrs = None;\n",
    "        for node in basins.G.nodes:\n",
    "            # Average node connection difference for each node\n",
    "            temp = 0; cnt = 0;\n",
    "            for conNode in basins.G.neighbors(node):\n",
    "                temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                cnt+=1;\n",
    "            try:\n",
    "                diffAve = temp/cnt; \n",
    "            except:\n",
    "                # If node has no connections. This rarely happens.\n",
    "                #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                diffAve = 0\n",
    "            # Collect average node neighbor difference property\n",
    "            if attrs == None:\n",
    "                attrs = {node: {\"diffAve\": diffAve}};\n",
    "            else:\n",
    "                attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "        # Assign average node neighbor difference node property to graph\n",
    "        G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "        # List values\n",
    "        diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "        #####################################################\n",
    "        ################ Interpolate to grid ################\n",
    "        #####################################################\n",
    "        def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "            \"\"\"\n",
    "            interp2regularGrid method is used to interpolate data to\n",
    "            a regular grid given an input of irregular spaced data.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            dataIrregular : NUMPY ARRAY\n",
    "                3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                The default is None. This will make the function define the \n",
    "                dataIrregular variable with basinIDs.\n",
    "            mask : STRING\n",
    "                The path to a netCDF4 file that can be used to mask the result\n",
    "                of interpolation. The default is None.\n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            array : NUMPY ARRAY\n",
    "                A 2nxn array that hold node properties for each corresponding\n",
    "                entry in basins.lat and basins.lon. \n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            import copy as cp\n",
    "\n",
    "            # Get basin IDs from network object.\n",
    "            tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "            tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "            # Define an array to hold longitude, latitude, and basinID\n",
    "            dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "            # Iterate over all nodes so each node's longitude, latitude,\n",
    "            # and basinID can be added to the dataIrregular array.\n",
    "            for i in tmpValuesID:\n",
    "                dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "            # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "            # on the surface of the a sphere (planet). \n",
    "            array = cp.deepcopy(basins.lat)\n",
    "\n",
    "            # Define a mapping function that maps node indecies on a irregular grid\n",
    "            # to those on the regular grid. This will speed up calculations if this\n",
    "            # function is called more than once.\n",
    "\n",
    "            # Iterate over all latitude and longitudes of the input grid.\n",
    "            for i in range(len(basins.lat[:,0])):\n",
    "                for j in range(len(basins.lat[0,:])):\n",
    "                    # Find the distances from each regular grid point (i,j) to all\n",
    "                    # irregular grid points.\n",
    "                    x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                            lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                            radius=1)\n",
    "\n",
    "                    # Assign the nearest basin ID to element (i,j) \n",
    "                    array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "            ## Apply the mask\n",
    "            if mask:\n",
    "                array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "            return array;\n",
    "\n",
    "        # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "        diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "        #####################################################\n",
    "        ####################### Plot ########################\n",
    "        #####################################################\n",
    "        # Transform using the QT\n",
    "        DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "        shape = np.shape(DQT_zscore)\n",
    "        DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "        DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "        DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "        DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "        DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    2]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"zscore\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "    # Plot using ExoCcycle plotGlobal function\n",
    "    # Same as above except plots the weight values\n",
    "    # excluding the distance dependence between nodes.\n",
    "    # However, this should be negligible.\n",
    "    def complementCDF(diff,\n",
    "                      transformer,\n",
    "                      std,\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight']):\n",
    "        \"\"\"\n",
    "        complementCDF is function used to calculate the weight of a node\n",
    "        pair connection given the following inputs.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        diff : FLOAT\n",
    "            A node pair difference value from field of data.\n",
    "        transformer : OBJECT\n",
    "            Quantile transformation that is used to convert diff\n",
    "            input into z-score value.\n",
    "        std : FLAOT\n",
    "            Standard devitaion of total field data input after\n",
    "            being quantile transformed (i.e., this value should\n",
    "            be ~0). \n",
    "        shortenFactor : FLOAT\n",
    "            Factor to shorten CDF distribution by.\n",
    "        shiftFactor : FLOAT\n",
    "            Factor to shift CDF distribution by.\n",
    "        minWeight : FLOAT\n",
    "            A value between 0 and 1 that determines the minimum\n",
    "            weight to assign to a diff value. \n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        node pair edge weight(s)\n",
    "\n",
    "        \"\"\"\n",
    "        from scipy import stats\n",
    "        # Transform from diff-space to gaussian-space\n",
    "        if len(diff) == 1:\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "        else:\n",
    "            shape = np.shape(diff)\n",
    "            QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "            QTGdiff = np.reshape(QTGdiff, shape);\n",
    "        # Get probablity in stretched distribution\n",
    "        cdfCenter  = std*shiftFactor\n",
    "        cdfStretch = std/shortenFactor\n",
    "        CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "        # Divide by probablity in normal distribution. This\n",
    "        # scales probablility between 0-1.\n",
    "        # Note that:\n",
    "        #   S->1 for |value1 - value2|-> 0   and\n",
    "        #   S->0 for |value1 - value2|-> inf\n",
    "        Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "        return Ss\n",
    "\n",
    "    Ss= complementCDF(diffAveGrd,\n",
    "                      transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                      std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                      shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                      shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                      minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                        cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1]},\n",
    "                        pltOpts={\"valueType\": \"DQT\",\n",
    "                                 \"valueUnits\": \"Weights\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8227ca",
   "metadata": {},
   "source": [
    "# F13: Etopo Basins (interior and boundary bathymetry distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1211e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "########### LGN Basin Detection on Etopo ###########\n",
    "####################################################\n",
    "\n",
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [5]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden-GirvanNewman-PP-Stats')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_1.0deg.nc\".format(body),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    plotRange = [0, 6000];\n",
    "    N = 1000\n",
    "    blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "    #plotRange = [ave-1*std, ave+1*std];\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    \n",
    "    EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":blues_cm,\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"boundaryColor\":'k',\n",
    "                                 \"boundaryLinewidth\":1.5,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "\n",
    "    \n",
    "############################################################################\n",
    "########### Calculation/Plotting of Basin/Boundary Distributions ###########\n",
    "############################################################################\n",
    "\n",
    "# 12a. Calculate basin bathymetry parameters\n",
    "# Note: the basin bathymetry distributions will be calculated\n",
    "# with basins.bathymetry\n",
    "basins.calculateBasinParameters(verbose=True, fldName=fldName, fieldNum=\"Field1\")\n",
    "\n",
    "# 12b. Calculate basin connectivity parameters\n",
    "# Note: the connective distributions will be calculated\n",
    "# with graph node bathymetry values.\n",
    "basins.calculateBasinConnectivityParameters(verbose=True, fldName=fldName, fieldNum=\"Field1\")\n",
    "\n",
    "# 12c. Expand original bathymetry netCDF4 file by writting a new basin bathymetry\n",
    "# netCDF4 file that also contains basin bathymetry parameters.\n",
    "basins.saveCcycleParameter(verbose=True);\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b61e4d",
   "metadata": {},
   "source": [
    "# F15, F16: Etopo Shelf vs Deep Marine Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdc4c4",
   "metadata": {},
   "source": [
    "#### Create etopo bathymetry netCDF4 at high resolution for shelf analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Set spatial resolutions\n",
    "spatialResolutions = [0.3];\n",
    "\n",
    "# Iterate over spatial resolutions to create each sampled etopo bathymetry model\n",
    "for spatialResolution in spatialResolutions:\n",
    "    # Create bathymetry object with body=... attributes\n",
    "    # Try setting body='mars' | 'earth' | 'moon', 'Venus'\n",
    "    body=\"Earth\"\n",
    "    planetBathy = EC.Bathymetry.BathyMeasured(body=body)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory_name = os.getcwd()+\"/topographies/{}\".format(planetBathy.model)\n",
    "    os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "    # Download topography model (note that is must only be done once per body).\n",
    "    # NOTE: UNCOMMENT THIS SECTION TO DOWNLOAD TOPOGRAPHY MODEL\n",
    "    planetBathy.getTopo(os.getcwd(),\n",
    "                      verbose=True);\n",
    "\n",
    "    # Read topography. This method will generate a topography model netCDF4 file with \n",
    "    # new_resolution, in degrees. Note that the generated topography model will be \n",
    "    # cell registered (All calculations from here on out are in cell registered to\n",
    "    # simplify codes and reduce data loss on conversions).\n",
    "    planetBathy.readTopo(os.getcwd(),\n",
    "                       new_resolution=spatialResolution,\n",
    "                       verbose=False);\n",
    "\n",
    "    # Generate a bathymetry model base on a set of input methods and properties. The setSeaLelvel\n",
    "    # method has multiple ways to fill topography with oceans. The two currently implemented at\n",
    "    # the time of this JN creation are as follows:\n",
    "    #     1) basinVolume : An option to define bathymetry by flooding topography with\n",
    "    #                      basinVolume['uncompactedVol'] amount of ocean water, in m3.\n",
    "    #     2) OceanArea : Option to define bathymetry by flooding topography until\n",
    "    #                    oceanArea['area'], decimal percent, of global area is covered\n",
    "    #                    with oceans.\n",
    "    # \n",
    "    # Here, I use the OceanArea constraint and block the basinVolume constraint with comments.\n",
    "    # \n",
    "    planetBathy.setSeaLevel(basinVolume = {\"on\":False, 'uncompactedVol':None},\n",
    "                          oceanArea = {\"on\":True, \"area\":0.7},\n",
    "                          isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "    # Note that in this basinVolume example the uncompactedVol was set to the oceanArea\n",
    "    # bathymetry model's VOC, where oceanArea = {\"on\":True, \"area\":0.7}. \n",
    "    #\n",
    "    # planetBathy.setSeaLevel(basinVolume = {\"on\":True, 'uncompactedVol':3.299187952154623e+17},\n",
    "    #                       oceanArea = {\"on\":False, \"area\":0.7},\n",
    "    #                       isostaticCompensation = {\"on\":False}, verbose=False)\n",
    "\n",
    "\n",
    "    # Save bathymetry model as netCDF4. Note that models will be saved under the same root folder\n",
    "    # that was supplied to the readTopo(...) method.\n",
    "    # \n",
    "    # only the bathymetry array is saved in this file. Other relevant values are represented\n",
    "    # as vectors (e.g., lat, lon, area-weights, global bathymetery distributions, etc) or\n",
    "    # attributes (e.g., VOC, AOC, high latitude cutoff, etc).\n",
    "    # \n",
    "    planetBathy.saveBathymetry()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a99bb",
   "metadata": {},
   "source": [
    "#### Prepare etopo data for community detection - i.e., split between pelagic and shelf regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5594e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import ExoCcycle as EC\n",
    "    \n",
    "# Make directory for output files\n",
    "!mkdir -p figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/ncfiles\n",
    "fldBase='figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/ncfiles';\n",
    "\n",
    "# Set spatial resolutions\n",
    "spatialResolutions = [1, 0.3];\n",
    "\n",
    "# Iterate over spatial resolutions to create each sampled etopo bathymetry model\n",
    "for spatialResolution in spatialResolutions:\n",
    "    # Input bathymetry\n",
    "    if spatialResolution == int(spatialResolution):\n",
    "        spatialResolution = int(spatialResolution)\n",
    "    inputFile = os.getcwd()+\"/bathymetries/Earth/Earth_resampled_{0:0.1f}deg.nc\".format(spatialResolution)\n",
    "\n",
    "    # Threshold depth [m]\n",
    "    depthCut = 600\n",
    "\n",
    "    # Make shelf bathymetry netCDF4\n",
    "    #keepOnlySelectedVars(inputFile, fldBase+\"/EtopoBathymetry.nc\", keepVars=['lat', 'lon', 'bathymetry'])\n",
    "    optionsShelf = {\"inputFile\":inputFile, \"outputFile\":fldBase+\"/ShelfBathymetry_{0:0.1f}deg.nc\".format(spatialResolution), \"varName\":\"bathymetry\", \"threshold\":depthCut, \"gt\":True}\n",
    "    EC.utils.filterNc(optionsShelf)\n",
    "\n",
    "    # # Make Deep ocean bathymetry netCDF4\n",
    "    optionsDeep = {\"inputFile\":inputFile, \"outputFile\":fldBase+\"/DeepBathymetry_{0:0.1f}deg.nc\".format(spatialResolution), \"varName\":\"bathymetry\", \"threshold\":depthCut, \"le\":True}\n",
    "    EC.utils.filterNc(optionsDeep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe67ad7",
   "metadata": {},
   "source": [
    "### Run community detection as an alternative field (on Deep Bathymetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "\n",
    "###################################\n",
    "### Different Bathymetry Models ###\n",
    "###################################\n",
    "fldBase='figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/ncfiles';\n",
    "bathymetryModelids = [0]\n",
    "bathymetryModels = [\"DeepBathymetry_{0:0.1f}deg.nc\"]\n",
    "\n",
    "\n",
    "# Set of spatial resolutions to calculate basin for\n",
    "spatialResolutions = [1];\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = \"Lite\";\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Define fields to plot weights for. Note that weights must be calculated\n",
    "# for these fields.\n",
    "fieldNums = [\"Field2\"]\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt, bathymetryModelid in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, bathymetryModelids):\n",
    "    print(resolution, ensembleSize, minBasinCnt, bathymetryModelid, bathymetryModels[int(bathymetryModelid)])\n",
    "\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt, bathymetryModelid, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, bathymetryModelids, spatialResolutions):\n",
    "    # Change data type to avoid errors\n",
    "    minBasinCnt = int(minBasinCnt);\n",
    "    ensembleSize = int(ensembleSize);\n",
    "    bathymetryModelid = int(bathymetryModelid);\n",
    "    bathymetryModel = bathymetryModels[bathymetryModelid];\n",
    "    if spatialResolution == int(spatialResolution):\n",
    "        spatialResolution = int(spatialResolution)\n",
    "    \n",
    "    # Set detection method\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/{0}-{1}-PP'.format(bathymetryModel.replace(\".nc\", \"\").format(spatialResolution), communityDetectionMethod))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"{} used to calculate basin boundaries.\".format(bathymetryModel.replace(\".nc\", \"\").format(spatialResolution));\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{0}_resampled_{1:0.1f}deg.nc\".format(body,spatialResolution),\n",
    "                             body=body);\n",
    "    ####################################\n",
    "    # Add bathymetry field\n",
    "    basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                    dataGrid =  os.getcwd()+\"/{0}/{1}\".format(fldBase, bathymetryModel.format(spatialResolution)),\n",
    "                    parameter = basins.Fields[\"Field1\"][\"parameter\"],\n",
    "                    parameterUnit = basins.Fields[\"Field1\"][\"parameterUnit\"],\n",
    "                    parameterName = basins.Fields[\"Field1\"][\"parameterName\"])\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field2\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "    \n",
    "    # Set field mask parameters\n",
    "    fieldMaskParameter = {\"usedField\":0, \"fliprl\":False, \"flipud\":False}\n",
    "    \n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        fieldMaskParameter = fieldMaskParameter,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    for fieldNum in fieldNums:\n",
    "        # Read reconstructed bathymetry to plot it\n",
    "        nc = Dataset(os.getcwd()+\"/{0}/{1}\".format(fldBase, bathymetryModel.format(spatialResolution)), 'r')\n",
    "        \n",
    "        lon = nc['lon'][:]\n",
    "        lat = nc['lat'][:]\n",
    "        bathymetry = nc[\"bathymetry\"][:]\n",
    "        nc.close()\n",
    "        \n",
    "        lon, lat = np.meshgrid(lon, lat);\n",
    "        \n",
    "\n",
    "        # Calculate area weighted average and standard deviation (for plotting)\n",
    "        areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                                  LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                                  LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "        ave, std = EC.utils.weightedAvgAndStd(bathymetry, areaWeights)\n",
    "\n",
    "        \n",
    "        #########################\n",
    "        ### Plot input fields ###\n",
    "        #########################\n",
    "        plotRange = [1000, 6000];\n",
    "        N = 1000\n",
    "        blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "        #plotRange = [ave-1*std, ave+1*std];\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"boundaryColor\":'k',\n",
    "                                     \"boundaryLinewidth\":1.5,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "        \n",
    "    #########################\n",
    "    ### Plot Large Basins ###\n",
    "    #########################\n",
    "    # This function plots basins that are larger than half a percent of the total\n",
    "    # shelf surface area.\n",
    "    BasinIDAMod = EC.plotHelper.plotLargeBasins(basins,\n",
    "                                           fieldNum=\"Field2\",\n",
    "                                           percentage=.5/100,\n",
    "                                           fldName=os.getcwd()+\"/\"+fldName,\n",
    "                                           savePNG=True,\n",
    "                                           verbose=False)\n",
    "    \n",
    "        \n",
    "    verbose = False\n",
    "    if verbose:\n",
    "\n",
    "        ###########################\n",
    "        ### Plot DQT-CDF Values ###\n",
    "        ###########################\n",
    "        for fieldNum in fieldNums:\n",
    "            #####################################################\n",
    "            ####### Find average node neighbor difference #######\n",
    "            #####################################################\n",
    "            # Iterate over each node\n",
    "            attrs = None;\n",
    "            for node in basins.G.nodes:\n",
    "                # Average node connection difference for each node\n",
    "                temp = 0; cnt = 0;\n",
    "                for conNode in basins.G.neighbors(node):\n",
    "                    temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                    cnt+=1;\n",
    "                try:\n",
    "                    diffAve = temp/cnt; \n",
    "                except:\n",
    "                    # If node has no connections. This rarely happens.\n",
    "                    #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                    diffAve = 0\n",
    "                # Collect average node neighbor difference property\n",
    "                if attrs == None:\n",
    "                    attrs = {node: {\"diffAve\": diffAve}};\n",
    "                else:\n",
    "                    attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "            # Assign average node neighbor difference node property to graph\n",
    "            G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "            # List values\n",
    "            diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "            #####################################################\n",
    "            ################ Interpolate to grid ################\n",
    "            #####################################################\n",
    "            def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "                \"\"\"\n",
    "                interp2regularGrid method is used to interpolate data to\n",
    "                a regular grid given an input of irregular spaced data.\n",
    "\n",
    "                Parameters\n",
    "                -----------\n",
    "                dataIrregular : NUMPY ARRAY\n",
    "                    3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                    The default is None. This will make the function define the \n",
    "                    dataIrregular variable with basinIDs.\n",
    "                mask : STRING\n",
    "                    The path to a netCDF4 file that can be used to mask the result\n",
    "                    of interpolation. The default is None.\n",
    "\n",
    "                Returns\n",
    "                --------\n",
    "                array : NUMPY ARRAY\n",
    "                    A 2nxn array that hold node properties for each corresponding\n",
    "                    entry in basins.lat and basins.lon. \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                import copy as cp\n",
    "\n",
    "                # Get basin IDs from network object.\n",
    "                tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "                tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "                # Define an array to hold longitude, latitude, and basinID\n",
    "                dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "                # Iterate over all nodes so each node's longitude, latitude,\n",
    "                # and basinID can be added to the dataIrregular array.\n",
    "                for i in tmpValuesID:\n",
    "                    dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "                # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "                # on the surface of the a sphere (planet). \n",
    "                array = cp.deepcopy(basins.lat)\n",
    "\n",
    "                # Define a mapping function that maps node indecies on a irregular grid\n",
    "                # to those on the regular grid. This will speed up calculations if this\n",
    "                # function is called more than once.\n",
    "\n",
    "                # Iterate over all latitude and longitudes of the input grid.\n",
    "                for i in range(len(basins.lat[:,0])):\n",
    "                    for j in range(len(basins.lat[0,:])):\n",
    "                        # Find the distances from each regular grid point (i,j) to all\n",
    "                        # irregular grid points.\n",
    "                        x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                                lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                                radius=1)\n",
    "\n",
    "                        # Assign the nearest basin ID to element (i,j) \n",
    "                        array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "                ## Apply the mask\n",
    "                if mask:\n",
    "                    array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "                return array;\n",
    "\n",
    "            # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "            diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "\n",
    "            #####################################################\n",
    "            ####################### Plot ########################\n",
    "            #####################################################\n",
    "            # Transform using the QT\n",
    "            DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "            shape = np.shape(DQT_zscore)\n",
    "            DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "            DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "            DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "            DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "            DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "            # Plot using ExoCcycle plotGlobal function\n",
    "            EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[0,\n",
    "                                                        2]},\n",
    "                                pltOpts={\"valueType\": \"DQT\",\n",
    "                                         \"valueUnits\": \"zscore\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "\n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        # Same as above except plots the weight values\n",
    "        # excluding the distance dependence between nodes.\n",
    "        # However, this should be negligible.\n",
    "        def complementCDF(diff,\n",
    "                          transformer,\n",
    "                          std,\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight']):\n",
    "            \"\"\"\n",
    "            complementCDF is function used to calculate the weight of a node\n",
    "            pair connection given the following inputs.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            diff : FLOAT\n",
    "                A node pair difference value from field of data.\n",
    "            transformer : OBJECT\n",
    "                Quantile transformation that is used to convert diff\n",
    "                input into z-score value.\n",
    "            std : FLAOT\n",
    "                Standard devitaion of total field data input after\n",
    "                being quantile transformed (i.e., this value should\n",
    "                be ~0). \n",
    "            shortenFactor : FLOAT\n",
    "                Factor to shorten CDF distribution by.\n",
    "            shiftFactor : FLOAT\n",
    "                Factor to shift CDF distribution by.\n",
    "            minWeight : FLOAT\n",
    "                A value between 0 and 1 that determines the minimum\n",
    "                weight to assign to a diff value. \n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            node pair edge weight(s)\n",
    "\n",
    "            \"\"\"\n",
    "            from scipy import stats\n",
    "            # Transform from diff-space to gaussian-space\n",
    "            if len(diff) == 1:\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "            else:\n",
    "                shape = np.shape(diff)\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "                QTGdiff = np.reshape(QTGdiff, shape);\n",
    "            # Get probablity in stretched distribution\n",
    "            cdfCenter  = std*shiftFactor\n",
    "            cdfStretch = std/shortenFactor\n",
    "            CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "            # Divide by probablity in normal distribution. This\n",
    "            # scales probablility between 0-1.\n",
    "            # Note that:\n",
    "            #   S->1 for |value1 - value2|-> 0   and\n",
    "            #   S->0 for |value1 - value2|-> inf\n",
    "            Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "            return Ss\n",
    "\n",
    "        Ss= complementCDF(diffAveGrd,\n",
    "                          transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                          std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"Weights\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "    \n",
    "    ######################################################\n",
    "    ### Calculate metrics and write them to readme.txt ###\n",
    "    ######################################################\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "        \n",
    "        \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43a4a4",
   "metadata": {},
   "source": [
    "### Run community detection as an alternative field (on Shelf Bathymetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc538b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import copy as cp\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cmcrameri.cm as cmc\n",
    "import itertools\n",
    "\n",
    "# Create nodeclustering object\n",
    "from cdlib import evaluation\n",
    "from cdlib import NodeClustering\n",
    "\n",
    "\n",
    "###################################\n",
    "### Different Bathymetry Models ###\n",
    "###################################\n",
    "fldBase='figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/ncfiles';\n",
    "bathymetryModelids = [0]\n",
    "bathymetryModels = [\"ShelfBathymetry_{0:0.1f}deg.nc\"]\n",
    "\n",
    "\n",
    "# Set of spatial resolutions to calculate basin for\n",
    "spatialResolutions = [0.3];\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "## This is the most similar merger to that used on global bathymetry (i.e. Lite)\n",
    "mergerPackageName = \"LiteShelf0,3degree\";  # Given shelf area communities must imclude at least 408 nodes.\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [0.15]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Define fields to plot weights for. Note that weights must be calculated\n",
    "# for these fields.\n",
    "fieldNums = [\"Field2\"]\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt, bathymetryModelid in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, bathymetryModelids):\n",
    "    print(resolution, ensembleSize, minBasinCnt, bathymetryModelid, bathymetryModels[int(bathymetryModelid)])\n",
    "\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt, bathymetryModelid, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, bathymetryModelids, spatialResolutions):\n",
    "    # Change data type to avoid errors\n",
    "    minBasinCnt = int(minBasinCnt);\n",
    "    ensembleSize = int(ensembleSize);\n",
    "    bathymetryModelid = int(bathymetryModelid);\n",
    "    bathymetryModel = bathymetryModels[bathymetryModelid];\n",
    "    if spatialResolution == int(spatialResolution):\n",
    "        spatialResolution = int(spatialResolution)\n",
    "    \n",
    "    # Set detection method\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results\n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/shelf_noShelf_Communities/{0}-{1}-PP'.format(bathymetryModel.replace(\".nc\", \"\").format(spatialResolution), communityDetectionMethod))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "    \n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"{} used to calculate basin boundaries.\".format(bathymetryModel.replace(\".nc\", \"\").format(spatialResolution));\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{0}_resampled_{1:0.1f}deg.nc\".format(body,spatialResolution),\n",
    "                             body=body);\n",
    "    ####################################\n",
    "    # Add bathymetry field\n",
    "    basins.addField(resolution = basins.Fields[\"Field1\"][\"resolution\"],\n",
    "                    dataGrid =  os.getcwd()+\"/{0}/{1}\".format(fldBase, bathymetryModel.format(spatialResolution)),\n",
    "                    parameter = basins.Fields[\"Field1\"][\"parameter\"],\n",
    "                    parameterUnit = basins.Fields[\"Field1\"][\"parameterUnit\"],\n",
    "                    parameterName = basins.Fields[\"Field1\"][\"parameterName\"])\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field2\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "    \n",
    "    # Set field mask parameters\n",
    "    fieldMaskParameter = {\"usedField\":0, \"fliprl\":False, \"flipud\":False}\n",
    "    \n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        fieldMaskParameter = fieldMaskParameter,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    for fieldNum in fieldNums:\n",
    "        # Read reconstructed bathymetry to plot it\n",
    "        nc = Dataset(os.getcwd()+\"/{0}/{1}\".format(fldBase, bathymetryModel.format(spatialResolution)), 'r')\n",
    "        \n",
    "        lon = nc['lon'][:]\n",
    "        lat = nc['lat'][:]\n",
    "        bathymetry = nc[\"bathymetry\"][:]\n",
    "        nc.close()\n",
    "        \n",
    "        lon, lat = np.meshgrid(lon, lat);\n",
    "        \n",
    "\n",
    "        # Calculate area weighted average and standard deviation (for plotting)\n",
    "        areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                                  LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                                  LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "        ave, std = EC.utils.weightedAvgAndStd(bathymetry, areaWeights)\n",
    "\n",
    "        \n",
    "        #########################\n",
    "        ### Plot input fields ###\n",
    "        #########################\n",
    "        plotRange = [0, 300];\n",
    "        N = 1000\n",
    "        blues_cm = mpl.colormaps['Blues'].resampled(N)\n",
    "        #plotRange = [ave-1*std, ave+1*std];\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        EC.plotHelper.plotGlobalwBoundaries(basins.lat, basins.lon, basins.bathymetry, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobalwboundaries_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":blues_cm,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"boundaryColor\":'k',\n",
    "                                     \"boundaryLinewidth\":1.5,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "        \n",
    "        \n",
    "    #############################\n",
    "    ##### Regional plotting #####\n",
    "    #############################\n",
    "    # SE Asia Shelves 1\n",
    "    # SE Asia Shelves 2\n",
    "    # SE Asia Shelves 3\n",
    "    # ES South America Shelves 1\n",
    "    regions = np.array([[100,150,-30,20],\n",
    "                        [90,130,0,30],\n",
    "                        [85,125,-10,25],\n",
    "                        [-90, -35, -60, 20],\n",
    "                       ])\n",
    "\n",
    "\n",
    "    regionCnt=0\n",
    "    for region in regions:\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotRegion{}.png\".format(regionCnt),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True,\n",
    "                                     \"coastlines\":True,\n",
    "                                     \"region\":region,\n",
    "                                     \"regionalZBoundaries\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "        if ave-1*std<0:\n",
    "            lowerBound = 0;\n",
    "        else:\n",
    "            lowerBound = ave-1*std;\n",
    "        #plotRange = [lowerBound, ave+1*std]\n",
    "        plotRange = [0, 300]\n",
    "\n",
    "        EC.plotHelper.plotGlobal(lat, lon, bathymetry,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotRegion{1}_{0}.png\".format(basins.Fields[fieldNum]['parameterName'], regionCnt),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":plotRange},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[fieldNum]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True,\n",
    "                                     \"coastlines\":True,\n",
    "                                     \"region\":region,\n",
    "                                     \"regionalZBoundaries\":False},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "        regionCnt+=1\n",
    "        \n",
    "        \n",
    "    verbose = False\n",
    "    if verbose:\n",
    "\n",
    "        ###########################\n",
    "        ### Plot DQT-CDF Values ###\n",
    "        ###########################\n",
    "        for fieldNum in fieldNums:\n",
    "            #####################################################\n",
    "            ####### Find average node neighbor difference #######\n",
    "            #####################################################\n",
    "            # Iterate over each node\n",
    "            attrs = None;\n",
    "            for node in basins.G.nodes:\n",
    "                # Average node connection difference for each node\n",
    "                temp = 0; cnt = 0;\n",
    "                for conNode in basins.G.neighbors(node):\n",
    "                    temp+= np.abs( basins.G.nodes[conNode][fieldNum]-basins.G.nodes[node][fieldNum] )\n",
    "                    cnt+=1;\n",
    "                try:\n",
    "                    diffAve = temp/cnt; \n",
    "                except:\n",
    "                    # If node has no connections. This rarely happens.\n",
    "                    #print(temp, cnt, basins.G.neighbors(node) )\n",
    "                    diffAve = 0\n",
    "                # Collect average node neighbor difference property\n",
    "                if attrs == None:\n",
    "                    attrs = {node: {\"diffAve\": diffAve}};\n",
    "                else:\n",
    "                    attrs[node] = {\"diffAve\": diffAve};\n",
    "\n",
    "            # Assign average node neighbor difference node property to graph\n",
    "            G = nx.set_node_attributes(basins.G, attrs)\n",
    "\n",
    "            # List values\n",
    "            diffAve_values = list(basins.G.nodes(data=\"diffAve\"))\n",
    "\n",
    "\n",
    "            #####################################################\n",
    "            ################ Interpolate to grid ################\n",
    "            #####################################################\n",
    "            def interp2regularGrid(basins, dataIrregular=None, mask=True):\n",
    "                \"\"\"\n",
    "                interp2regularGrid method is used to interpolate data to\n",
    "                a regular grid given an input of irregular spaced data.\n",
    "\n",
    "                Parameters\n",
    "                -----------\n",
    "                dataIrregular : NUMPY ARRAY\n",
    "                    3XN numpy array with columns of longitude, latitude, magnitude.\n",
    "                    The default is None. This will make the function define the \n",
    "                    dataIrregular variable with basinIDs.\n",
    "                mask : STRING\n",
    "                    The path to a netCDF4 file that can be used to mask the result\n",
    "                    of interpolation. The default is None.\n",
    "\n",
    "                Returns\n",
    "                --------\n",
    "                array : NUMPY ARRAY\n",
    "                    A 2nxn array that hold node properties for each corresponding\n",
    "                    entry in basins.lat and basins.lon. \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                import copy as cp\n",
    "\n",
    "                # Get basin IDs from network object.\n",
    "                tmpValuesID  = nx.get_node_attributes(basins.G, \"diffAve\");\n",
    "                tmpValuesPos = nx.get_node_attributes(basins.G, \"pos\");\n",
    "\n",
    "                # Define an array to hold longitude, latitude, and basinID\n",
    "                dataIrregular = np.zeros((len(tmpValuesPos), 3))\n",
    "\n",
    "                # Iterate over all nodes so each node's longitude, latitude,\n",
    "                # and basinID can be added to the dataIrregular array.\n",
    "                for i in tmpValuesID:\n",
    "                    dataIrregular[i,:] = np.array([tmpValuesPos[i][1], tmpValuesPos[i][0], tmpValuesID[i]])\n",
    "\n",
    "                # Define an array 2nxn to hold the basin IDs for the regular grid\n",
    "                # on the surface of the a sphere (planet). \n",
    "                array = cp.deepcopy(basins.lat)\n",
    "\n",
    "                # Define a mapping function that maps node indecies on a irregular grid\n",
    "                # to those on the regular grid. This will speed up calculations if this\n",
    "                # function is called more than once.\n",
    "\n",
    "                # Iterate over all latitude and longitudes of the input grid.\n",
    "                for i in range(len(basins.lat[:,0])):\n",
    "                    for j in range(len(basins.lat[0,:])):\n",
    "                        # Find the distances from each regular grid point (i,j) to all\n",
    "                        # irregular grid points.\n",
    "                        x = EC.utils.haversine_distance(lat2= dataIrregular[:,1], lat1= basins.lat[i,j],\n",
    "                                                lon2= dataIrregular[:,0], lon1= basins.lon[i,j],\n",
    "                                                radius=1)\n",
    "\n",
    "                        # Assign the nearest basin ID to element (i,j) \n",
    "                        array[i,j] = dataIrregular[np.argwhere(np.nanmin(x) == x)[0][0], 2]\n",
    "\n",
    "                ## Apply the mask\n",
    "                if mask:\n",
    "                    array[np.isnan(basins.maskValue)] = np.nan\n",
    "\n",
    "\n",
    "                return array;\n",
    "\n",
    "            # Interpolate from equal area grid to regular spaced latitude/longitude\n",
    "            diffAveGrd = interp2regularGrid(basins, mask=True)\n",
    "            #diffAveGrd = EC.utils.interp2regularGrid(basins, mask=True, propertyName='diffAve')\n",
    "\n",
    "            #####################################################\n",
    "            ####################### Plot ########################\n",
    "            #####################################################\n",
    "            # Transform using the QT\n",
    "            DQT_zscore = cp.deepcopy(diffAveGrd);\n",
    "            shape = np.shape(DQT_zscore)\n",
    "            DQT_zscore = np.reshape(DQT_zscore, (np.size(DQT_zscore), 1) )\n",
    "            DQT_zscoreNonNans = cp.deepcopy( DQT_zscore[~np.isnan(DQT_zscore)] )\n",
    "            DQT_zscoreNonNans =  basins.Fields[fieldNum]['weightMethodPara']['qt'].transform( np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans), 1) ) )             \n",
    "            DQT_zscore[~np.isnan(DQT_zscore)] = np.reshape(DQT_zscoreNonNans, (len(DQT_zscoreNonNans),) )\n",
    "            DQT_zscore = np.reshape(DQT_zscore, shape)\n",
    "\n",
    "\n",
    "            # Plot using ExoCcycle plotGlobal function\n",
    "            EC.plotHelper.plotGlobal(basins.lat, basins.lon, DQT_zscore,\n",
    "                                outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                                fidName = \"plotGlobal_DQT_{}.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                          \"cbar-title\":\"cbar-title\",\n",
    "                                          \"cbar-range\":[0,\n",
    "                                                        2]},\n",
    "                                pltOpts={\"valueType\": \"DQT\",\n",
    "                                         \"valueUnits\": \"zscore\",\n",
    "                                         \"plotTitle\":\"\",\n",
    "                                         \"plotZeroContour\":False,\n",
    "                                         \"transparent\":True},\n",
    "                                savePNG=True,\n",
    "                                saveSVG=False)\n",
    "\n",
    "        # Plot using ExoCcycle plotGlobal function\n",
    "        # Same as above except plots the weight values\n",
    "        # excluding the distance dependence between nodes.\n",
    "        # However, this should be negligible.\n",
    "        def complementCDF(diff,\n",
    "                          transformer,\n",
    "                          std,\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight']):\n",
    "            \"\"\"\n",
    "            complementCDF is function used to calculate the weight of a node\n",
    "            pair connection given the following inputs.\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            diff : FLOAT\n",
    "                A node pair difference value from field of data.\n",
    "            transformer : OBJECT\n",
    "                Quantile transformation that is used to convert diff\n",
    "                input into z-score value.\n",
    "            std : FLAOT\n",
    "                Standard devitaion of total field data input after\n",
    "                being quantile transformed (i.e., this value should\n",
    "                be ~0). \n",
    "            shortenFactor : FLOAT\n",
    "                Factor to shorten CDF distribution by.\n",
    "            shiftFactor : FLOAT\n",
    "                Factor to shift CDF distribution by.\n",
    "            minWeight : FLOAT\n",
    "                A value between 0 and 1 that determines the minimum\n",
    "                weight to assign to a diff value. \n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            node pair edge weight(s)\n",
    "\n",
    "            \"\"\"\n",
    "            from scipy import stats\n",
    "            # Transform from diff-space to gaussian-space\n",
    "            if len(diff) == 1:\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (1,1) ) );\n",
    "            else:\n",
    "                shape = np.shape(diff)\n",
    "                QTGdiff = transformer.transform( np.reshape( np.array(diff), (np.size(diff), 1) ) )\n",
    "                QTGdiff = np.reshape(QTGdiff, shape);\n",
    "            # Get probablity in stretched distribution\n",
    "            cdfCenter  = std*shiftFactor\n",
    "            cdfStretch = std/shortenFactor\n",
    "            CDF = stats.norm.cdf(QTGdiff, loc=cdfCenter, scale=cdfStretch)\n",
    "            # Divide by probablity in normal distribution. This\n",
    "            # scales probablility between 0-1.\n",
    "            # Note that:\n",
    "            #   S->1 for |value1 - value2|-> 0   and\n",
    "            #   S->0 for |value1 - value2|-> inf\n",
    "            Ss = ( (1-CDF) + minWeight )/(minWeight+1);\n",
    "\n",
    "            return Ss\n",
    "\n",
    "        Ss= complementCDF(diffAveGrd,\n",
    "                          transformer = basins.Fields[fieldNum]['weightMethodPara']['qt'],\n",
    "                          std = basins.Fields[fieldNum]['weightMethodPara']['qtDissSTD'],\n",
    "                          shortenFactor = edgeWeightMethod['shortenFactor'],\n",
    "                          shiftFactor = edgeWeightMethod['shiftFactor'],\n",
    "                          minWeight = edgeWeightMethod['minWeight'])\n",
    "\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, Ss,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_DQT_{}_weights.png\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                            cmapOpts={\"cmap\":cmc.batlow,\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1]},\n",
    "                            pltOpts={\"valueType\": \"DQT\",\n",
    "                                     \"valueUnits\": \"Weights\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "    \n",
    "    ######################################################\n",
    "    ### Calculate metrics and write them to readme.txt ###\n",
    "    ######################################################\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    \n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "\n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "        \n",
    "        \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "smallBasinThresholdkm2 = basins.AOC*(np.max(mergerPackage['mergeSmallBasins']['threshold'])/100)\n",
    "smallBasinMinNodes     = np.floor( smallBasinThresholdkm2/basins.G.nodes[0]['areaWeightm2'] )\n",
    "\n",
    "print(f\"The small basin merger package requires no basin be smaller than {smallBasinThresholdkm2:0.2f} km^2.\")\n",
    "print(f\"The small basin merger package requires no basin have no less than {smallBasinMinNodes:0.0f} nodes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07b437",
   "metadata": {},
   "source": [
    "### Test plotting other regions by changing regions array variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96176373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "##### Regional plotting #####\n",
    "#############################\n",
    "# SE Asia Shelves 1\n",
    "# SE Asia Shelves 2\n",
    "# ES South America Shelves 1\n",
    "regions = np.array([[85,125,-10,25]])\n",
    "\n",
    "regionCnt-=1\n",
    "for region in regions:\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotRegion{}.png\".format(regionCnt),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True,\n",
    "                                 \"coastlines\":True,\n",
    "                                 \"region\":region,\n",
    "                                 \"regionalZBoundaries\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    if ave-1*std<0:\n",
    "        lowerBound = 0;\n",
    "    else:\n",
    "        lowerBound = ave-1*std;\n",
    "        \n",
    "    #plotRange = [lowerBound, ave+1*std]\n",
    "    plotRange = [0,300]\n",
    "\n",
    "    EC.plotHelper.plotGlobal(lat, lon, bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotRegion{1}_{0}.png\".format(basins.Fields[fieldNum]['parameterName'], regionCnt),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":plotRange},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[fieldNum]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[fieldNum]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True,\n",
    "                                 \"coastlines\":True,\n",
    "                                 \"region\":region,\n",
    "                                 \"regionalZBoundaries\":False},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    regionCnt+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566963a9",
   "metadata": {},
   "source": [
    "### Determine equivalent small basin threshold ($\\chi$) values for systems with different node counts (e.g., shelf only analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lite node counts for global ocean system\n",
    "AOCOcean = 361e12\n",
    "resolution_at_1deg = basins.G.nodes[0]['areaWeightm2']/.3\n",
    "percentages = [0.1, 0.5] \n",
    "SmallestBasin1 = AOCOcean*(percentages[0]/100)\n",
    "SmallestBasin2 = AOCOcean*(percentages[1]/100)\n",
    "print(f\"(Whole Ocean) The small basin merger package requires no basin have no less than {SmallestBasin1/resolution_at_1deg:0.0f} nodes.\")\n",
    "print(f\"(Whole Ocean) The small basin merger package requires no basin have no less than {SmallestBasin2/resolution_at_1deg:0.0f} nodes.\")\n",
    "\n",
    "\n",
    "# Lite node counts for shelf ocean system\n",
    "percentagesShelf = [0.03, 0.15]\n",
    "smallBasinThresholdkm2 = basins.AOC*(percentagesShelf[0])/100\n",
    "smallBasinMinNodes     = np.floor( smallBasinThresholdkm2/basins.G.nodes[0]['areaWeightm2'] )\n",
    "print(f\"\\n(Shelf) The small basin merger package requires no basin be smaller than {smallBasinThresholdkm2:0.2f} km^2.\")\n",
    "print(f\"(Shelf) The small basin merger package requires no basin have no less than {smallBasinMinNodes:0.0f} nodes.\")\n",
    "\n",
    "smallBasinThresholdkm2 = basins.AOC*(percentagesShelf[1])/100\n",
    "smallBasinMinNodes     = np.floor( smallBasinThresholdkm2/basins.G.nodes[0]['areaWeightm2'] )\n",
    "\n",
    "print(f\"(Shelf) The small basin merger package requires no basin be smaller than {smallBasinThresholdkm2:0.2f} km^2.\")\n",
    "print(f\"(Shelf) The small basin merger package requires no basin have no less than {smallBasinMinNodes:0.0f} nodes.\")\n",
    "\n",
    "\n",
    "print(\"\\u03C7 = {0} for global ocean are equivalent to \\u03C7 = {1} for global shelf analysis.\".format(percentages, percentagesShelf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d80a1",
   "metadata": {},
   "source": [
    "# Walltime Run \\& Basin Count 1: Louvain + No small basin merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import time\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "\n",
    "#communityDetectionMethod = \"Louvain\"\n",
    "#communityDetectionMethod = \"Leiden\"\n",
    "communityDetectionMethod = \"Girvan-Newman\"\n",
    "#communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = 'Lite'; # ['threshold'] = [0]\n",
    "#mergerPackageName = 'Lite';\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [5]\n",
    "\n",
    "# Define spatial resolutions\n",
    "spatialResolutions = [10, 8, 4];\n",
    "# spatialResolutions = [10,8,4,1];\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [1];\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    print(resolution, ensembleSize, minBasinCnt, spatialResolution)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "# for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    # Change data type to avoid errors\n",
    "    spatialResolution = int(spatialResolution)\n",
    "    minBasinCnt = int(minBasinCnt)\n",
    "    ensembleSize = int(ensembleSize)\n",
    "    \n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":1}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results    \n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/SpatialResolutionTestsWallTimes\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/SpatialResolutionTestsWallTimes/{0}_{1}'.format(communityDetectionMethod,spatialResolution))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    if not (communityDetectionMethod == \"Girvan-Newman\"):\n",
    "        readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "    \n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_{:0.1f}deg.nc\".format(body, spatialResolution),\n",
    "                             body=body);\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    startTime = time.time()\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "    endTime = time.time()\n",
    "    print(\"Detection Time: {} seconds\".format(endTime-startTime))\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    readmetxt += \"\\nDetection Time: {} seconds\\n\".format(endTime-startTime)\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    if not (communityDetectionMethod == \"Girvan-Newman\"):\n",
    "        metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                             resolution=resolution,\n",
    "                                                             ensembleSize=ensembleSize,\n",
    "                                                             distance_threshold=0.3)\n",
    "        readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)  \n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[ave-1*std,\n",
    "                                                ave+1*std]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_2_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[-1,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([-1,0, .5, 1]),\n",
    "                                  \"cbar-intervals\":np.array([-1, 0, .5, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Poor\", \"Good\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6dc19",
   "metadata": {},
   "source": [
    "# Theoretical community detection runtime scaling\n",
    "\n",
    "Given runs with of Louvain, Leiden, Girvan-Newman, and Leiden-Girvan-Newman with different spatial resolution (10, 8, 4, 1 degree) the below node counts and runtimes can be collected to do the below analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ed6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assign graph characteristics\n",
    "spatialResolutions = [10,8,4,1];\n",
    "nodeCnt = np.array([284, 527, 1603, 24441])\n",
    "edgeCnt = 2*nodeCnt\n",
    "\n",
    "\n",
    "# Define node/edge scaling with increasing resolution steps\n",
    "nodeScaling = nodeCnt/nodeCnt[0]\n",
    "edgeScaling = edgeCnt/edgeCnt[0]\n",
    "\n",
    "\n",
    "# Define calculation walltimes (calculated with simulations in pervious cell)\n",
    "LouvainTimes = np.array([0.6, 1, 2.6, 55.6])\n",
    "LeidenTimes = np.array([0.7, 0.8, 2.6, 55.6])\n",
    "GNTimes = np.array([8.5, 40.2, 0, 0])\n",
    "\n",
    "# Define functions for theoretical scaling for increasing node and edge count\n",
    "def fncLouvainPredictedTimes(n,m):\n",
    "    return n*np.log(n)\n",
    "def fncGNPredictedTimes(n,m):\n",
    "    return n*(m**2)\n",
    "\n",
    "# Calculate the predicted walltimes based on coarsest model walltime + theoretical scaling\n",
    "LouvainPredictedTimes = LouvainTimes[0]*fncLouvainPredictedTimes(nodeCnt,edgeCnt)/fncLouvainPredictedTimes(nodeCnt,edgeCnt)[0]\n",
    "LeidenPredictedTimes = LeidenTimes[0]*fncLouvainPredictedTimes(nodeCnt,edgeCnt)/fncLouvainPredictedTimes(nodeCnt,edgeCnt)[0]\n",
    "GNPredictedTimes = GNTimes[0]*fncGNPredictedTimes(nodeCnt,edgeCnt)/fncGNPredictedTimes(nodeCnt,edgeCnt)[0]\n",
    "\n",
    "\n",
    "# Report the predicted walltimes based on coarsest model walltime + theoretical scaling\n",
    "print(\"Runtimes for Louvain Model predicted with:\")\n",
    "print(\"10 degree {0:2.1f}s; 8 degree {1:2.1f}s; 4 degree {2:2.1f}s; 1 degree {3:2.1f}s\\n\".format(\n",
    "    LouvainPredictedTimes[0],\n",
    "    LouvainPredictedTimes[1],\n",
    "    LouvainPredictedTimes[2],\n",
    "    LouvainPredictedTimes[3]) )\n",
    "\n",
    "print(\"Runtimes for Leiden Model predicted with:\")\n",
    "print(\"10 degree {0:2.1f}s; 8 degree {1:2.1f}s; 4 degree {2:2.1f}s; 1 degree {3:2.1f}s\\n\".format(\n",
    "    LeidenPredictedTimes[0],\n",
    "    LeidenPredictedTimes[1],\n",
    "    LeidenPredictedTimes[2],\n",
    "    LeidenPredictedTimes[3]) )\n",
    "\n",
    "print(\"Runtimes for Girvan-Newman Model predicted with:\")\n",
    "print(\"10 degree {0:2.1f}s; 8 degree {1:2.1f}s; 4 degree {2:2.1f} min; 1 degree {3:2.1f} days\\n\".format(\n",
    "    GNPredictedTimes[0],\n",
    "    GNPredictedTimes[1],\n",
    "    GNPredictedTimes[2]/60,\n",
    "    GNPredictedTimes[3]/60/60/24) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dab12",
   "metadata": {},
   "source": [
    "# F08: Global silhouette score variation w.r.t. ensemble size\n",
    "\n",
    "### Calculate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import time\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "\n",
    "#communityDetectionMethod = \"Louvain\"\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "#communityDetectionMethod = \"Girvan-Newman\"\n",
    "#communityDetectionMethod = \"Leiden-Girvan-Newman\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackageName = 'Lite'; # ['threshold'] = [0]\n",
    "#mergerPackageName = 'Lite';\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [5]\n",
    "\n",
    "# Define spatial resolutions\n",
    "spatialResolutions = [1];\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "setEnsembleSizes = [1,3,5,10,20,30,40,50];\n",
    "nsimulation = 20\n",
    "ensembleSizes = []\n",
    "for ensembleSize in setEnsembleSizes:\n",
    "    for j in range(nsimulation):\n",
    "        ensembleSizes.append(ensembleSize)\n",
    "\n",
    "# Set initiation to false, this tells defineBasins not to recalculate\n",
    "# 1) graph (nodes and connections)\n",
    "# 2) node values from the field\n",
    "# 3) node edge weights node values and used method\n",
    "# Only set to false if this is not the first time the cell is being run in this kernel.\n",
    "initiation = True;\n",
    "\n",
    "# Option to output plots or only readme.txt used for analysis\n",
    "makePlots = False;\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    print(resolution, ensembleSize, minBasinCnt, spatialResolution)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "# for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "for resolution, ensembleSize, minBasinCnt, spatialResolution in EC.utils.combine_lists(resolutions, ensembleSizes, minBasinCnts, spatialResolutions):\n",
    "    # Change data type to avoid errors\n",
    "    spatialResolution = int(spatialResolution)\n",
    "    minBasinCnt = int(minBasinCnt)\n",
    "    ensembleSize = int(ensembleSize)\n",
    "    \n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"constantSeeds\":False,\n",
    "                       \"minBasinLargerThanSmallMergers\":True,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":8}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results    \n",
    "    !mkdir -p figures/GMD_Manuscript/CodeOutputs/EnsembleSilhouetteScores\n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/EnsembleSilhouetteScores/EnsembleSize{0}_Resolution-{1}deg'.format(ensembleSize,spatialResolution))\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "    # Create basin object\n",
    "    if initiation:\n",
    "        body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "        body = body[0]\n",
    "        basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                                 filename=\"{}_resampled_{:0.1f}deg.nc\".format(body, spatialResolution),\n",
    "                                 body=body);\n",
    "\n",
    "\n",
    "        # Assign fields to use in community detection\n",
    "        basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "        # Show all fields stored in basins object\n",
    "        basins.getFields(usedFields = False)\n",
    "\n",
    "        # Show all fields stored in basins object that will be used\n",
    "        # for community detection.\n",
    "        basins.getFields(usedFields = True)\n",
    "        \n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    startTime = time.time()\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False,\n",
    "                        initiation=initiation)\n",
    "    endTime = time.time()\n",
    "    print(\"Detection Time: {} seconds\".format(endTime-startTime))\n",
    "    \n",
    "    # Set initiation to false, this tells defineBasins not to recalculate\n",
    "    # 1) graph (nodes and connections)\n",
    "    # 2) node values from the field\n",
    "    # 3) node edge weights node values and used method\n",
    "    initiation = False\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    readmetxt += \"\\nDetection Time: {} seconds\\n\".format(endTime-startTime)\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    if not (communityDetectionMethod == \"Girvan-Newman\"):\n",
    "        metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                             resolution=resolution,\n",
    "                                                             ensembleSize=ensembleSize,\n",
    "                                                             distance_threshold=0.3)\n",
    "        readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "    if makePlots:\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal.png\",\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"mesh\":True,\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_Contour.png\",\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                            pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"-\",\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"mesh\":False,\n",
    "                                     \"coastlines\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)  \n",
    "\n",
    "\n",
    "\n",
    "        #########################\n",
    "        ### Plot input fields ###\n",
    "        #########################\n",
    "        EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[ave-1*std,\n",
    "                                                    ave+1*std]},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                     \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "\n",
    "        ##############################\n",
    "        ### Plot Silhouette fields ###\n",
    "        ##############################\n",
    "        EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[0,\n",
    "                                                    1],\n",
    "                                      \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                      \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                     \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)\n",
    "\n",
    "        EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                            outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                            fidName = \"plotGlobal_silhouette_2_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                            cmapOpts={\"cmap\":\"jet\",\n",
    "                                      \"cbar-title\":\"cbar-title\",\n",
    "                                      \"cbar-range\":[-1,\n",
    "                                                    1],\n",
    "                                      \"cbar-levels\":np.array([-1,0, .5, 1]),\n",
    "                                      \"cbar-intervals\":np.array([-1, 0, .5, 1]),\n",
    "                                      \"cbar-level-names\":[\"No\", \"Poor\", \"Good\"]},\n",
    "                            pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                     \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                     \"plotTitle\":\"\",\n",
    "                                     \"plotZeroContour\":False,\n",
    "                                     \"nanSolidPoly\":True,\n",
    "                                     \"nanSolidPolyOutline\":True,\n",
    "                                     \"plotIntegerContours\":True,\n",
    "                                     \"transparent\":True},\n",
    "                            savePNG=True,\n",
    "                            saveSVG=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218a2fa",
   "metadata": {},
   "source": [
    "### Plot model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca165ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import used libraries\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_SILHOUETTE_RE = re.compile(\n",
    "    r\"\"\"^Silhouette\\ value:\\s*\n",
    "        (?P<val>[+-]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][+-]?\\d+)?)\n",
    "        \\s*(?:|\\+|\\+-|\\u00B1|\\s*\\\\pm\\s*)\n",
    "        \\s*(?P<std>[+-]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][+-]?\\d+)?)\n",
    "        \\s*$\n",
    "    \"\"\",\n",
    "    re.VERBOSE,\n",
    ")\n",
    "\n",
    "\n",
    "def _parse_silhouette(readme_path: Path) -> Optional[Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    _parse_silhouette reads value and std pair from the readme.txt outputed\n",
    "    by basin detections above.\n",
    "    \n",
    "    Returns  \n",
    "    --------\n",
    "    value : FLOAT\n",
    "        silhouette value from readme.txt, or None if not found.\n",
    "    reported_std : FLOAT\n",
    "        silhouette std value from readme.txt, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for line in readme_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "            line = line.strip()\n",
    "            m = _SILHOUETTE_RE.match(line)\n",
    "            if m:\n",
    "                return float(m.group(\"val\")), float(m.group(\"std\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def weightedAverageUncertainty(values, std):\n",
    "    '''\n",
    "    weightedAverageUncertainty is used to do error propagation\n",
    "    given input values and their uncertainty.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    values : NDARRAY\n",
    "        Measurement value.\n",
    "    \n",
    "    std : NDARRAY\n",
    "        Measurement uncertainty value.\n",
    "        \n",
    "    Return\n",
    "    -------\n",
    "    xw : FLOAT\n",
    "        Uncertainty weighted average.\n",
    "    \n",
    "    stdw : FLOAT\n",
    "        Uncertainty weighted uncertainty for xw.\n",
    "    '''\n",
    "    import numpy as np\n",
    "    \n",
    "    # Define weight based on measurement uncertainty\n",
    "    w    = 1/(std**2);\n",
    "    \n",
    "    # Define the measurement uncertainty weighted uncertainty\n",
    "    stdw = 1/np.sqrt(np.sum(w))\n",
    "\n",
    "    # Define the measurement uncertainty weighted average\n",
    "    xw   = np.sum(w*values)/np.sum(w)\n",
    "    \n",
    "    # Return values\n",
    "    return xw, stdw\n",
    "\n",
    "\n",
    "def summarize_silhouette_by_ensemble(\n",
    "    base_path: Path | str,\n",
    "    ensemble_sizes: Iterable[int],\n",
    "    *,\n",
    "    file_name: str = \"readme.txt\",\n",
    "    pattern_prefix: str = \"EnsembleSize\",      # e.g., EnsembleSize{ES}_Resolution-1deg_{RUN}\n",
    "    pattern_middle: str = \"_Resolution-1deg_\", # the fixed chunk between ES and run index\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    summarize_silhouette_by_ensemble scans directories like:\n",
    "        base_path / f\"EnsembleSize{ES}_Resolution-1deg_*/readme.txt\"\n",
    "    extract 'Silhouette value: X  Y', and compute per-ensemble-size aggregates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_path : PATH | STRING\n",
    "        Root directory containing EnsembleSize* folders.\n",
    "    ensemble_sizes : ITERABLE[INT]\n",
    "        Which ensemble sizes to aggregate.\n",
    "    file_name : STRING\n",
    "        Name of the file to parse in each run directory (default 'readme.txt').\n",
    "    pattern_prefix : STRING\n",
    "        Prefix before the ensemble size in the directory name.\n",
    "    pattern_middle : STRING\n",
    "        Fixed text between ensemble size and the run index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per ensemble size with:\n",
    "            - ensemble_size\n",
    "            - n_runs_parsed\n",
    "            - value_mean             (mean of the absolute silhouette values across runs)\n",
    "            - value_std_across_runs  (standard deviation of values across runs)\n",
    "            - reported_std_mean      (mean of the reported std after '' across runs)\n",
    "            - reported_std_std       (std of the reported std across runs)\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    rows: List[Dict] = []\n",
    "\n",
    "    for es in ensemble_sizes:\n",
    "        # Find all run folders for this ensemble size\n",
    "        glob_pat = f\"{pattern_prefix}{es}{pattern_middle}*/{file_name}\"\n",
    "        files = sorted(base_path.glob(glob_pat))\n",
    "\n",
    "        vals: List[float] = []\n",
    "        reps: List[float] = []\n",
    "\n",
    "        for f in files:\n",
    "            parsed = _parse_silhouette(f)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "            v, s = parsed\n",
    "            # The user asked for the \"absolute value before \"; silhouette is commonly non-negative,\n",
    "            # but we honor the request explicitly:\n",
    "            vals.append(abs(v))\n",
    "            reps.append(float(s))\n",
    "            \n",
    "        # Calculate uncertainty weighted mean and propagrated uncertainty\n",
    "        uncertaintyWMean, uncertaintyWstd = weightedAverageUncertainty(np.array(vals), np.array(reps))\n",
    "        \n",
    "        minVal = np.min(np.array(vals))\n",
    "        minValRep = np.max(np.array(reps)[np.array(vals)==minVal])\n",
    "        \n",
    "        n = len(vals)\n",
    "        if n == 0:\n",
    "            # still create a row so it's visible that nothing was found\n",
    "            rows.append(\n",
    "                dict(\n",
    "                    ensemble_size=es,\n",
    "                    n_runs_parsed=0,\n",
    "                    value_mean=np.nan,\n",
    "                    value_std_across_runs=np.nan,\n",
    "                    reported_std_mean=np.nan,\n",
    "                    reported_std_std=np.nan,\n",
    "                    uncertaintyWMean=np.nan,\n",
    "                    uncertaintyWstd=np.nan,\n",
    "                    minVal=np.nan,\n",
    "                    minValRep=np.nan\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        vals_arr = np.asarray(vals, dtype=float)\n",
    "        reps_arr = np.asarray(reps, dtype=float)\n",
    "\n",
    "        rows.append(\n",
    "            dict(\n",
    "                ensemble_size=es,\n",
    "                n_runs_parsed=n,\n",
    "                value_mean=float(np.mean(vals_arr)),\n",
    "                value_std_across_runs=float(np.std(vals_arr, ddof=1)) if n > 1 else 0.0,\n",
    "                reported_std_mean=float(np.mean(reps_arr)),\n",
    "                reported_std_std=float(np.std(reps_arr, ddof=1)) if n > 1 else 0.0,\n",
    "                uncertaintyWMean=uncertaintyWMean,\n",
    "                uncertaintyWstd=uncertaintyWstd,\n",
    "                minVal=minVal,\n",
    "                minValRep=minValRep\n",
    "            )\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"ensemble_size\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def makePlot(std1, std2, meanSilhouette, summary):\n",
    "    \"\"\"\n",
    "    makePlot creates summary plot of silhouette values given\n",
    "    information of multiple runs at different emsemble size.\n",
    "    summarize_silhouette_by_ensemble can be used to read summarized\n",
    "    ensemble runs.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    std1\n",
    "    std2\n",
    "    meanSilhouette\n",
    "    \n",
    "    \"\"\"\n",
    "    # Plot mean silhouette and envelope for std \n",
    "    idxStable = 5\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 4), width_ratios=[2,1])\n",
    "\n",
    "\n",
    "    # Plot 1\n",
    "    ax1 = axes[0][0]\n",
    "    ax2 = axes[1][0]\n",
    "\n",
    "    ax1.plot(summary['ensemble_size'].values,\n",
    "             summary['minVal'].values,\n",
    "             '-k',\n",
    "             label=r\"Minimum silhouette\")\n",
    "\n",
    "    ax1.plot(summary['ensemble_size'].values,\n",
    "             summary['minVal'].values-summary['minValRep'].values,\n",
    "             '--k',\n",
    "             label=r\"Minimum silhouette - $\\sigma$\")\n",
    "    \n",
    "    ax1.plot(summary['ensemble_size'].values,\n",
    "             summary['value_mean'].values,\n",
    "             '-r',\n",
    "             label='Averaged silhouette')\n",
    "\n",
    "    ax1.plot(summary['ensemble_size'].values[idxStable], \n",
    "              meanSilhouette[idxStable],\n",
    "              'om',\n",
    "              markersize=10,\n",
    "              label='Stable Ensemble Threshold')\n",
    "\n",
    "\n",
    "    # Create hatch regions to define Strong and Good Boundary Stability\n",
    "    ax1.fill_between(summary['ensemble_size'].values,\n",
    "                     0.7+0*summary['ensemble_size'].values,\n",
    "                     y2=1+0*summary['ensemble_size'].values,\n",
    "                     where=(0.7+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='yellow',\n",
    "                     alpha=0.7,\n",
    "                     label='Strong Boundary Stability')\n",
    "\n",
    "    ax1.fill_between(summary['ensemble_size'].values,\n",
    "                     0.5+0*summary['ensemble_size'].values,\n",
    "                     y2=0.7+0*summary['ensemble_size'].values,\n",
    "                     where=(0.5+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='gray',\n",
    "                     alpha=0.7,\n",
    "                     label='Good Boundary Stability')\n",
    "\n",
    "\n",
    "    ax1.fill_between(summary['ensemble_size'].values,\n",
    "                     0*summary['ensemble_size'].values,\n",
    "                     y2=0.5+0*summary['ensemble_size'].values,\n",
    "                     where=(0.3+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='red',\n",
    "                     alpha=0.7,\n",
    "                     label='Week Boundary Stability')\n",
    "\n",
    "\n",
    "\n",
    "    fig.supylabel('Area Averaged Silhouette')\n",
    "\n",
    "    ax1.set_ylim([0,1]);\n",
    "    ax1.set_xlim([np.min(summary['ensemble_size'].values),np.max(summary['ensemble_size'].values)]);\n",
    "\n",
    "\n",
    "    # Plot 2\n",
    "    idxStart = 2\n",
    "    std1 = std1[idxStart:]\n",
    "    std2 = std2[idxStart:]\n",
    "\n",
    "\n",
    "    ax2.set_xlim([np.min(summary['ensemble_size'].values),np.max(summary['ensemble_size'].values)]);\n",
    "\n",
    "    ax2.plot(summary['ensemble_size'].values[idxStart:],\n",
    "              meanSilhouette[idxStart:],\n",
    "              '-r',\n",
    "              label='Averaged silhouette')\n",
    "\n",
    "    ax2.plot(summary['ensemble_size'].values[idxStart:][idxStable-idxStart], \n",
    "              meanSilhouette[idxStart:][idxStable-idxStart],\n",
    "              'om',\n",
    "              markersize=10,\n",
    "              label='Stable Ensemble Threshold')\n",
    "\n",
    "\n",
    "    \n",
    "    # Plot 3 (used for creating legend)\n",
    "    std1 = summary['value_std_across_runs'].values\n",
    "    std2 = summary['reported_std_mean'].values\n",
    "\n",
    "    ax3 = axes[0][1]    \n",
    "    ax3.plot(summary['ensemble_size'].values,\n",
    "             summary['minVal'].values,\n",
    "             '-k',\n",
    "             label=r\"Minimum silhouette\")\n",
    "\n",
    "    ax3.plot(summary['ensemble_size'].values,\n",
    "             summary['minVal'].values-summary['minValRep'].values,\n",
    "             '--k',\n",
    "             label=r\"Minimum silhouette - $\\sigma$\")\n",
    "\n",
    "    ax3.plot(summary['ensemble_size'].values,\n",
    "              meanSilhouette,\n",
    "              '-r',\n",
    "              label='Averaged silhouette')\n",
    "\n",
    "    ax3.plot(summary['ensemble_size'].values[idxStable], \n",
    "              summary['value_mean'].values[idxStable],\n",
    "              'om',\n",
    "              markersize=10,\n",
    "              label='Stable Ensemble Threshold')\n",
    "\n",
    "\n",
    "    # Create hatch regions to define Strong and Good Boundary Stability\n",
    "    ax3.fill_between(summary['ensemble_size'].values,\n",
    "                     0.7+0*summary['ensemble_size'].values,\n",
    "                     y2=1+0*summary['ensemble_size'].values,\n",
    "                     where=(0.7+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='yellow',\n",
    "                     alpha=0.7,\n",
    "                     label='Strong Boundary Stability')\n",
    "\n",
    "    ax3.fill_between(summary['ensemble_size'].values,\n",
    "                     0.5+0*summary['ensemble_size'].values,\n",
    "                     y2=0.7+0*summary['ensemble_size'].values,\n",
    "                     where=(0.5+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='gray',\n",
    "                     alpha=0.7,\n",
    "                     label='Good Boundary Stability')\n",
    "\n",
    "\n",
    "    ax3.fill_between(summary['ensemble_size'].values,\n",
    "                     0*summary['ensemble_size'].values,\n",
    "                     y2=0.5+0*summary['ensemble_size'].values,\n",
    "                     where=(0.3+0*summary['ensemble_size'].values > -np.inf),\n",
    "                     facecolor='none',\n",
    "                     hatch='///',\n",
    "                     edgecolor='red',\n",
    "                     alpha=0.7,\n",
    "                     label='Week Boundary Stability')\n",
    "\n",
    "\n",
    "    \n",
    "    # Formatting\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticks([0,0.5,0.7,1])\n",
    "\n",
    "    ax2.set_xlabel('Ensemble Count')\n",
    "    ax2.set_ylim([0.7,0.9]);\n",
    "\n",
    "    ax3.set_ylim([-1,-.5]);\n",
    "    ax3.set_xlim([0,.5]);\n",
    "    ax3.legend(loc='lower center')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    ax4 = axes[1][1]\n",
    "    ax4.axis('off')\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    # Output figure\n",
    "    plt.savefig(os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/EnsembleSilhouetteScores/SilhouetteEnsembleSizeAnalysis.png\",\n",
    "                dpi=600,\n",
    "                transparent=True)\n",
    "    plt.savefig(os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/EnsembleSilhouetteScores/SilhouetteEnsembleSizeAnalysis.svg\",\n",
    "                dpi=600,\n",
    "                transparent=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Read model outputs (i.e., readme.txt files)\n",
    "base = os.getcwd()+\"/figures/GMD_Manuscript/CodeOutputs/EnsembleSilhouetteScores\"\n",
    "ensemble_sizes = [1, 3, 5, 10, 20, 30, 40, 50]\n",
    "summary = summarize_silhouette_by_ensemble(base, ensemble_sizes)\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "# Report some silhouette score information on the ensembles\n",
    "std1 = summary['value_std_across_runs'].values\n",
    "std2 = summary['reported_std_mean'].values\n",
    "meanSilhouette = summary['value_mean'].values\n",
    "\n",
    "\n",
    "std1 = summary['uncertaintyWstd'].values\n",
    "std2 = summary['reported_std_mean'].values\n",
    "meanSilhouette = summary['uncertaintyWMean'].values\n",
    "makePlot(std1, std2, meanSilhouette, summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155cc4b",
   "metadata": {},
   "source": [
    "# Regional Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################### Imports ####################\n",
    "#################################################\n",
    "import os\n",
    "import ExoCcycle as EC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as ccrs # type: ignore\n",
    "\n",
    "\n",
    "#########################################\n",
    "### Define Community Detection Inputs ###\n",
    "#########################################\n",
    "# Set the detection method\n",
    "communityDetectionMethod = \"Leiden\"\n",
    "\n",
    "# Define basin merging criteria\n",
    "# mergerPackageName = 'None'; # ['threshold'] = [0]\n",
    "mergerPackageName = 'Lite';\n",
    "\n",
    "# Define basin merging criteria\n",
    "mergerPackage = EC.utils.mergerPackages(mergerPackageName);\n",
    "mergerPackage['verbose'] = False;\n",
    "\n",
    "# Resolution for quality function\n",
    "resolutions = [.01]\n",
    "\n",
    "# Minimum number of basins to have in output (only used for\n",
    "# girvan-newman or composite algorithms)\n",
    "minBasinCnts = [12]\n",
    "\n",
    "# Set the ensemble size to use for the first part of the composite community detection\n",
    "# This part runs Louvain or Leiden algorithms to reduce the network complexity. Setting\n",
    "# a non-one ensemble ensures that community structure is robust given inherent randomness\n",
    "# of initial node clustering. Note that ensembles of size 100 for 1 degree resolution data\n",
    "# only increase total computational time by 1-2 minutes.\n",
    "ensembleSizes = [50];\n",
    "\n",
    "\n",
    "# Set spatial resolution\n",
    "spatialResolution = .1\n",
    "region = np.array([[-100, 20], [-80, 31]])\n",
    "\n",
    "\n",
    "# Show the resolution, ensembleSize, and minBasinCnt used for community detection\n",
    "# runs. Note that only one community detection is run here.\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    print(resolution, ensembleSize, minBasinCnt)\n",
    "\n",
    "# Run for multiple resolution, ensembleSize, and minBasinCnt\n",
    "for resolution, ensembleSize, minBasinCnt in zip(resolutions, ensembleSizes, minBasinCnts):\n",
    "    detectionMethod = {\"method\":communityDetectionMethod,\n",
    "                       \"resolution\":resolution,\n",
    "                       \"minBasinCnt\":minBasinCnt,\n",
    "                       \"ensembleSize\":ensembleSize,\n",
    "                       \"minBasinLargerThanSmallMergers\":False,\n",
    "                       \"mergerPackage\":mergerPackage,\n",
    "                       \"njobs\":4}\n",
    "\n",
    "    # Set the edge weight scheme for node connections\n",
    "    # Options:\n",
    "    #    \"useGravity\", \"useLogistic\", \"useQTGaussianShiftedGaussianWeightDistribution\"\n",
    "    edgeWeightMethod = {\"method\":\"useQTGaussianShiftedGaussianWeightDistribution\",\n",
    "                       \"shortenFactor\": 5,\n",
    "                       \"shiftFactor\": .5,\n",
    "                       \"minWeight\": 0.01}\n",
    "\n",
    "    # Make folder to hold figure results    \n",
    "    fldName = EC.utils.makeFolderSeries(fldBase='figures/GMD_Manuscript/CodeOutputs/CompositeMethod_Leiden')\n",
    "    print(\"Storing images in {}\".format(fldName))\n",
    "\n",
    "    # Short readme text to write to folder with images\n",
    "    readmetxt = \"Bathymetry used to calculate basin boundaries.\";\n",
    "    readmetxt += \"\\nUsing {0} detection with the DQT-CDF edge weighting method\".format(detectionMethod[\"method\"])\n",
    "    readmetxt += \"DQT-CDF parameters: 'useQTGaussianShiftedGaussianWeightDistribution' with shorten = sigma*{0} & shift = sigma*{1}, minimum weight = {2})\".format(edgeWeightMethod[\"shortenFactor\"], edgeWeightMethod[\"shiftFactor\"], edgeWeightMethod['minWeight']);\n",
    "    readmetxt += \"\\n{} resolution: {}\".format(detectionMethod[\"method\"], detectionMethod[\"resolution\"]);\n",
    "    readmetxt += \"\\n{} ensemble size: {}\".format(detectionMethod[\"method\"], detectionMethod[\"ensembleSize\"]);\n",
    "    readmetxt += \"\\nGirvan-Newman minimum unisolated basins: {}\".format(detectionMethod['minBasinCnt']);\n",
    "    readmetxt += \"\\nCommunity merger package is EC.utils.mergePackage(package='{}'), Chi = {}\".format(mergerPackageName, \", \".join( list(mergerPackage['mergeSmallBasins']['threshold'].astype(str)) ));    \n",
    "\n",
    "\n",
    "    #################################################################\n",
    "    ### Create basin object and set Field for Community detection ###\n",
    "    #################################################################\n",
    "\n",
    "    # Create basin object\n",
    "    body = [\"Earth\", \"Mars\", \"Venus\", \"Moon\"]\n",
    "    body = body[0]\n",
    "\n",
    "    basins = EC.utils.BasinsEA(dataDir=os.getcwd()+\"/bathymetries/{}\".format(body),\n",
    "                             filename=\"{}_resampled_{:0.1f}deg.nc\".format(body, spatialResolution),\n",
    "                             body=body,\n",
    "                             region=region  );\n",
    "\n",
    "\n",
    "    # Assign fields to use in community detection\n",
    "    basins.useFields(fieldList=np.array([\"Field1\"]))\n",
    "\n",
    "    # Show all fields stored in basins object\n",
    "    basins.getFields(usedFields = False)\n",
    "\n",
    "    # Show all fields stored in basins object that will be used\n",
    "    # for community detection.\n",
    "    basins.getFields(usedFields = True)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    ### Run Community Detection Algorithm ###\n",
    "    #########################################\n",
    "    # Define basins based on user input boundaries.\n",
    "    # For the Louvain-Girvan-Newman composite algorithm the variable\n",
    "    # minBasinCnt refers to the number of basins to maintain that are\n",
    "    # not completely isolated after running the louvain algorithm.\n",
    "    basins.defineBasins(detectionMethod = detectionMethod,\n",
    "                        edgeWeightMethod = edgeWeightMethod,\n",
    "                        reducedRes={\"on\":True,\"factor\":1},\n",
    "                        read=False,\n",
    "                        write=True,\n",
    "                        verbose=False)\n",
    "\n",
    "\n",
    "    # Merge communities based off criteria \n",
    "    basins.applyMergeBasinMethods(mergerID=0, mergerPackage=mergerPackage)\n",
    "\n",
    "    # Convert basinID equal area grid to regular grid\n",
    "    basins.interp2regularGrid(mask=True)\n",
    "    \n",
    "    # Get small and large basins\n",
    "    percentThreshold = 0.5;\n",
    "    basinSizeDic = basins.getBasinSize(fraction=True, Threshold=percentThreshold)\n",
    "    \n",
    "    readmetxt += basinSizeDic[\"text\"]\n",
    "    \n",
    "    # Get community detection metrics\n",
    "    metrics, metricText = basins.reportEvaluationMetrics(returnText=True,\n",
    "                                                         resolution=resolution,\n",
    "                                                         ensembleSize=ensembleSize,\n",
    "                                                         distance_threshold=0.3)\n",
    "    readmetxt += (\"\\n\\n\" + metricText)\n",
    "    \n",
    "    \n",
    "    ##################################\n",
    "    ### Calculate Silhouette field ###\n",
    "    ##################################\n",
    "    silhouette = basins.interp2regularGrid(propertyName=\"consensus_silhouette\", mask=True)\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    areaWeights, longitudes, latitudes, totalArea, totalAreaCalculated = EC.utils.areaWeights(resolution=basins.Fields[\"Field1\"]['resolution'],\n",
    "                                                                                              LonStEd = [np.min(basins.lon),np.max(basins.lon)+basins.Fields[\"Field1\"]['resolution']/2],\n",
    "                                                                                              LatStEd = [np.min(basins.lat),np.max(basins.lat)+basins.Fields[\"Field1\"]['resolution']/2])\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "    aveSilhouette, stdSilhouette = EC.utils.weightedAvgAndStd(silhouette, areaWeights)\n",
    "    print( \"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette) )\n",
    "    readmetxt += (\"Silhouette value: {0:2.4f} \\u00B1 {1:2.4f}\".format(aveSilhouette, stdSilhouette))  \n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    ### Report community evaluation metrics ###\n",
    "    ###########################################\n",
    "    with open(fldName+\"/readme.txt\", \"w\") as text_file:\n",
    "        text_file.write(readmetxt)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ### Plot results of community IDs ###\n",
    "    #####################################\n",
    "\n",
    "\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_Contour.png\",\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,np.nanmax(basins.BasinIDA)]},\n",
    "                        pltOpts={\"valueType\": \"BasinID divided by {}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"-\",\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"region\": [region[0,0],region[1,0], region[0,1],region[1,1]],\n",
    "                                 \"projection\":ccrs.Mercator(),\n",
    "                                 \"mesh\":False,\n",
    "                                 \"coastlines\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)  \n",
    "\n",
    "\n",
    "\n",
    "    # Calculate area weighted average and standard deviation (for plotting)\n",
    "    ave, std = EC.utils.weightedAvgAndStd(basins.bathymetry, areaWeights)\n",
    "\n",
    "    #########################\n",
    "    ### Plot input fields ###\n",
    "    #########################\n",
    "    EC.plotHelper.plotGlobal(basins.lat, basins.lon, basins.bathymetry,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[ave-1*std,\n",
    "                                                ave+1*std]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                                 \"valueUnits\": \"{}\".format(basins.Fields[\"Field1\"]['parameterUnit']),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"region\": [region[0,0],region[1,0], region[0,1],region[1,1]],\n",
    "                                 \"projection\":ccrs.Mercator(),\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "    ##############################\n",
    "    ### Plot Silhouette fields ###\n",
    "    ##############################\n",
    "    EC.plotHelper.plotGlobalSilhouette(basins.lat, basins.lon, silhouette, basins.BasinIDA,\n",
    "                        outputDir = os.getcwd()+\"/\"+fldName,\n",
    "                        fidName = \"plotGlobal_silhouette_1_{0}.png\".format(basins.Fields[\"Field1\"]['parameterName']),\n",
    "                        cmapOpts={\"cmap\":\"jet\",\n",
    "                                  \"cbar-title\":\"cbar-title\",\n",
    "                                  \"cbar-range\":[0,\n",
    "                                                1],\n",
    "                                  \"cbar-levels\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-intervals\":np.array([0,.25, .5, .7, 1]),\n",
    "                                  \"cbar-level-names\":[\"No\", \"Weak\", \"Medium\", \"Strong\"]},\n",
    "                        pltOpts={\"valueType\": \"{0}\".format(\"Silhouette Structure\"),\n",
    "                                 \"valueUnits\": \"{}\".format(\"-\"),\n",
    "                                 \"plotTitle\":\"\",\n",
    "                                 \"region\": [region[0,0],region[1,0], region[0,1],region[1,1]],\n",
    "                                 \"projection\":ccrs.Mercator(),\n",
    "                                 \"plotZeroContour\":False,\n",
    "                                 \"nanSolidPoly\":True,\n",
    "                                 \"nanSolidPolyOutline\":True,\n",
    "                                 \"plotIntegerContours\":True,\n",
    "                                 \"transparent\":True},\n",
    "                        savePNG=True,\n",
    "                        saveSVG=False)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ExoCcycle] *",
   "language": "python",
   "name": "conda-env-ExoCcycle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
